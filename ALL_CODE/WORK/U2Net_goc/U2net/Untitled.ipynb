{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdb176f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df1 = gp.read_file(\n",
    "    '/mnt/data/public/changedetection_SAR/result_1712/predict/stack_4img_Oct21_feb20.shp')\n",
    "df2 = gp.read_file('/mnt/data/public/changedetection_SAR/10class_lulc.geojson')\n",
    "\n",
    "df1 = df1.to_crs('EPSG:4326')\n",
    "df2 = df2.to_crs('EPSG:4326')\n",
    "# df1 = df1[['Layer', 'Level', 'geometry']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89aaa75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "# a = np.array([[1, 0, 0], [1, 0, 0], [2, 3, 4]])\n",
    "# np.unique(a)\n",
    "\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "dir_img = \"/home/skm/SKM16/Work/OpenLand/all_tif/tmp/20220823_104207_ssc7_u0001_visual.tif\"\n",
    "src = rasterio.open(dir_img)\n",
    "a = src.read(window=Window(0, 0, 512, 512))[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "351250d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0, 0, 0])\n",
    "if type(a) == 'numpy.ndarray':\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c031cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb279f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1= df1[['fid', 'geometry']]\n",
    "# df1 = df1.rename(columns={\"fid\": \"FID\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4009418",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfxxx = gp.overlay(df1, df2, how='intersection')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa02724",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1159130/2610056326.py:2: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  i = a.area\n"
     ]
    }
   ],
   "source": [
    "def xxx(a):\n",
    "    i = a.area\n",
    "    a = a[i == max(i)]\n",
    "    return a\n",
    "\n",
    "\n",
    "dff = dfxxx.groupby('FID').apply(xxx).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668806b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FID</th>\n",
       "      <th>fid</th>\n",
       "      <th>class</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16719</td>\n",
       "      <td>5</td>\n",
       "      <td>MULTIPOLYGON (((-84.55404 9.90664, -84.55404 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17145</td>\n",
       "      <td>7</td>\n",
       "      <td>MULTIPOLYGON (((-84.52717 9.90807, -84.52724 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19645</td>\n",
       "      <td>5</td>\n",
       "      <td>POLYGON ((-83.87685 9.90995, -83.87685 9.90987...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>19645</td>\n",
       "      <td>5</td>\n",
       "      <td>POLYGON ((-83.83225 9.91868, -83.83234 9.91868...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>14239</td>\n",
       "      <td>6</td>\n",
       "      <td>POLYGON ((-84.36096 9.95493, -84.36087 9.95493...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8415</th>\n",
       "      <td>8976</td>\n",
       "      <td>308</td>\n",
       "      <td>3</td>\n",
       "      <td>MULTIPOLYGON (((-83.52036 10.13256, -83.51973 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8416</th>\n",
       "      <td>8977</td>\n",
       "      <td>714</td>\n",
       "      <td>5</td>\n",
       "      <td>POLYGON ((-83.48529 10.13265, -83.48502 10.132...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8417</th>\n",
       "      <td>8978</td>\n",
       "      <td>18841</td>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((-83.41191 10.13302, -83.41191 10.133...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8418</th>\n",
       "      <td>8979</td>\n",
       "      <td>771</td>\n",
       "      <td>7</td>\n",
       "      <td>POLYGON ((-83.55634 10.13301, -83.55598 10.133...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8419</th>\n",
       "      <td>8980</td>\n",
       "      <td>308</td>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((-83.51614 10.13373, -83.51596 10.133...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8420 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FID    fid  class                                           geometry\n",
       "0        0  16719      5  MULTIPOLYGON (((-84.55404 9.90664, -84.55404 9...\n",
       "1        1  17145      7  MULTIPOLYGON (((-84.52717 9.90807, -84.52724 9...\n",
       "2        2  19645      5  POLYGON ((-83.87685 9.90995, -83.87685 9.90987...\n",
       "3        3  19645      5  POLYGON ((-83.83225 9.91868, -83.83234 9.91868...\n",
       "4        4  14239      6  POLYGON ((-84.36096 9.95493, -84.36087 9.95493...\n",
       "...    ...    ...    ...                                                ...\n",
       "8415  8976    308      3  MULTIPOLYGON (((-83.52036 10.13256, -83.51973 ...\n",
       "8416  8977    714      5  POLYGON ((-83.48529 10.13265, -83.48502 10.132...\n",
       "8417  8978  18841      2  POLYGON ((-83.41191 10.13302, -83.41191 10.133...\n",
       "8418  8979    771      7  POLYGON ((-83.55634 10.13301, -83.55598 10.133...\n",
       "8419  8980    308      3  POLYGON ((-83.51614 10.13373, -83.51596 10.133...\n",
       "\n",
       "[8420 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5895937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FID</th>\n",
       "      <th>geometry</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((-84.55782 9.90096, -84.55782 9.90087...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((-84.52958 9.90744, -84.52940 9.90744...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((-83.87685 9.90995, -83.87685 9.90987...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>POLYGON ((-83.83135 9.91895, -83.83126 9.91895...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>POLYGON ((-84.36096 9.95493, -84.36087 9.95493...</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8976</th>\n",
       "      <td>8976</td>\n",
       "      <td>POLYGON ((-83.52036 10.13256, -83.51973 10.132...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8977</th>\n",
       "      <td>8977</td>\n",
       "      <td>POLYGON ((-83.48529 10.13265, -83.48502 10.132...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8978</th>\n",
       "      <td>8978</td>\n",
       "      <td>POLYGON ((-83.41272 10.13328, -83.41263 10.133...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8979</th>\n",
       "      <td>8979</td>\n",
       "      <td>POLYGON ((-83.55634 10.13301, -83.55598 10.133...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8980</th>\n",
       "      <td>8980</td>\n",
       "      <td>POLYGON ((-83.51614 10.13373, -83.51596 10.133...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8981 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FID                                           geometry  class\n",
       "0        0  POLYGON ((-84.55782 9.90096, -84.55782 9.90087...    5.0\n",
       "1        1  POLYGON ((-84.52958 9.90744, -84.52940 9.90744...    7.0\n",
       "2        2  POLYGON ((-83.87685 9.90995, -83.87685 9.90987...    5.0\n",
       "3        3  POLYGON ((-83.83135 9.91895, -83.83126 9.91895...    5.0\n",
       "4        4  POLYGON ((-84.36096 9.95493, -84.36087 9.95493...    6.0\n",
       "...    ...                                                ...    ...\n",
       "8976  8976  POLYGON ((-83.52036 10.13256, -83.51973 10.132...    3.0\n",
       "8977  8977  POLYGON ((-83.48529 10.13265, -83.48502 10.132...    5.0\n",
       "8978  8978  POLYGON ((-83.41272 10.13328, -83.41263 10.133...    2.0\n",
       "8979  8979  POLYGON ((-83.55634 10.13301, -83.55598 10.133...    7.0\n",
       "8980  8980  POLYGON ((-83.51614 10.13373, -83.51596 10.133...    3.0\n",
       "\n",
       "[8981 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dfx = pd.merge(df1, dff[['class', 'FID']], on='FID', how='outer')\n",
    "dfx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495ec224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dicts = {\n",
    "#     1.0: 'Background',\n",
    "#     2.0: 'Urban',\n",
    "#     3.0: 'Water',\n",
    "#     4.0: 'Forest',\n",
    "#     5.0: 'Agriculture'\n",
    "# }\n",
    "\n",
    "dicts = {\n",
    "    1.0: 'Water',\n",
    "    2.0: 'Trees',\n",
    "    3.0: 'Grass',\n",
    "    4.0: 'Flooded Vegetation',\n",
    "    5.0: 'Crops',\n",
    "    6.0: 'Scrub/Shrub',\n",
    "    7.0: 'Built Area',\n",
    "    8.0: 'Bare Ground',\n",
    "    9.0: 'Snow/Ice',\n",
    "    10.0: 'Clouds',\n",
    "    11.0: 'Unknow'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e381e490",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1159130/4249559086.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfx['class'][dfx['class'].isnull().values]= 11.\n"
     ]
    }
   ],
   "source": [
    "dfx['class'][dfx['class'].isnull().values] = 11.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addcab98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx['class'].isnull().values.any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f527a911",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def xxx(a):\n",
    "    return dicts[a]\n",
    "\n",
    "\n",
    "dfx['label'] = dfx['class'].apply(xxx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00909810",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx.to_file(\n",
    "    '/mnt/data/public/changedetection_SAR/result_1712/stack_4img_Oct21_feb20.geojson', driver='GeoJSON')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860e1b04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8dd9fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df1 = gp.read_file(\n",
    "    '/media/skymap/Learnning/public/Komsat_change_8bit_perimage/Zoning/xxxxxxxxxxxx.shp')\n",
    "df2 = gp.read_file(\n",
    "    '/media/skymap/Learnning/public/Komsat_change_8bit_perimage/data_predict/predict_468.shp')\n",
    "\n",
    "df1 = df1.to_crs('EPSG:4326')\n",
    "df2 = df2.to_crs('EPSG:4326')\n",
    "df1 = df1[['Layer', 'Level', 'geometry']]\n",
    "\n",
    "dfxxx = gp.overlay(df1, df2, how='intersection')\n",
    "\n",
    "\n",
    "def xxx(a):\n",
    "    a = a[a.area == max(a.area)]\n",
    "    return a\n",
    "\n",
    "\n",
    "dff = dfxxx.groupby('FID').apply(xxx).reset_index(drop=True)\n",
    "df2['Layer'] = None\n",
    "df = pd.merge(df2, dff, on='FID', how='outer')\n",
    "df = df[['FID', 'score_x', 'label_x', 'Layer_y', 'Level', 'geometry_x']]\n",
    "df = df.rename(columns={\"score_x\": \"score\", \"label_x\": \"label\",\n",
    "                        \"Layer_y\": \"Layer\", \"geometry_x\": \"geometry\"})\n",
    "df = gp.GeoDataFrame(df, geometry='geometry', crs='EPSG:4326')\n",
    "df.to_file(\n",
    "    '/media/skymap/Learnning/public/Komsat_change_8bit_perimage/predictttt/result_bahrain.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c9abf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gp.read_file(\n",
    "    '/media/skymap/Learnning/public/Komsat_change_8bit_perimage/predictttt/result_Aug.shp')\n",
    "df1 = df[df['label'] == 1]\n",
    "df2 = df[df['label'] == 2][df[df['label'] == 2].score >\n",
    "                           np.percentile(df[df['label'] == 2].score, 70)]\n",
    "dfxxx = df1.append(df2)\n",
    "\n",
    "# dfxxx.to_file('/media/skymap/Learnning/public/Komsat_change_8bit_perimage/predictttt/result_Aug_v1.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5fd246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gp\n",
    "\n",
    "a = gp.read_file(\n",
    "    '/media/skymap/Learnning/public/change_detect_Bahrain/predict_xx.shp')\n",
    "\n",
    "dicts = {\n",
    "    1: 0.95,\n",
    "    2: 0.95,\n",
    "    3: 0.95\n",
    "}\n",
    "\n",
    "\n",
    "def xxx(x):\n",
    "    return x[x.score > dicts[x.label.iloc[0]]]\n",
    "\n",
    "\n",
    "mm = a.groupby('label').apply(xxx).reset_index(drop=True)\n",
    "mm.to_file('/media/skymap/Learnning/public/change_detect_Bahrain/predict_xx.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a93069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df2 = gp.read_file(\n",
    "    '/media/skymap/Learnning/public/Komsat_change_8bit_perimage/predictttttttttttttttttttttttttttttttttt/change_Aug_Jan_2020.geojson')\n",
    "\n",
    "dicts = {\n",
    "    1: 'built',\n",
    "    2: 'area',\n",
    "    3: 'tree'\n",
    "}\n",
    "\n",
    "\n",
    "def xxx(x):\n",
    "    return dicts[x]\n",
    "\n",
    "\n",
    "df2['label'] = df2['label'].apply(xxx)\n",
    "df2.to_file('/media/skymap/Learnning/public/Komsat_change_8bit_perimage/result_1211/change_Aug_Jan_2020.geojson', driver='GeoJSON')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0027a110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbb5662",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = gp.read_file(\n",
    "    '/media/skymap/Learnning/public/Komsat_change/AOI_intersec_all.shp')\n",
    "df2 = gp.read_file(\n",
    "    '/media/skymap/Learnning/public/Komsat_change_8bit_perimage/result_update1811/result_Jan20_Aug20.shp')\n",
    "df1 = df1.to_crs('EPSG:4326')\n",
    "df2 = df2.to_crs('EPSG:4326')\n",
    "dfxxx = gp.overlay(df1, df2, how='intersection')\n",
    "dfxxx = dfxxx[['label', 'score', 'FID', 'geometry']]\n",
    "dfxxx.to_file(\n",
    "    '/media/skymap/Learnning/public/Komsat_change_8bit_perimage/result_update_1811_v2/result_Jan20_Aug20.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724193e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06299938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f23c254",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import cv2\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "with rasterio.open('/media/skymap/Learnning/public/gtl/haze/train.tif') as r:\n",
    "    xxx1 = r.read()\n",
    "    out_meta = r.meta\n",
    "\n",
    "with rasterio.open('/media/skymap/Learnning/public/gtl/haze/train_1.tif') as r:\n",
    "    xxx2 = r.read()\n",
    "    out_meta = r.meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dfad70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def convert(a):\n",
    "#     return (a-np.max(a))/(np.max(a)-np.min(a))\n",
    "\n",
    "def convert(a):\n",
    "    return a\n",
    "\n",
    "\n",
    "band1 = np.concatenate(\n",
    "    (convert(xxx1[0].flatten()), convert(xxx2[0].flatten())))\n",
    "band2 = np.concatenate(\n",
    "    (convert(xxx1[1].flatten()), convert(xxx2[1].flatten())))\n",
    "band3 = np.concatenate(\n",
    "    (convert(xxx1[2].flatten()), convert(xxx2[2].flatten())))\n",
    "# band1 = np.concatenate((xxx1[0].flatten(), xxx2[0].flatten()))\n",
    "# band2 = np.concatenate((xxx1[1].flatten(), xxx2[1].flatten()))\n",
    "# band3 = np.concatenate((xxx1[2].flatten(), xxx2[2].flatten()))\n",
    "band7 = np.concatenate(\n",
    "    (convert(xxx1[6].flatten()), convert(xxx2[6].flatten())))\n",
    "band8 = np.concatenate(\n",
    "    (convert(xxx1[7].flatten()), convert(xxx2[7].flatten())))\n",
    "band9 = np.concatenate(\n",
    "    (convert(xxx1[8].flatten()), convert(xxx2[8].flatten())))\n",
    "\n",
    "\n",
    "reg1 = LinearRegression().fit(np.c_[band7, band8, band9], band1)\n",
    "reg2 = LinearRegression().fit(np.c_[band7, band8, band9], band2)\n",
    "reg3 = LinearRegression().fit(np.c_[band7, band8, band9], band3)\n",
    "print(reg1.coef_, reg1.intercept_, reg1.score(\n",
    "    np.c_[band7, band8, band9], band1))\n",
    "print(reg2.coef_, reg2.intercept_, reg2.score(\n",
    "    np.c_[band7, band8, band9], band1))\n",
    "print(reg3.coef_, reg3.intercept_, reg3.score(\n",
    "    np.c_[band7, band8, band9], band1))\n",
    "# r1 = reg1.predict(np.c_[band7, band8, band9]).astype(np.uint16).reshape(xxx1.shape[:2])\n",
    "# r2 = reg2.predict(np.c_[band7, band8, band9]).astype(np.uint16).reshape(xxx1.shape[:2])\n",
    "# r3 = reg3.predict(np.c_[band7, band8, band9]).astype(np.uint16).reshape(xxx1.shape[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef78c56b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ggg = np.stack((r1, r2, r3)).transpose(1, 2, 0)\n",
    "plt.figure(figsize=(15, 20))\n",
    "plt.imshow(ggg/np.max(ggg, axis=(0, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703a0539",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 20))\n",
    "plt.imshow(xxx1[..., :3]/np.max(xxx1[..., :3], axis=(0, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ba3778",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open('/media/skymap/Learnning/public/gtl/haze/predict.tif') as r:\n",
    "    yyy = r.read()\n",
    "    out_meta = r.meta\n",
    "\n",
    "bandy7 = convert(yyy[6].flatten())\n",
    "bandy8 = convert(yyy[7].flatten())\n",
    "bandy9 = convert(yyy[8].flatten())\n",
    "\n",
    "a = reg1.predict(np.c_[bandy7, bandy8, bandy9]).astype(\n",
    "    np.uint16).reshape(yyy.shape[1:])\n",
    "b = reg2.predict(np.c_[bandy7, bandy8, bandy9]).astype(\n",
    "    np.uint16).reshape(yyy.shape[1:])\n",
    "c = reg3.predict(np.c_[bandy7, bandy8, bandy9]).astype(\n",
    "    np.uint16).reshape(yyy.shape[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71572f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open('/media/skymap/Learnning/public/gtl/haze/predict.tif') as r:\n",
    "    yyy = r.read()\n",
    "    out_meta = r.meta\n",
    "\n",
    "bandy7 = convert(yyy[6].flatten())\n",
    "bandy8 = convert(yyy[7].flatten())\n",
    "bandy9 = convert(yyy[8].flatten())\n",
    "\n",
    "a = reg1.predict(np.c_[bandy7, bandy8, bandy9]).reshape(yyy.shape[1:])\n",
    "b = reg2.predict(np.c_[bandy7, bandy8, bandy9]).reshape(yyy.shape[1:])\n",
    "c = reg3.predict(np.c_[bandy7, bandy8, bandy9]).reshape(yyy.shape[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ece68e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out_meta.update({'count': 4})\n",
    "with rasterio.open('/media/skymap/Learnning/public/gtl/haze/xxxx.tif', 'w', **out_meta) as r:\n",
    "    r.write(np.stack((a, b, c, yyy[6])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a2d416",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "showw = np.stack((a, b, c)).transpose(1, 2, 0)\n",
    "plt.figure(figsize=(15, 20))\n",
    "plt.imshow(showw/np.max(showw, axis=(0, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abe88a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 20))\n",
    "plt.imshow(yyy[..., :3]/np.max(yyy[..., :3], axis=(0, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cb7859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02abcc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import cv2\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "with rasterio.open('/media/skymap/Learnning/public/changedetection_SAR/xxxxx.tif') as r:\n",
    "    xxx = r.read().transpose(1, 2, 0)\n",
    "    out_meta = r.meta\n",
    "plt.imshow(xxx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005dc69c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "band = copy.copy(xxx)\n",
    "extrapol = (2*band[..., 2] - 0.95*band[..., 0])\n",
    "plt.imshow(extrapol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742bc4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 21\n",
    "x_size = [i for i in range(0, xxx.shape[0], w)]\n",
    "y_size = [j for j in range(0, xxx.shape[1], w)]\n",
    "HTM = np.ones((len(x_size), len(y_size)))\n",
    "\n",
    "for idx, x in enumerate(x_size):\n",
    "    for idy, y in enumerate(y_size):\n",
    "        HTM[idx, idy] = np.min(extrapol[x:x+w, y:y+w])\n",
    "\n",
    "HTM = cv2.resize(HTM, (xxx.shape[1], xxx.shape[0]), cv2.INTER_LINEAR)\n",
    "plt.imshow(HTM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a82749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 21\n",
    "x_size = [i for i in range(0, xxx.shape[0], w)]\n",
    "y_size = [j for j in range(0, xxx.shape[1], w)]\n",
    "HTM_hm = np.ones((len(x_size), len(y_size)))\n",
    "\n",
    "for idx, x in enumerate(x_size):\n",
    "    for idy, y in enumerate(y_size):\n",
    "        HTM_hm[idx, idy] = np.min(extrapol[x:x+w, y:y+w])\n",
    "\n",
    "HTM_hm = cv2.resize(HTM_hm, (xxx.shape[1], xxx.shape[0]), cv2.INTER_LINEAR)\n",
    "HM = HTM_hm > np.mean(HTM_hm)\n",
    "N_HM = HTM_hm < np.mean(HTM_hm)\n",
    "plt.imshow(HTM_hm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c01431",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w = 3\n",
    "x_size = [i for i in range(0, xxx.shape[0], w)]\n",
    "y_size = [j for j in range(0, xxx.shape[1], w)]\n",
    "HTM_i = np.ones((len(x_size), len(y_size)))\n",
    "k = []\n",
    "\n",
    "for i in range(xxx.shape[2]):\n",
    "    for idx, x in enumerate(x_size):\n",
    "        for idy, y in enumerate(y_size):\n",
    "            HTM_i[idx, idy] = np.min(band[x:x+w, y:y+w, i])\n",
    "\n",
    "    HTM_i = cv2.resize(HTM_i, (xxx.shape[1], xxx.shape[0]), cv2.INTER_LINEAR)\n",
    "    x_train = HTM_i[HM].reshape(-1, 1)\n",
    "    y_train = HTM_hm[HM]\n",
    "    reg = LinearRegression().fit(x_train, y_train)\n",
    "    print(reg.coef_)\n",
    "    k.append(reg.coef_)\n",
    "# plt.imshow(band)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24de02ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "BAND_i = np.ones(xxx.shape)\n",
    "\n",
    "for i in range(xxx.shape[2]):\n",
    "    BAND_i[..., i] = band[..., i] - HTM*k[1]\n",
    "    BAND_i[..., i] = BAND_i[..., i] + \\\n",
    "        np.absolute(np.mean(band[..., i][N_HM])-np.mean(BAND_i[..., i][N_HM]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0705f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(BAND_i.astype('uint8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63664e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(xxx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8af3d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1665995924.525042\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(time.time())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8621f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "TRAIN_LOGDIR = '/home/skm/SKM16/ALL_MODEL/Openland/logs'\n",
    "\n",
    "os.makedirs(TRAIN_LOGDIR, exist_ok=True)\n",
    "MODEL_SAVE_DIR = os.path.join(TRAIN_LOGDIR, \"weight\")\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc67509",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with rasterio.open('/media/skymap/Learnning/public/DA/2_GreenSpaceSing/A/T1-T12_scene_crop_by_AOI/xxx.tif', 'w', **out_meta) as r:\n",
    "#     r.write(BAND_i.transpose(2,0,1).astype('uint16'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c902a5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with rasterio.open('/media/skymap/Learnning/public/changedetection_SAR/xxxx.tif', 'w', **out_meta) as r:\n",
    "#     r.write(BAND_i.transpose(2,0,1).astype('uint8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4599b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3141ef58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4abe75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7056374",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def conv2d_bn(x,\n",
    "              filters,\n",
    "              kernel_size,\n",
    "              strides=1,\n",
    "              padding='same',\n",
    "              activation='relu',\n",
    "              use_bias=False,\n",
    "              name=None):\n",
    "\n",
    "    x = KL.Conv2D(filters,\n",
    "                  kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding=padding,\n",
    "                  use_bias=use_bias,\n",
    "                  name=name)(x)\n",
    "    if not use_bias:\n",
    "        bn_axis = 1 if K.image_data_format() == 'channels_first' else 3\n",
    "        bn_name = None if name is None else name + '_bn'\n",
    "        x = KL.BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n",
    "    if activation is not None:\n",
    "        ac_name = None if name is None else name + '_ac'\n",
    "        x = KL.Activation(activation, name=ac_name)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def inception_resnet_block(x, scale, block_type, block_idx, activation='relu'):\n",
    "    if block_type == 'block35':\n",
    "        branch_0 = conv2d_bn(x, 32, 1)\n",
    "        branch_1 = conv2d_bn(x, 32, 1)\n",
    "        branch_1 = conv2d_bn(branch_1, 32, 3)\n",
    "        branch_2 = conv2d_bn(x, 32, 1)\n",
    "        branch_2 = conv2d_bn(branch_2, 48, 3)\n",
    "        branch_2 = conv2d_bn(branch_2, 64, 3)\n",
    "        branches = [branch_0, branch_1, branch_2]\n",
    "    elif block_type == 'block17':\n",
    "        branch_0 = conv2d_bn(x, 192, 1)\n",
    "        branch_1 = conv2d_bn(x, 128, 1)\n",
    "        branch_1 = conv2d_bn(branch_1, 160, [1, 7])\n",
    "        branch_1 = conv2d_bn(branch_1, 192, [7, 1])\n",
    "        branches = [branch_0, branch_1]\n",
    "    elif block_type == 'block8':\n",
    "        branch_0 = conv2d_bn(x, 192, 1)\n",
    "        branch_1 = conv2d_bn(x, 192, 1)\n",
    "        branch_1 = conv2d_bn(branch_1, 224, [1, 3])\n",
    "        branch_1 = conv2d_bn(branch_1, 256, [3, 1])\n",
    "        branches = [branch_0, branch_1]\n",
    "    else:\n",
    "        raise ValueError('Unknown Inception-ResNet block type. '\n",
    "                         'Expects \"block35\", \"block17\" or \"block8\", '\n",
    "                         'but got: ' + str(block_type))\n",
    "\n",
    "    block_name = block_type + '_' + str(block_idx)\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else 3\n",
    "    mixed = KL.Concatenate(\n",
    "        axis=channel_axis, name=block_name + '_mixed')(branches)\n",
    "    up = conv2d_bn(mixed,\n",
    "                   K.int_shape(x)[channel_axis],\n",
    "                   1,\n",
    "                   activation=None,\n",
    "                   use_bias=True,\n",
    "                   name=block_name + '_conv')\n",
    "\n",
    "    x = KL.Lambda(lambda inputs, scale: inputs[0] + inputs[1] * scale,\n",
    "                  output_shape=K.int_shape(x)[1:],\n",
    "                  arguments={'scale': scale},\n",
    "                  name=block_name)([x, up])\n",
    "    if activation is not None:\n",
    "        x = KL.Activation(activation, name=block_name + '_ac')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def InceptionResNetV2():\n",
    "    img_input = KL.Input(shape=[512, 512, 3], name=\"input_image\")\n",
    "    ggg = []\n",
    "    # Stem block: 35 x 35 x 192\n",
    "    x = conv2d_bn(img_input, 32, 3, strides=2, padding='valid')\n",
    "    x = conv2d_bn(x, 32, 3, padding='valid')\n",
    "    x = conv2d_bn(x, 64, 3)\n",
    "    x = KL.MaxPooling2D(3, strides=2)(x)\n",
    "    x = conv2d_bn(x, 80, 1, padding='valid')\n",
    "    x = conv2d_bn(x, 192, 3, padding='valid')\n",
    "    x = KL.MaxPooling2D(3, strides=2)(x)\n",
    "    ggg.append(x)\n",
    "    # Mixed 5b (Inception-A block): 35 x 35 x 320\n",
    "    branch_0 = conv2d_bn(x, 96, 1)\n",
    "    branch_1 = conv2d_bn(x, 48, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 64, 5)\n",
    "    branch_2 = conv2d_bn(x, 64, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 96, 3)\n",
    "    branch_2 = conv2d_bn(branch_2, 96, 3)\n",
    "    branch_pool = KL.AveragePooling2D(3, strides=1, padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 64, 1)\n",
    "    branches = [branch_0, branch_1, branch_2, branch_pool]\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else 3\n",
    "    x = KL.Concatenate(axis=channel_axis, name='mixed_5b')(branches)\n",
    "\n",
    "    # 10x block35 (Inception-ResNet-A block): 35 x 35 x 320\n",
    "    for block_idx in range(1, 11):\n",
    "        x = inception_resnet_block(x,\n",
    "                                   scale=0.17,\n",
    "                                   block_type='block35',\n",
    "                                   block_idx=block_idx)\n",
    "    ggg.append(x)\n",
    "    # Mixed 6a (Reduction-A block): 17 x 17 x 1088\n",
    "    branch_0 = conv2d_bn(x, 384, 3, strides=2, padding='valid')\n",
    "    branch_1 = conv2d_bn(x, 256, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 256, 3)\n",
    "    branch_1 = conv2d_bn(branch_1, 384, 3, strides=2, padding='valid')\n",
    "    branch_pool = KL.MaxPooling2D(3, strides=2, padding='valid')(x)\n",
    "    branches = [branch_0, branch_1, branch_pool]\n",
    "    x = KL.Concatenate(axis=channel_axis, name='mixed_6a')(branches)\n",
    "\n",
    "    # 20x block17 (Inception-ResNet-B block): 17 x 17 x 1088\n",
    "    for block_idx in range(1, 21):\n",
    "        x = inception_resnet_block(x,\n",
    "                                   scale=0.1,\n",
    "                                   block_type='block17',\n",
    "                                   block_idx=block_idx)\n",
    "    ggg.append(x)\n",
    "    # Mixed 7a (Reduction-B block): 8 x 8 x 2080\n",
    "    branch_0 = conv2d_bn(x, 256, 1)\n",
    "    branch_0 = conv2d_bn(branch_0, 384, 3, strides=2, padding='valid')\n",
    "    branch_1 = conv2d_bn(x, 256, 1)\n",
    "    branch_1 = conv2d_bn(branch_1, 288, 3, strides=2, padding='valid')\n",
    "    branch_2 = conv2d_bn(x, 256, 1)\n",
    "    branch_2 = conv2d_bn(branch_2, 288, 3)\n",
    "    branch_2 = conv2d_bn(branch_2, 320, 3, strides=2, padding='valid')\n",
    "    branch_pool = KL.MaxPooling2D(3, strides=2, padding='valid')(x)\n",
    "    branches = [branch_0, branch_1, branch_2, branch_pool]\n",
    "    x = KL.Concatenate(axis=channel_axis, name='mixed_7a')(branches)\n",
    "    # 10x block8 (Inception-ResNet-C block): 8 x 8 x 2080\n",
    "    for block_idx in range(1, 10):\n",
    "        x = inception_resnet_block(x,\n",
    "                                   scale=0.2,\n",
    "                                   block_type='block8',\n",
    "                                   block_idx=block_idx)\n",
    "\n",
    "    x = inception_resnet_block(x,\n",
    "                               scale=1.,\n",
    "                               activation=None,\n",
    "                               block_type='block8',\n",
    "                               block_idx=10)\n",
    "    # Final convolution block: 8 x 8 x 1536\n",
    "    x = conv2d_bn(x, 1536, 1, name='conv_7b')\n",
    "    ggg.append(x)\n",
    "    return ggg\n",
    "\n",
    "\n",
    "a = InceptionResNetV2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f86c17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1cf598",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "\n",
    "\n",
    "def conv2d_bn(x,\n",
    "              filters,\n",
    "              num_row,\n",
    "              num_col,\n",
    "              padding='same',\n",
    "              strides=(1, 1),\n",
    "              name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        bn_axis = 1\n",
    "    else:\n",
    "        bn_axis = 3\n",
    "    x = KL.Conv2D(\n",
    "        filters, (num_row, num_col),\n",
    "        strides=strides,\n",
    "        padding=padding,\n",
    "        use_bias=False,\n",
    "        name=conv_name)(x)\n",
    "    x = KL.BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n",
    "    x = KL.Activation('relu', name=name)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def InceptionV3(include_top=True,\n",
    "                weights='imagenet',\n",
    "                input_tensor=None,\n",
    "                input_shape=None,\n",
    "                pooling=None,\n",
    "                classes=1000):\n",
    "\n",
    "    x = conv2d_bn(img_input, 32, 3, 3, strides=(2, 2), padding='valid')\n",
    "    x = conv2d_bn(x, 32, 3, 3, padding='valid')\n",
    "    x = conv2d_bn(x, 64, 3, 3)\n",
    "    x = KL.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = conv2d_bn(x, 80, 1, 1, padding='valid')\n",
    "    x = conv2d_bn(x, 192, 3, 3, padding='valid')\n",
    "    x = KL.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    # mixed 0, 1, 2: 35 x 35 x 256\n",
    "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
    "\n",
    "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
    "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "    branch_pool = KL.AveragePooling2D(\n",
    "        (3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n",
    "    x = KL.concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed0')\n",
    "\n",
    "    # mixed 1: 35 x 35 x 256\n",
    "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
    "\n",
    "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
    "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "    branch_pool = KL.AveragePooling2D(\n",
    "        (3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n",
    "    x = KL.concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed1')\n",
    "\n",
    "    # mixed 2: 35 x 35 x 256\n",
    "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
    "\n",
    "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
    "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "\n",
    "    branch_pool = KL.AveragePooling2D(\n",
    "        (3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n",
    "    x = KL.concatenate(\n",
    "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed2')\n",
    "\n",
    "    # mixed 3: 17 x 17 x 768\n",
    "    branch3x3 = conv2d_bn(x, 384, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(\n",
    "        branch3x3dbl, 96, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_pool = KL.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = KL.concatenate(\n",
    "        [branch3x3, branch3x3dbl, branch_pool], axis=channel_axis, name='mixed3')\n",
    "\n",
    "    # mixed 4: 17 x 17 x 768\n",
    "    branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "    branch7x7 = conv2d_bn(x, 128, 1, 1)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 128, 1, 7)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
    "\n",
    "    branch7x7dbl = conv2d_bn(x, 128, 1, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 1, 7)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "\n",
    "    branch_pool = KL.AveragePooling2D(\n",
    "        (3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "    x = KL.concatenate(\n",
    "        [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed4')\n",
    "\n",
    "    # mixed 5, 6: 17 x 17 x 768\n",
    "    for i in range(2):\n",
    "        branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "        branch7x7 = conv2d_bn(x, 160, 1, 1)\n",
    "        branch7x7 = conv2d_bn(branch7x7, 160, 1, 7)\n",
    "        branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
    "\n",
    "        branch7x7dbl = conv2d_bn(x, 160, 1, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 1, 7)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n",
    "        branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "\n",
    "        branch_pool = KL.AveragePooling2D(\n",
    "            (3, 3), strides=(1, 1), padding='same')(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "        x = KL.concatenate(\n",
    "            [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "            axis=channel_axis,\n",
    "            name='mixed' + str(5 + i))\n",
    "\n",
    "    # mixed 7: 17 x 17 x 768\n",
    "    branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
    "\n",
    "    branch7x7 = conv2d_bn(x, 192, 1, 1)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 192, 1, 7)\n",
    "    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
    "\n",
    "    branch7x7dbl = conv2d_bn(x, 192, 1, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
    "\n",
    "    branch_pool = KL.AveragePooling2D(\n",
    "        (3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "    x = layers.concatenate(\n",
    "        [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
    "        axis=channel_axis,\n",
    "        name='mixed7')\n",
    "\n",
    "    # mixed 8: 8 x 8 x 1280\n",
    "    branch3x3 = conv2d_bn(x, 192, 1, 1)\n",
    "    branch3x3 = conv2d_bn(branch3x3, 320, 3, 3,\n",
    "                          strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch7x7x3 = conv2d_bn(x, 192, 1, 1)\n",
    "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 1, 7)\n",
    "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 7, 1)\n",
    "    branch7x7x3 = conv2d_bn(\n",
    "        branch7x7x3, 192, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_pool = KL.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = KL.concatenate(\n",
    "        [branch3x3, branch7x7x3, branch_pool], axis=channel_axis, name='mixed8')\n",
    "\n",
    "    # mixed 9: 8 x 8 x 2048\n",
    "    for i in range(2):\n",
    "        branch1x1 = conv2d_bn(x, 320, 1, 1)\n",
    "\n",
    "        branch3x3 = conv2d_bn(x, 384, 1, 1)\n",
    "        branch3x3_1 = conv2d_bn(branch3x3, 384, 1, 3)\n",
    "        branch3x3_2 = conv2d_bn(branch3x3, 384, 3, 1)\n",
    "        branch3x3 = KL.concatenate(\n",
    "            [branch3x3_1, branch3x3_2], axis=channel_axis, name='mixed9_' + str(i))\n",
    "\n",
    "        branch3x3dbl = conv2d_bn(x, 448, 1, 1)\n",
    "        branch3x3dbl = conv2d_bn(branch3x3dbl, 384, 3, 3)\n",
    "        branch3x3dbl_1 = conv2d_bn(branch3x3dbl, 384, 1, 3)\n",
    "        branch3x3dbl_2 = conv2d_bn(branch3x3dbl, 384, 3, 1)\n",
    "        branch3x3dbl = KL.concatenate(\n",
    "            [branch3x3dbl_1, branch3x3dbl_2], axis=channel_axis)\n",
    "\n",
    "        branch_pool = KL.AveragePooling2D(\n",
    "            (3, 3), strides=(1, 1), padding='same')(x)\n",
    "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
    "        x = KL.concatenate(\n",
    "            [branch1x1, branch3x3, branch3x3dbl, branch_pool],\n",
    "            axis=channel_axis,\n",
    "            name='mixed' + str(9 + i))\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "        x = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='inception_v3')\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image data format convention '\n",
    "                              '(`image_data_format=\"channels_first\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_data_format=\"channels_last\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "        if include_top:\n",
    "            weights_path = get_file(\n",
    "                'inception_v3_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                WEIGHTS_PATH,\n",
    "                cache_subdir='models',\n",
    "                md5_hash='9a0d58056eeedaa3f26cb7ebd46da564')\n",
    "        else:\n",
    "            weights_path = get_file(\n",
    "                'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                WEIGHTS_PATH_NO_TOP,\n",
    "                cache_subdir='models',\n",
    "                md5_hash='bcbd6486424b2319ff4ef7d526e38f63')\n",
    "        model.load_weights(weights_path)\n",
    "        if K.backend() == 'theano':\n",
    "            convert_all_kernels_in_model(model)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed275130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c380bee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8208bd85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331516e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import cv2\n",
    "import numpy as np\n",
    "import timeit\n",
    "from skimage.morphology import skeletonize, remove_small_holes, thin\n",
    "from math import sqrt\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "image = '/media/skymap/Learnning/public/farm-bing18/Data/maskkkkkkkkkkkkkkkkkkkkk/box_28.tif'\n",
    "\n",
    "print(image)\n",
    "with rasterio.open(image) as inds:\n",
    "    data = inds.read()\n",
    "    out_meta = inds.meta\n",
    "    transform = inds.transform\n",
    "    projstr = inds.crs.to_string()\n",
    "\n",
    "    end = time.time()\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "    img = cv2.dilate(data[0], kernel, iterations=1)\n",
    "    img = remove_small_holes(img.astype(bool), area_threshold=77)\n",
    "#     skeleton = skeletonize(img)\n",
    "    print(time.time()-end)\n",
    "\n",
    "out_img_img = '/media/skymap/Learnning/public/farm-bing18/Data/boxx.tif'\n",
    "with rasterio.open(out_img_img, \"w\", **out_meta, compress='lzw') as dest:\n",
    "    dest.write(img[np.newaxis, ...].astype(np.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df168b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d222c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ba8ac4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import rasterio\n",
    "\n",
    "path = r\"/media/skymap/Learnning/public/changedetection_SAR/pipeline/Raw/Costa Rica S1A  Dsc 24-February-2021.tif\"\n",
    "with rasterio.open(path) as r:\n",
    "    data = r.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be80045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "t1_test = copy.deepcopy(data)\n",
    "t1_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d333fab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "t1_test = np.reshape(t1_test, (-1, t1_test.shape[-1]))\n",
    "t1_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b07ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "mat = scipy.io.loadmat(\n",
    "    \"/media/skymap/Learnning/public/changedetection_SAR/pipeline/Raw/Cross-sensor-Bastrop-data.mat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0308c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.array(mat[\"ROI_1\"], dtype=bool)\n",
    "t1_test = np.array(mat[\"t1_L5\"], dtype=float)\n",
    "t2_test = np.array(mat[\"t2_L5\"], dtype=float)\n",
    "print(t1_test.shape)\n",
    "print(t2_test.shape)\n",
    "t1_test = np.reshape(t1_test, (-1, t1_test.shape[-1]))\n",
    "t2_test = np.reshape(t2_test, (-1, t2_test.shape[-1]))\n",
    "idx = np.where(mask)[0]\n",
    "t1 = t1_test[idx.transpose()]\n",
    "t2 = t2_test[idx.transpose()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c3b29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.gaussian_process as gp\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import sys\n",
    "from sklearn.ensemble import RandomForestRegressor as rf\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "mat = scipy.io.loadmat(\n",
    "    \"/media/skymap/Learnning/public/changedetection_SAR/pipeline/Raw/Cross-sensor-Bastrop-data.mat\")\n",
    "mask = np.array(mat[\"ROI_1\"], dtype=bool)\n",
    "t1_test = np.array(mat[\"t1_L5\"], dtype=float)\n",
    "t1_test = np.reshape(t1_test, (-1, t1_test.shape[-1]))\n",
    "t2_test = np.array(mat[\"t2_L5\"], dtype=float)\n",
    "t2_test = np.reshape(t2_test, (-1, t2_test.shape[-1]))\n",
    "idx = np.where(mask)[0]\n",
    "t1 = t1_test[idx.transpose()]\n",
    "t2 = t2_test[idx.transpose()]\n",
    "\n",
    "del mat\n",
    "\n",
    "regr = rf(\n",
    "    n_estimators=256,\n",
    "    max_features=\"sqrt\",\n",
    "    oob_score=True,\n",
    "    n_jobs=-1,\n",
    "    min_samples_leaf=10,\n",
    ")\n",
    "\n",
    "regr.fit(t1, t2)\n",
    "t1_hat = regr.predict(t1_test)\n",
    "\n",
    "regr.fit(t2, t1)\n",
    "t2_hat = regr.predict(t2_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6ce82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = np.linalg.norm(t2_hat - t1_test, axis=1)\n",
    "print(d1.shape)\n",
    "outliers = d1 > np.nanmean(d1) + 3 * np.nanstd(d1)\n",
    "d1[outliers] = np.nanmax(d1[outliers == 0])\n",
    "d1 = d1 / np.nanmax(d1)\n",
    "d2 = np.linalg.norm(t1_hat - t2_test, axis=1)\n",
    "outliers = d2 > np.nanmean(d2) + 3 * np.nanstd(d2)\n",
    "d2[outliers] = np.nanmax(d2[outliers == 0])\n",
    "d2 = d2 / np.nanmax(d2)\n",
    "d = d1 + d2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7266974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('geoai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "1bff4993b5c6f9c50422f70b2dd5a13ec694dfd7dde205c6b1afc92728df224a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
