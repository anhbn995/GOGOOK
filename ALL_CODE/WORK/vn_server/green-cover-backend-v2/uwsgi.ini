[uwsgi]

chdir           = /home/geoai/api.eofactory.ai
wsgi-file       = app.wsgi
uid             = geoai
gid		= geoai

logger          = file:/home/geoai/uwsgi/uwsgi-geoai-error.log
req-logger      = file:/home/geoai/uwsgi/uwsgi-geoai.log
home            = /home/geoai/anaconda3/envs/geoai
# process-related settings
# master
master          = true
# maximum number of worker processes
# processes       = 16
# the socket (use the full path to be safe
socket          = /home/geoai/uwsgi/geoai.sock
# ... with appropriate permissions - may be needed
chmod-socket    = 666
enable-threads  = true
wsgi-disable-file-wrapper = true

die-on-term = true
need-app = true
single-interpreter = true
# clear environment on exit
vacuum          = true
harakiri = 43200                     ; forcefully kill workers after 12 hours
py-callos-afterfork = true           ; allow workers to trap signals
max-requests = 1000                  ; Restart workers after this many requests
max-worker-lifetime = 36000          ; Restart workers after this many seconds
reload-on-rss = 24000                 ; Restart workers after this much resident memory
worker-reload-mercy = 60             ; How long to wait before forcefully killing workers

cheaper-algo = busyness
processes = 128                      ; Maximum number of workers allowed
cheaper = 8                          ; Minimum number of workers allowed
cheaper-initial = 16                 ; Workers created at startup
cheaper-overload = 1                 ; Length of a cycle in seconds
cheaper-step = 16                    ; How many workers to spawn at a time

cheaper-busyness-multiplier = 30     ; How many cycles to wait before killing workers
cheaper-busyness-min = 20            ; Below this threshold, kill workers (if stable for multiplier cycles)
cheaper-busyness-max = 70            ; Above this threshold, spawn new workers
cheaper-busyness-backlog-alert = 16  ; Spawn emergency workers if more than this many requests are waiting in the queue
cheaper-busyness-backlog-step = 2    ; How many emergency workers to create if there are too many requests in the queue