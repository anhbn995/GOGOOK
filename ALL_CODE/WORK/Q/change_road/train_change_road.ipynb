{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "394c553c-b311-439b-934c-9e3cdd738b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b48bd20-ba2a-40a2-88e3-c6ef48fd8872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import fiona\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import rasterio.mask\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from models import loss\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras import backend as K\n",
    "from models.metrics import iou, dice_coef\n",
    "from models.callback.save_best import SavebestweightsandEarlyStopping\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cee9ca1d-9791-4378-95ca-d7cf7fa485cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_feature, filters, kernel_size=(1,1), strides=1, padding='same', use_relu=False):\n",
    "    x = tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding,\n",
    "                                        kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')(input_feature)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    if use_relu:\n",
    "        x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def depthwise_conv_block(input_feature, kernel_size, strides=1, padding='same', r=1):\n",
    "    x = tf.keras.layers.DepthwiseConv2D(kernel_size=kernel_size, strides=strides, padding=padding, \n",
    "                                        dilation_rate=r, depthwise_initializer='he_normal',\n",
    "                                        use_bias=True, bias_initializer='zeros')(input_feature)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def channel_attention_block(input_feature, ratio=8):\n",
    "    channel = input_feature.shape[-1]\n",
    "\n",
    "    shared_layer_one = tf.keras.layers.Dense(channel//ratio, activation='relu', kernel_initializer='he_normal',\n",
    "                                            use_bias=True, bias_initializer='zeros')\n",
    "    shared_layer_two = tf.keras.layers.Dense(channel, activation='relu', kernel_initializer='he_normal',\n",
    "                                            use_bias=True, bias_initializer='zeros')\n",
    "    \n",
    "    avg_pool = tf.keras.layers.GlobalAveragePooling2D()(input_feature)\n",
    "    avg_pool = tf.keras.layers.Reshape((1,1,channel))(avg_pool)\n",
    "    avg_pool = shared_layer_one(avg_pool)\n",
    "    avg_pool = shared_layer_two(avg_pool)\n",
    "\n",
    "    max_pool = tf.keras.layers.GlobalMaxPooling2D()(input_feature)\n",
    "    max_pool = tf.keras.layers.Reshape((1,1,channel))(max_pool)\n",
    "    max_pool = shared_layer_one(max_pool)\n",
    "    max_pool = shared_layer_two(max_pool)\n",
    "\n",
    "    cbam_feature = tf.keras.layers.Add()([avg_pool,max_pool])\n",
    "    cbam_feature = tf.keras.layers.Activation('sigmoid')(cbam_feature)\n",
    "    return tf.keras.layers.multiply([input_feature, cbam_feature])\n",
    "\n",
    "def spatial_attention_block(input_feature):\n",
    "    kernel_size = 7\n",
    "    channel = input_feature.shape[-1]\n",
    "    cbam_feature = input_feature\n",
    "\n",
    "    avg_pool = tf.keras.layers.Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    max_pool = tf.keras.layers.Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n",
    "    concat = tf.keras.layers.Concatenate(axis=3)([avg_pool, max_pool])\n",
    "\n",
    "    cbam_feature = tf.keras.layers.Conv2D(filters = 1, kernel_size=kernel_size, strides=1, padding='same',\n",
    "                    activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(concat)\n",
    "\n",
    "    return tf.keras.layers.multiply([input_feature, cbam_feature])\n",
    "\n",
    "def cbam_block(cbam_feature, ratio=8):\n",
    "    \"\"\"Contains the implementation of Convolutional Block Attention Module(CBAM) block.\n",
    "    As described in https://arxiv.org/abs/1807.06521.\n",
    "    \"\"\"\n",
    "\n",
    "    cbam_feature = channel_attention_block(cbam_feature, ratio)\n",
    "    cbam_feature = spatial_attention_block(cbam_feature)\n",
    "    return cbam_feature\n",
    "\n",
    "def ADM_block(input_feature):\n",
    "    filters = input_feature.shape[-1]\n",
    "    x = conv_block(input_feature, filters=filters, kernel_size=(1,1), strides=1, padding='same', use_relu=True)\n",
    "    x = depthwise_conv_block(x, kernel_size=(3,3), strides=2, padding='same', r=1)\n",
    "    x = conv_block(x, filters=filters, kernel_size=(1,1), strides=1, padding='same', use_relu=False)\n",
    "    x_pool = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2)(input_feature)\n",
    "    x_concat = tf.keras.layers.concatenate([x, x_pool], axis=-1)\n",
    "    x = channel_attention_block(x_concat)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def SCBAM_block(input_feature, r=1):\n",
    "    filters = input_feature.shape[-1] // 4\n",
    "    x = conv_block(input_feature, filters=filters, kernel_size=(1,1), strides=1, padding='same', use_relu=True)\n",
    "    x = depthwise_conv_block(x, kernel_size=(3,3), strides=1, padding='same', r=r)\n",
    "    x = conv_block(x, filters=filters*4, kernel_size=(1,1), strides=1, padding='same', use_relu=False)\n",
    "    x = channel_attention_block(x)\n",
    "    x_add = tf.keras.layers.Add()([x, input_feature])\n",
    "    x = tf.keras.layers.Activation('relu')(x_add)\n",
    "    return x\n",
    "\n",
    "def stack_ADM_SCBAM(input_feature):\n",
    "    x = ADM_block(input_feature)\n",
    "    x = SCBAM_block(x)\n",
    "    x = SCBAM_block(x)\n",
    "    return x\n",
    "\n",
    "def HDC_block(input_feature, rate_list):\n",
    "    x = input_feature\n",
    "    for i in rate_list:\n",
    "        x = SCBAM_block(x, r=i)\n",
    "    return x\n",
    "\n",
    "def multi_HDC_block(input_feature, stage1=[1,2,5,9,1,2,5,9], stage2=[1,2,5,9], stage3=[1,2], stage4=[1]):\n",
    "    x1 = HDC_block(input_feature, rate_list=stage1)\n",
    "    x2 = HDC_block(x1, rate_list=stage2)\n",
    "    x3 = HDC_block(x2, rate_list=stage3)\n",
    "    x4 = HDC_block(x3, rate_list=stage4)\n",
    "    x_concat = tf.keras.layers.concatenate([x1,x2,x3,x4,input_feature])\n",
    "    return x_concat\n",
    "\n",
    "def DUC_block(input_feature, out_channles=1, upscale=8):\n",
    "    out_channles = out_channles * (upscale ** 2)\n",
    "    x = tf.keras.layers.Conv2D(filters=out_channles, kernel_size=(1,1), strides=1, padding='same', use_bias=False)(input_feature)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    outputs = tf.nn.depth_to_space(x, upscale)\n",
    "    return outputs\n",
    "\n",
    "def MHA_Net(input_shape, filters=64, num_ADM_SCBAM=3):\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    x = conv_block(inputs, filters=filters, kernel_size=(3, 3))\n",
    "    x = conv_block(x, filters=filters*2, kernel_size=(3, 3))\n",
    "\n",
    "    for _ in range(num_ADM_SCBAM):   \n",
    "        x = stack_ADM_SCBAM(x)\n",
    "\n",
    "    x = multi_HDC_block(x)\n",
    "    x = channel_attention_block(x)\n",
    "    x = conv_block(x, filters=filters*16, kernel_size=(1,1))\n",
    "    x = tf.keras.layers.Conv2D(filters=filters, kernel_size=(1,1), strides=1, padding='same',\n",
    "                                kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros')(x)\n",
    "    x = DUC_block(x)\n",
    "    x = tf.keras.layers.Activation('sigmoid')(x)\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27faa25c-5c73-4a79-9351-08cc59f4c909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:validation = 2035:509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 17:10:58.265207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4998 MB memory:  -> device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:05:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "from preprocess.prepare_dataset import data_gen\n",
    "\n",
    "out_path = '/home/quyet/DATA_ML/Projects/change_detection/new_video/tarmac/bonus_negative'\n",
    "overlap_mask = os.path.join(out_path, 'mask_cut_crop')\n",
    "train_dataset, valid_dataset, _, _ = data_gen(os.path.join(overlap_mask, '*.tif'), img_size=512, \n",
    "                                                            batch_size=1, N_CLASSES=1, numband=3, \n",
    "                                                            split_ratios=0.8, test_data=False, multi=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9bfd4e-0901-4314-8044-62bea0dcf258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init metric function\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.0003.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 17:11:38.667683: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100\n",
      "2022-07-21 17:11:38.982682: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-07-21 17:11:40.056078: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 798.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-21 17:11:40.076580: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.11GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-21 17:11:40.183458: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-21 17:11:40.188508: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-21 17:11:40.206243: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 798.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2035/Unknown - 1718s 825ms/step - loss: 0.3778 - precision: 0.9900 - recall: 0.9449 - dice_coef: 0.9257 - iou: 0.8627\n",
      "Save best train weights.\n",
      "Save best val weights.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 17:44:08.433960: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 786432000 exceeds 10% of free system memory.\n",
      "2022-07-21 17:44:09.611860: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 786432000 exceeds 10% of free system memory.\n",
      "2022-07-21 17:44:10.880899: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1258291200 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2035/2035 [==============================] - 1988s 958ms/step - loss: 0.3778 - precision: 0.9900 - recall: 0.9449 - dice_coef: 0.9257 - iou: 0.8627 - val_loss: 0.4036 - val_precision: 0.9990 - val_recall: 0.8407 - val_dice_coef: 0.9084 - val_iou: 0.8410 - lr: 3.0000e-04\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.00027.\n",
      "Epoch 2/100\n",
      " 527/2035 [======>.......................] - ETA: 21:08 - loss: 0.3410 - precision: 0.9892 - recall: 0.9557 - dice_coef: 0.9376 - iou: 0.8837"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 17:51:37.238085: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 100.03MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 528/2035 [======>.......................] - ETA: 21:07 - loss: 0.3410 - precision: 0.9893 - recall: 0.9553 - dice_coef: 0.9375 - iou: 0.8836"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 17:51:38.080189: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 100.03MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 529/2035 [======>.......................] - ETA: 21:06 - loss: 0.3408 - precision: 0.9893 - recall: 0.9553 - dice_coef: 0.9376 - iou: 0.8837"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 17:51:38.915741: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 100.03MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 530/2035 [======>.......................] - ETA: 21:06 - loss: 0.3406 - precision: 0.9893 - recall: 0.9553 - dice_coef: 0.9376 - iou: 0.8838"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 17:51:39.767510: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 100.03MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 531/2035 [======>.......................] - ETA: 21:05 - loss: 0.3407 - precision: 0.9893 - recall: 0.9554 - dice_coef: 0.9376 - iou: 0.8838"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 17:51:40.615650: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 100.03MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2035/2035 [==============================] - ETA: 0s - loss: 0.3242 - precision: 0.9896 - recall: 0.9643 - dice_coef: 0.9426 - iou: 0.8928\n",
      "Save best train weights.\n",
      "Save best val weights.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 18:16:55.347585: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 786432000 exceeds 10% of free system memory.\n",
      "2022-07-21 18:16:56.543902: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 786432000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2035/2035 [==============================] - 1967s 966ms/step - loss: 0.3242 - precision: 0.9896 - recall: 0.9643 - dice_coef: 0.9426 - iou: 0.8928 - val_loss: 0.2895 - val_precision: 0.9938 - val_recall: 0.9665 - val_dice_coef: 0.9498 - val_iou: 0.9069 - lr: 2.7000e-04\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.000243.\n",
      "Epoch 3/100\n",
      " 118/2035 [>.............................] - ETA: 27:23 - loss: 0.3114 - precision: 0.9815 - recall: 0.9716 - dice_coef: 0.9458 - iou: 0.8992"
     ]
    }
   ],
   "source": [
    "model_name = 'mhanet'\n",
    "mission = 'change_road'\n",
    "img_size = 512\n",
    "num_bands = 3\n",
    "num_class = 1 \n",
    "batch_size = 1\n",
    "\n",
    "def lr_decay(epoch):\n",
    "    initial_learningrate=3e-4\n",
    "    if epoch < 1:\n",
    "        return initial_learningrate\n",
    "    else:\n",
    "        return initial_learningrate * 0.9 ** (epoch)\n",
    "\n",
    "if batch_size >1:\n",
    "    val_batch_size = int(batch_size/2)\n",
    "else:\n",
    "    val_batch_size = batch_size\n",
    "    \n",
    "print(\"Init metric function\")\n",
    "if num_class==1:\n",
    "    recall = tf.keras.metrics.Recall()\n",
    "    precision = tf.keras.metrics.Precision()\n",
    "    model_metrics = [precision,\n",
    "                     recall, \n",
    "                     dice_coef,\n",
    "                     iou, \n",
    "                     # tf.keras.metrics.BinaryAccuracy(threshold=0.5)\n",
    "                    ]\n",
    "else:\n",
    "    recall = tf.keras.metrics.Recall()\n",
    "    precision = tf.keras.metrics.Precision()\n",
    "    accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "    model_metrics = [precision, recall, dice_coef, iou, accuracy]\n",
    "\n",
    "root_dir = os.path.dirname(sys.path[0])\n",
    "data_path = os.path.join(os.path.join(root_dir, 'data', mission))\n",
    "checkpoint_filepath = os.path.join(root_dir, 'logs', mission, 'tmp')\n",
    "log_dir = os.path.join(root_dir, 'logs', mission, 'graph')\n",
    "weights_path = os.path.join(root_dir, 'weights', '%s'%(model_name), model_name+'_'+mission+'_'+str(img_size)+'_'+str(num_class)+'class.h5')\n",
    "patience = 10\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only= True, \n",
    "                                                                monitor='val_loss', mode='min', save_best_only=True)\n",
    "model_lrscheduler_callback = tf.keras.callbacks.LearningRateScheduler(lr_decay, verbose=1)\n",
    "model_lrreduce_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=patience, min_lr=1e-7, verbose=1)\n",
    "model_earlystopping_callback = SavebestweightsandEarlyStopping(patience=patience, weights_path=weights_path)\n",
    "model_endtrainnan_callback = tf.keras.callbacks.TerminateOnNaN()\n",
    "model_tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=True)\n",
    "model_callbacks = [model_checkpoint_callback, model_lrscheduler_callback,\n",
    "                    model_lrreduce_callback, model_earlystopping_callback,\n",
    "                    model_tensorboard_callback,]\n",
    "\n",
    "model = MHA_Net((img_size,img_size,num_bands))\n",
    "\n",
    "loss_func = loss.hybrid_loss\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer = optimizer, loss = loss_func,\n",
    "             metrics = model_metrics\n",
    "             )\n",
    "\n",
    "model.load_weights('/home/quyet/DATA_ML/WorkSpace/segmentation/weights/mhanet/mhanet_change_road_512_1class_train.h5')\n",
    "history_train = model.fit(train_dataset, batch_size=batch_size, epochs=100, verbose=1, \n",
    "                      callbacks=model_callbacks, validation_data=valid_dataset, \n",
    "                      validation_batch_size=val_batch_size, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "251eaa21-9ab8-405b-937a-04601712a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# from osgeo import gdal\n",
    "# from postprocess.convert_tif import dilation_obj, remove_small_items, write_image\n",
    "\n",
    "# def get_im_by_coord(org_im, start_x, start_y,num_band, padding, crop_size, input_size):\n",
    "#     startx = start_x-padding\n",
    "#     endx = start_x+crop_size+padding\n",
    "#     starty = start_y - padding\n",
    "#     endy = start_y+crop_size+padding\n",
    "#     result=[]\n",
    "#     img = org_im[starty:endy, startx:endx]\n",
    "#     img = img.swapaxes(2,1).swapaxes(1,0)\n",
    "#     for chan_i in range(num_band):\n",
    "#         result.append(cv2.resize(img[chan_i],(input_size, input_size), interpolation = cv2.INTER_CUBIC))\n",
    "#     return np.array(result).swapaxes(0,1).swapaxes(1,2)\n",
    "\n",
    "# def get_img_coords(w, h, padding, crop_size):\n",
    "#     new_w = w + 2*padding\n",
    "#     new_h = h + 2*padding\n",
    "#     cut_w = list(range(padding, new_w - padding, crop_size))\n",
    "#     cut_h = list(range(padding, new_h - padding, crop_size))\n",
    "\n",
    "#     list_hight = []\n",
    "#     list_weight = []\n",
    "#     for i in cut_h:\n",
    "#         if i < new_h - padding - crop_size:\n",
    "#             list_hight.append(i)\n",
    "#     list_hight.append(new_h-crop_size-padding)\n",
    "\n",
    "#     for i in cut_w:\n",
    "#         if i < new_w - crop_size - padding:\n",
    "#             list_weight.append(i)\n",
    "#     list_weight.append(new_w-crop_size-padding)\n",
    "\n",
    "#     img_coords = []\n",
    "#     for i in list_weight:\n",
    "#         for j in list_hight:\n",
    "#             img_coords.append([i, j])\n",
    "#     return img_coords\n",
    "\n",
    "# def padded_for_org_img(values, num_band, padding):\n",
    "#     padded_org_im = []\n",
    "#     for i in range(num_band):\n",
    "#         band = np.pad(values[i], padding, mode='reflect')\n",
    "#         padded_org_im.append(band)\n",
    "\n",
    "#     values = np.array(padded_org_im).swapaxes(0,1).swapaxes(1,2)\n",
    "#     # print(values.shape)\n",
    "#     del padded_org_im\n",
    "#     return values\n",
    "\n",
    "# def predict(model, values, img_coords, num_band, h, w, padding, crop_size, \n",
    "#             input_size, batch_size, thresh_hold, choose_stage):\n",
    "#     cut_imgs = []\n",
    "#     for i in range(len(img_coords)):\n",
    "#         im = get_im_by_coord(values, img_coords[i][0], img_coords[i][1],\n",
    "#                             num_band,padding, crop_size, input_size)\n",
    "#         cut_imgs.append(im)\n",
    "\n",
    "#     a = list(range(0, len(cut_imgs), batch_size))\n",
    "\n",
    "#     if a[len(a)-1] != len(cut_imgs):\n",
    "#         a[len(a)-1] = len(cut_imgs)\n",
    "\n",
    "#     y_pred = []\n",
    "#     for i in range(len(a)-1):\n",
    "#         x_batch = []\n",
    "#         x_batch = np.array(cut_imgs[a[i]:a[i+1]])\n",
    "#         # print(x_batch.shape)\n",
    "#         img_edge = []\n",
    "#         # for img_x in x_batch:\n",
    "#         #     lab_batch = color.rgb2lab(img_x)  \n",
    "#             # img_edge.append(cv2.Canny(np.asarray(np.uint8(lab_batch)),0,0)[..., np.newaxis])\n",
    "#         # print(img_edge.shape)\n",
    "#         # img_edge = np.array(img_edge)\n",
    "        \n",
    "#         # print(x_batch.shape, img_edge.shape)\n",
    "#         # y_batch = model.predict((x_batch/255, img_edge/255))\n",
    "#         y_batch = model.predict(x_batch/255)\n",
    "#         if len(model.outputs)>1:\n",
    "#             y_batch = y_batch[choose_stage]\n",
    "#         mutilabel = False\n",
    "#         if y_batch.shape[-1]>=2:\n",
    "#             mutilabel = True\n",
    "#             y_batch = np.argmax(y_batch, axis=-1)\n",
    "#         # print(np.unique(y_batch), y_batch.shape)\n",
    "            \n",
    "#         y_pred.extend(y_batch)\n",
    "#     big_mask = np.zeros((h, w)).astype(np.float16)\n",
    "#     for i in range(len(cut_imgs)):\n",
    "#         true_mask = y_pred[i].reshape((input_size,input_size))\n",
    "#         if not mutilabel:\n",
    "#             true_mask = (true_mask>thresh_hold).astype(np.uint8)\n",
    "#             true_mask = (cv2.resize(true_mask,(input_size, input_size), interpolation = cv2.INTER_CUBIC)>thresh_hold).astype(np.uint8)\n",
    "#             # true_mask = true_mask.astype(np.float16)\n",
    "#         start_x = img_coords[i][1]\n",
    "#         start_y = img_coords[i][0]\n",
    "#         big_mask[start_x-padding:start_x-padding+crop_size, start_y-padding:start_y -\n",
    "#                     padding+crop_size] = true_mask[padding:padding+crop_size, padding:padding+crop_size]\n",
    "#     del cut_imgs\n",
    "#     return big_mask\n",
    "\n",
    "# img_size = 256\n",
    "# num_band = 3\n",
    "# crop_size = 200\n",
    "# batch_size = 1\n",
    "# thresh_hold = 0.8\n",
    "# choose_stage = 0\n",
    "\n",
    "# model.load_weights('/home/quyet/DATA_ML/WorkSpace/segmentation/weights/mhanet/mhanet_change_road_256_1class_train.h5')\n",
    "# image_path = '/home/quyet/DATA_ML/Projects/road_multi/crop/img/test.tif'\n",
    "# image_path = glob.glob('/home/quyet/DATA_ML/Projects/change_detection/new_video/tarmac/img/*.tif')\n",
    "# try: \n",
    "#     for i in tqdm(image_path):\n",
    "#         if '_result.tif' not in i:\n",
    "#             dataset = gdal.Open(i)\n",
    "#             values = dataset.ReadAsArray()[0:num_band]\n",
    "#             h,w = values.shape[1:3]    \n",
    "#             padding = int((img_size - crop_size)/2)\n",
    "#             img_coords = get_img_coords(w, h, padding, crop_size)\n",
    "#             values = padded_for_org_img(values, num_band, padding)\n",
    "#             big_mask = predict(model, values, img_coords, num_band, h, w, padding, crop_size, \n",
    "#                                 img_size, batch_size, thresh_hold, choose_stage)\n",
    "#             big_mask[big_mask==0]=2\n",
    "#             big_mask[big_mask==1]=0\n",
    "#             big_mask[big_mask==2]=1\n",
    "#             result_path = write_image(i, big_mask)\n",
    "# except:\n",
    "#     dataset = gdal.Open(image_path)\n",
    "#     values = dataset.ReadAsArray()[0:num_band]\n",
    "#     h,w = values.shape[1:3]    \n",
    "#     padding = int((img_size - crop_size)/2)\n",
    "#     img_coords = get_img_coords(w, h, padding, crop_size)\n",
    "#     values = padded_for_org_img(values, num_band, padding)\n",
    "#     big_mask = predict(model, values, img_coords, num_band, h, w, padding, crop_size, \n",
    "#                         img_size, batch_size, thresh_hold, choose_stage)\n",
    "#     big_mask[big_mask==0]=2\n",
    "#     big_mask[big_mask==1]=0\n",
    "#     big_mask[big_mask==2]=1\n",
    "#     result_path = write_image(image_path, big_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc893b9c-1ea9-4b94-8847-b5a32f334db4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
