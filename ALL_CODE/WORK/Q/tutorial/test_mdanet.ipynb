{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08475932-cf99-463b-8b86-63b050cf572f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07d8e551-2a1e-4568-9d2d-98b1b80f8992",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 08:08:58.937187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4873 MB memory:  -> device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:05:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "def conv_block(inputs, filters, kernel_size, strides, padding, use_bias):\n",
    "    x = tf.keras.layers.Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, \n",
    "                                padding = padding, use_bias = use_bias)(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def conv_block_1(inputs, filters):\n",
    "    x1 = conv_block(inputs, filters=filters, kernel_size=1, strides=1, padding='same', use_bias=True)\n",
    "    x1 = conv_block(x1, filters=filters, kernel_size=1, strides=1, padding='same', use_bias=True)\n",
    "    return x1\n",
    "\n",
    "def conv_block_3(inputs, filters):\n",
    "    x3 = conv_block(inputs, filters=filters, kernel_size=3, strides=1, padding='same', use_bias=True)\n",
    "    x3 = conv_block(x3, filters=filters, kernel_size=3, strides=1, padding='same', use_bias=True)\n",
    "    return x3\n",
    "\n",
    "def conv_block_5(inputs, filters):\n",
    "    x5 = conv_block(inputs, filters=filters, kernel_size=5, strides=1, padding='same', use_bias=True)\n",
    "    x5 = conv_block(x5, filters=filters, kernel_size=5, strides=1, padding='same', use_bias=True)\n",
    "    return x5\n",
    "\n",
    "def conv_3_1(inputs, filters):\n",
    "    x1 = conv_block_1(inputs, filters)\n",
    "    x3 = conv_block_3(inputs, filters)\n",
    "    x5 = conv_block_5(inputs, filters)\n",
    "    x = tf.keras.layers.concatenate(inputs=[x1, x3, x5], axis=-1)\n",
    "    x = tf.keras.layers.Conv2D(filters = filters, kernel_size = 1, strides = 1, \n",
    "                                padding = 'same', use_bias = True)(x)\n",
    "    return x\n",
    "\n",
    "def conv_3_1_1(inputs, filters):\n",
    "    x1 = conv_block_1(inputs, filters)\n",
    "    x3 = conv_block_3(inputs, filters)\n",
    "    x5 = conv_block_5(inputs, filters)\n",
    "    x = tf.keras.layers.concatenate(inputs=[x1, x3, x5], axis=-1)\n",
    "    x = tf.keras.layers.Conv2D(filters = filters, kernel_size = 1, strides = 1, \n",
    "                                padding = 'same', use_bias = True)(x)\n",
    "    return x\n",
    "\n",
    "def up_conv(inputs, filters ,bilinear):\n",
    "    if bilinear:\n",
    "        x = tf.keras.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(inputs)\n",
    "        x = tf.keras.Conv2D(filters=filters, kernel_size=3, strides=1, \n",
    "                            padding='same', use_bias=True)(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "    else:\n",
    "        x = tf.keras.layers.Conv2DTranspose(filters=filters, kernel_size=2, strides=2)(inputs)\n",
    "    return x\n",
    "\n",
    "\n",
    "def dualAttention(g, inputs, filters, filters_g, ratio):\n",
    "    x1 = tf.keras.layers.Conv2D(filters=filters, kernel_size=1, use_bias=True)(inputs)\n",
    "\n",
    "    avg_out = tfa.layers.AdaptiveAveragePooling2D(output_size=(1,1))(x1)\n",
    "    avg_out = tf.keras.layers.Conv2D(filters=filters//ratio, kernel_size=1, use_bias=True)(avg_out)\n",
    "    avg_out = tf.keras.layers.LeakyReLU()(avg_out)\n",
    "    avg_out = tf.keras.layers.Conv2D(filters=filters, kernel_size=1, use_bias=True)(avg_out)\n",
    "\n",
    "    max_out = tfa.layers.AdaptiveMaxPooling2D(output_size=(1,1))(x1)\n",
    "    max_out = tf.keras.layers.Conv2D(filters=filters//ratio, kernel_size=1, use_bias=True)(max_out)\n",
    "    max_out = tf.keras.layers.LeakyReLU()(max_out)\n",
    "    max_out = tf.keras.layers.Conv2D(filters=filters, kernel_size=1, use_bias=True)(max_out)\n",
    "    \n",
    "    out = avg_out + max_out\n",
    "    del avg_out, max_out\n",
    "\n",
    "    x1 = x1 * tf.keras.activations.sigmoid(out)\n",
    "\n",
    "    g1 = tf.keras.layers.Conv2D(filters=filters_g, kernel_size=1, strides=1, \n",
    "                                padding='same', use_bias=True)(g)\n",
    "    g1 = tf.keras.layers.BatchNormalization()(g1)\n",
    "    x2 = tf.keras.layers.Conv2D(filters=filters_g, kernel_size=1, strides=1, \n",
    "                                padding='same', use_bias=True)(x1)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "\n",
    "    leakyReLU = tf.keras.layers.LeakyReLU()(g1 + x2)\n",
    "    psi = tf.keras.layers.Conv2D(filters=1, kernel_size=1, strides=1, \n",
    "                                padding='same', use_bias=True)(leakyReLU)\n",
    "    psi = tf.keras.layers.BatchNormalization()(psi)\n",
    "    psi = tf.keras.activations.sigmoid(psi)\n",
    "    \n",
    "    # print(filters.shape, psi.shape)\n",
    "    return inputs * psi\n",
    "    # return avg_out\n",
    "\n",
    "def MDA_Net(input_shape=(256,256,3), filters_number= [32, 64, 128, 256, 512], output_ch=1):\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    x1 = conv_3_1(inputs, filters=filters_number[0])\n",
    "    \n",
    "    x2 = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2)(x1)\n",
    "    x2 = conv_3_1(x2, filters=filters_number[1])\n",
    "\n",
    "    x3 = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2)(x2)\n",
    "    x3 = conv_3_1(x3, filters=filters_number[2])\n",
    "\n",
    "    x4 = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2)(x3)\n",
    "    x4 = conv_3_1(x4, filters=filters_number[3])\n",
    "\n",
    "    x5 = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=2)(x4)\n",
    "    x5 = conv_3_1(x5, filters=filters_number[4])\n",
    "\n",
    "    d5 = up_conv(x5, filters=filters_number[3], bilinear=False)\n",
    "    x41 = dualAttention(d5, x4, filters=filters_number[3], filters_g=filters_number[2], ratio=2)\n",
    "    d5 = tf.keras.layers.Concatenate(axis=-1)([x41, d5])\n",
    "    d5 = conv_3_1(d5, filters=filters_number[3])\n",
    "\n",
    "    d4 = up_conv(d5, filters=filters_number[2], bilinear=False)\n",
    "    x31 = dualAttention(d4, x3, filters=filters_number[2], filters_g=filters_number[1], ratio=2)\n",
    "    d4 = tf.keras.layers.Concatenate(axis=-1)([x31, d4])\n",
    "    d4 = conv_3_1(d4, filters=filters_number[2])\n",
    "\n",
    "    d3 = up_conv(d4, filters=filters_number[1], bilinear=False)\n",
    "    x21 = dualAttention(d3, x2, filters=filters_number[1], filters_g=filters_number[0], ratio=2)\n",
    "    d3 = tf.keras.layers.Concatenate(axis=-1)([x21, d3])\n",
    "    d3 = conv_3_1(d3, filters=filters_number[1])\n",
    "\n",
    "    d2 = up_conv(d3, filters=filters_number[0], bilinear=False)\n",
    "    x11 = dualAttention(d2, x1, filters=filters_number[0], filters_g=16, ratio=2)\n",
    "    d2 = tf.keras.layers.Concatenate(axis=-1)([x11, d2])\n",
    "    d2 = conv_3_1(d2, filters=filters_number[0])\n",
    "\n",
    "    d1 = tf.keras.layers.Conv2D(filters=output_ch, kernel_size=1, strides=1, \n",
    "                                padding='same')(d2)\n",
    "    d1 = tf.keras.activations.sigmoid(d1)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=d1)\n",
    "    return model\n",
    "\n",
    "model = MDA_Net(input_shape=(256,256,3), filters_number= [32, 64, 128, 256, 512], output_ch=1)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65c76090-3029-42cd-8ed7-565f8bfd735e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:validation = 924:232\n"
     ]
    }
   ],
   "source": [
    "from preprocess.prepare_dataset import data_gen\n",
    "\n",
    "out_path = '/home/quyet/DATA_ML/Projects/road_thailand/tmp'\n",
    "overlap_mask = os.path.join(out_path, 'mask_cut_crop')\n",
    "train_dataset, valid_dataset, _, _ = data_gen(os.path.join(overlap_mask, '*.tif'), img_size=256, \n",
    "                                                            batch_size=2, N_CLASSES=1, numband=3, \n",
    "                                                            split_ratios=0.8, test_data=False, multi=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a9d27b8-343a-4285-9fd0-473671343bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init metric function\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 08:09:22.994881: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100\n",
      "2022-08-16 08:09:24.968390: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    462/Unknown - 452s 929ms/step - loss: 0.0865 - precision: 0.9686 - recall: 0.7530 - dice_coef: 0.8041 - iou: 0.6743 - binary_accuracy: 0.7581\n",
      "Save best train weights.\n",
      "Save best val weights.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 08:18:42.021242: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 786432000 exceeds 10% of free system memory.\n",
      "2022-08-16 08:18:42.704805: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 566231040 exceeds 10% of free system memory.\n",
      "2022-08-16 08:18:43.035959: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1572864000 exceeds 10% of free system memory.\n",
      "2022-08-16 08:18:45.233483: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 786432000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462/462 [==============================] - 581s 1s/step - loss: 0.0865 - precision: 0.9686 - recall: 0.7530 - dice_coef: 0.8041 - iou: 0.6743 - binary_accuracy: 0.7581 - val_loss: 0.0916 - val_precision: 0.9778 - val_recall: 0.7133 - val_dice_coef: 0.7879 - val_iou: 0.6524 - val_binary_accuracy: 0.7346 - lr: 0.0010\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "Epoch 2/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0706 - precision: 0.9761 - recall: 0.8200 - dice_coef: 0.8476 - iou: 0.7366 - binary_accuracy: 0.8226\n",
      "Save best train weights.\n",
      "Save best val weights.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 08:27:41.612045: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 786432000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "462/462 [==============================] - 539s 1s/step - loss: 0.0706 - precision: 0.9761 - recall: 0.8200 - dice_coef: 0.8476 - iou: 0.7366 - binary_accuracy: 0.8226 - val_loss: 0.0865 - val_precision: 0.9503 - val_recall: 0.9418 - val_dice_coef: 0.9006 - val_iou: 0.8206 - val_binary_accuracy: 0.9050 - lr: 9.0000e-04\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "Epoch 3/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0649 - precision: 0.9793 - recall: 0.8327 - dice_coef: 0.8601 - iou: 0.7555 - binary_accuracy: 0.8355\n",
      "Save best train weights.\n",
      "Save best val weights.\n",
      "462/462 [==============================] - 576s 1s/step - loss: 0.0649 - precision: 0.9793 - recall: 0.8327 - dice_coef: 0.8601 - iou: 0.7555 - binary_accuracy: 0.8355 - val_loss: 0.0665 - val_precision: 0.9867 - val_recall: 0.8093 - val_dice_coef: 0.8456 - val_iou: 0.7340 - val_binary_accuracy: 0.8223 - lr: 8.1000e-04\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "Epoch 4/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0611 - precision: 0.9811 - recall: 0.8349 - dice_coef: 0.8670 - iou: 0.7663 - binary_accuracy: 0.8390\n",
      "Save best train weights.\n",
      "Save best val weights.\n",
      "462/462 [==============================] - 541s 1s/step - loss: 0.0611 - precision: 0.9811 - recall: 0.8349 - dice_coef: 0.8670 - iou: 0.7663 - binary_accuracy: 0.8390 - val_loss: 0.0642 - val_precision: 0.9742 - val_recall: 0.9146 - val_dice_coef: 0.9021 - val_iou: 0.8227 - val_binary_accuracy: 0.9037 - lr: 7.2900e-04\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "Epoch 5/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0588 - precision: 0.9822 - recall: 0.8443 - dice_coef: 0.8755 - iou: 0.7795 - binary_accuracy: 0.8481\n",
      "Save best train weights.\n",
      "Save best val weights.\n",
      "462/462 [==============================] - 544s 1s/step - loss: 0.0588 - precision: 0.9822 - recall: 0.8443 - dice_coef: 0.8755 - iou: 0.7795 - binary_accuracy: 0.8481 - val_loss: 0.0630 - val_precision: 0.9774 - val_recall: 0.9037 - val_dice_coef: 0.9116 - val_iou: 0.8392 - val_binary_accuracy: 0.8968 - lr: 6.5610e-04\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "Epoch 6/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0577 - precision: 0.9831 - recall: 0.8445 - dice_coef: 0.8784 - iou: 0.7842 - binary_accuracy: 0.8493\n",
      "Save best train weights.\n",
      "462/462 [==============================] - 558s 1s/step - loss: 0.0577 - precision: 0.9831 - recall: 0.8445 - dice_coef: 0.8784 - iou: 0.7842 - binary_accuracy: 0.8493 - val_loss: 0.0633 - val_precision: 0.9692 - val_recall: 0.9519 - val_dice_coef: 0.9233 - val_iou: 0.8585 - val_binary_accuracy: 0.9307 - lr: 5.9049e-04\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "Epoch 7/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0518 - precision: 0.9854 - recall: 0.8541 - dice_coef: 0.8890 - iou: 0.8012 - binary_accuracy: 0.8592\n",
      "Save best train weights.\n",
      "Save best val weights.\n",
      "462/462 [==============================] - 547s 1s/step - loss: 0.0518 - precision: 0.9854 - recall: 0.8541 - dice_coef: 0.8890 - iou: 0.8012 - binary_accuracy: 0.8592 - val_loss: 0.0578 - val_precision: 0.9798 - val_recall: 0.9134 - val_dice_coef: 0.9243 - val_iou: 0.8606 - val_binary_accuracy: 0.9065 - lr: 5.3144e-04\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "Epoch 8/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0509 - precision: 0.9857 - recall: 0.8581 - dice_coef: 0.8898 - iou: 0.8025 - binary_accuracy: 0.8624\n",
      "Save best train weights.\n",
      "Save best val weights.\n",
      "462/462 [==============================] - 547s 1s/step - loss: 0.0509 - precision: 0.9857 - recall: 0.8581 - dice_coef: 0.8898 - iou: 0.8025 - binary_accuracy: 0.8624 - val_loss: 0.0563 - val_precision: 0.9814 - val_recall: 0.9011 - val_dice_coef: 0.9043 - val_iou: 0.8262 - val_binary_accuracy: 0.8977 - lr: 4.7830e-04\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "Epoch 9/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0490 - precision: 0.9863 - recall: 0.8650 - dice_coef: 0.8962 - iou: 0.8129 - binary_accuracy: 0.8692\n",
      "Save best train weights.\n",
      "462/462 [==============================] - 556s 1s/step - loss: 0.0490 - precision: 0.9863 - recall: 0.8650 - dice_coef: 0.8962 - iou: 0.8129 - binary_accuracy: 0.8692 - val_loss: 0.0585 - val_precision: 0.9921 - val_recall: 0.8229 - val_dice_coef: 0.8694 - val_iou: 0.7704 - val_binary_accuracy: 0.8396 - lr: 4.3047e-04\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "Epoch 10/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0489 - precision: 0.9868 - recall: 0.8668 - dice_coef: 0.8983 - iou: 0.8164 - binary_accuracy: 0.8717\n",
      "Save best train weights.\n",
      "Save best val weights.\n",
      "462/462 [==============================] - 579s 1s/step - loss: 0.0489 - precision: 0.9868 - recall: 0.8668 - dice_coef: 0.8983 - iou: 0.8164 - binary_accuracy: 0.8717 - val_loss: 0.0541 - val_precision: 0.9942 - val_recall: 0.8285 - val_dice_coef: 0.8773 - val_iou: 0.7835 - val_binary_accuracy: 0.8450 - lr: 3.8742e-04\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "Epoch 11/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0461 - precision: 0.9882 - recall: 0.8690 - dice_coef: 0.9039 - iou: 0.8258 - binary_accuracy: 0.8743\n",
      "Save best train weights.\n",
      "462/462 [==============================] - 559s 1s/step - loss: 0.0461 - precision: 0.9882 - recall: 0.8690 - dice_coef: 0.9039 - iou: 0.8258 - binary_accuracy: 0.8743 - val_loss: 0.0800 - val_precision: 0.9622 - val_recall: 0.9531 - val_dice_coef: 0.9371 - val_iou: 0.8828 - val_binary_accuracy: 0.9257 - lr: 3.4868e-04\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "Epoch 12/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0454 - precision: 0.9882 - recall: 0.8789 - dice_coef: 0.9079 - iou: 0.8323 - binary_accuracy: 0.8831\n",
      "Save best train weights.\n",
      "Save best val weights.\n",
      "462/462 [==============================] - 561s 1s/step - loss: 0.0454 - precision: 0.9882 - recall: 0.8789 - dice_coef: 0.9079 - iou: 0.8323 - binary_accuracy: 0.8831 - val_loss: 0.0442 - val_precision: 0.9888 - val_recall: 0.9087 - val_dice_coef: 0.9218 - val_iou: 0.8560 - val_binary_accuracy: 0.9104 - lr: 3.1381e-04\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "Epoch 13/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0438 - precision: 0.9890 - recall: 0.8759 - dice_coef: 0.9092 - iou: 0.8345 - binary_accuracy: 0.8809\n",
      "Save best train weights.\n",
      "462/462 [==============================] - 568s 1s/step - loss: 0.0438 - precision: 0.9890 - recall: 0.8759 - dice_coef: 0.9092 - iou: 0.8345 - binary_accuracy: 0.8809 - val_loss: 0.0554 - val_precision: 0.9815 - val_recall: 0.9113 - val_dice_coef: 0.9218 - val_iou: 0.8561 - val_binary_accuracy: 0.9073 - lr: 2.8243e-04\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "Epoch 14/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0417 - precision: 0.9896 - recall: 0.8836 - dice_coef: 0.9146 - iou: 0.8435 - binary_accuracy: 0.8882\n",
      "Save best train weights.\n",
      "Save best val weights.\n",
      "462/462 [==============================] - 591s 1s/step - loss: 0.0417 - precision: 0.9896 - recall: 0.8836 - dice_coef: 0.9146 - iou: 0.8435 - binary_accuracy: 0.8882 - val_loss: 0.0432 - val_precision: 0.9908 - val_recall: 0.8964 - val_dice_coef: 0.9162 - val_iou: 0.8467 - val_binary_accuracy: 0.9008 - lr: 2.5419e-04\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0002287679245496101.\n",
      "Epoch 15/100\n",
      "462/462 [==============================] - 607s 1s/step - loss: 0.0418 - precision: 0.9896 - recall: 0.8846 - dice_coef: 0.9142 - iou: 0.8429 - binary_accuracy: 0.8891 - val_loss: 0.0542 - val_precision: 0.9796 - val_recall: 0.9367 - val_dice_coef: 0.9328 - val_iou: 0.8750 - val_binary_accuracy: 0.9275 - lr: 2.2877e-04\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.0002058911320946491.\n",
      "Epoch 16/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0414 - precision: 0.9901 - recall: 0.8882 - dice_coef: 0.9189 - iou: 0.8508 - binary_accuracy: 0.8932\n",
      "Save best train weights.\n",
      "462/462 [==============================] - 612s 1s/step - loss: 0.0414 - precision: 0.9901 - recall: 0.8882 - dice_coef: 0.9189 - iou: 0.8508 - binary_accuracy: 0.8932 - val_loss: 0.0439 - val_precision: 0.9855 - val_recall: 0.9362 - val_dice_coef: 0.9408 - val_iou: 0.8891 - val_binary_accuracy: 0.9316 - lr: 2.0589e-04\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.00018530201888518417.\n",
      "Epoch 17/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0406 - precision: 0.9903 - recall: 0.8887 - dice_coef: 0.9183 - iou: 0.8497 - binary_accuracy: 0.8934\n",
      "Save best train weights.\n",
      "Save best val weights.\n",
      "462/462 [==============================] - 551s 1s/step - loss: 0.0406 - precision: 0.9903 - recall: 0.8887 - dice_coef: 0.9183 - iou: 0.8497 - binary_accuracy: 0.8934 - val_loss: 0.0428 - val_precision: 0.9886 - val_recall: 0.9186 - val_dice_coef: 0.9343 - val_iou: 0.8778 - val_binary_accuracy: 0.9191 - lr: 1.8530e-04\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.00016677181699666576.\n",
      "Epoch 18/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0378 - precision: 0.9913 - recall: 0.8914 - dice_coef: 0.9234 - iou: 0.8583 - binary_accuracy: 0.8963\n",
      "Save best train weights.\n",
      "462/462 [==============================] - 569s 1s/step - loss: 0.0378 - precision: 0.9913 - recall: 0.8914 - dice_coef: 0.9234 - iou: 0.8583 - binary_accuracy: 0.8963 - val_loss: 0.0545 - val_precision: 0.9782 - val_recall: 0.9439 - val_dice_coef: 0.9429 - val_iou: 0.8932 - val_binary_accuracy: 0.9322 - lr: 1.6677e-04\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.00015009463529699917.\n",
      "Epoch 19/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0391 - precision: 0.9907 - recall: 0.8895 - dice_coef: 0.9215 - iou: 0.8553 - binary_accuracy: 0.8948Save best val weights.\n",
      "462/462 [==============================] - 607s 1s/step - loss: 0.0391 - precision: 0.9907 - recall: 0.8895 - dice_coef: 0.9215 - iou: 0.8553 - binary_accuracy: 0.8948 - val_loss: 0.0417 - val_precision: 0.9878 - val_recall: 0.9301 - val_dice_coef: 0.9382 - val_iou: 0.8847 - val_binary_accuracy: 0.9285 - lr: 1.5009e-04\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.0001350851717672993.\n",
      "Epoch 20/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0371 - precision: 0.9915 - recall: 0.8953 - dice_coef: 0.9241 - iou: 0.8599 - binary_accuracy: 0.8998\n",
      "Save best train weights.\n",
      "462/462 [==============================] - 595s 1s/step - loss: 0.0371 - precision: 0.9915 - recall: 0.8953 - dice_coef: 0.9241 - iou: 0.8599 - binary_accuracy: 0.8998 - val_loss: 0.0450 - val_precision: 0.9858 - val_recall: 0.9311 - val_dice_coef: 0.9386 - val_iou: 0.8853 - val_binary_accuracy: 0.9277 - lr: 1.3509e-04\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.00012157665459056935.\n",
      "Epoch 21/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0371 - precision: 0.9916 - recall: 0.8945 - dice_coef: 0.9248 - iou: 0.8609 - binary_accuracy: 0.8993Save best val weights.\n",
      "462/462 [==============================] - 591s 1s/step - loss: 0.0371 - precision: 0.9916 - recall: 0.8945 - dice_coef: 0.9248 - iou: 0.8609 - binary_accuracy: 0.8993 - val_loss: 0.0403 - val_precision: 0.9889 - val_recall: 0.9275 - val_dice_coef: 0.9406 - val_iou: 0.8888 - val_binary_accuracy: 0.9268 - lr: 1.2158e-04\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.00010941898913151242.\n",
      "Epoch 22/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0360 - precision: 0.9918 - recall: 0.9001 - dice_coef: 0.9280 - iou: 0.8664 - binary_accuracy: 0.9047\n",
      "Save best train weights.\n",
      "Save best val weights.\n",
      "462/462 [==============================] - 513s 1s/step - loss: 0.0360 - precision: 0.9918 - recall: 0.9001 - dice_coef: 0.9280 - iou: 0.8664 - binary_accuracy: 0.9047 - val_loss: 0.0398 - val_precision: 0.9891 - val_recall: 0.9276 - val_dice_coef: 0.9423 - val_iou: 0.8918 - val_binary_accuracy: 0.9276 - lr: 1.0942e-04\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 9.847709021836118e-05.\n",
      "Epoch 23/100\n",
      "462/462 [==============================] - 613s 1s/step - loss: 0.0375 - precision: 0.9912 - recall: 0.8923 - dice_coef: 0.9239 - iou: 0.8595 - binary_accuracy: 0.8971 - val_loss: 0.0425 - val_precision: 0.9890 - val_recall: 0.9205 - val_dice_coef: 0.9362 - val_iou: 0.8809 - val_binary_accuracy: 0.9213 - lr: 9.8477e-05\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 8.862938119652506e-05.\n",
      "Epoch 24/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0358 - precision: 0.9920 - recall: 0.8968 - dice_coef: 0.9268 - iou: 0.8643 - binary_accuracy: 0.9018\n",
      "Save best train weights.\n",
      "Save best val weights.\n",
      "462/462 [==============================] - 574s 1s/step - loss: 0.0358 - precision: 0.9920 - recall: 0.8968 - dice_coef: 0.9268 - iou: 0.8643 - binary_accuracy: 0.9018 - val_loss: 0.0373 - val_precision: 0.9914 - val_recall: 0.9261 - val_dice_coef: 0.9431 - val_iou: 0.8933 - val_binary_accuracy: 0.9278 - lr: 8.8629e-05\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 7.976644307687256e-05.\n",
      "Epoch 25/100\n",
      "462/462 [==============================] - 534s 1s/step - loss: 0.0372 - precision: 0.9915 - recall: 0.8926 - dice_coef: 0.9252 - iou: 0.8617 - binary_accuracy: 0.8978 - val_loss: 0.0406 - val_precision: 0.9911 - val_recall: 0.9161 - val_dice_coef: 0.9341 - val_iou: 0.8778 - val_binary_accuracy: 0.9186 - lr: 7.9766e-05\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 7.17897987691853e-05.\n",
      "Epoch 26/100\n",
      "462/462 [==============================] - 539s 1s/step - loss: 0.0361 - precision: 0.9921 - recall: 0.8989 - dice_coef: 0.9292 - iou: 0.8685 - binary_accuracy: 0.9041 - val_loss: 0.0379 - val_precision: 0.9900 - val_recall: 0.9308 - val_dice_coef: 0.9427 - val_iou: 0.8926 - val_binary_accuracy: 0.9308 - lr: 7.1790e-05\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 6.461081889226677e-05.\n",
      "Epoch 27/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0342 - precision: 0.9925 - recall: 0.9007 - dice_coef: 0.9308 - iou: 0.8712 - binary_accuracy: 0.9056\n",
      "Save best train weights.\n",
      "Save best val weights.\n",
      "462/462 [==============================] - 549s 1s/step - loss: 0.0342 - precision: 0.9925 - recall: 0.9007 - dice_coef: 0.9308 - iou: 0.8712 - binary_accuracy: 0.9056 - val_loss: 0.0353 - val_precision: 0.9923 - val_recall: 0.9263 - val_dice_coef: 0.9437 - val_iou: 0.8946 - val_binary_accuracy: 0.9285 - lr: 6.4611e-05\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 5.8149737003040094e-05.\n",
      "Epoch 28/100\n",
      "462/462 [==============================] - 509s 1s/step - loss: 0.0349 - precision: 0.9924 - recall: 0.8982 - dice_coef: 0.9294 - iou: 0.8688 - binary_accuracy: 0.9032 - val_loss: 0.0420 - val_precision: 0.9878 - val_recall: 0.9356 - val_dice_coef: 0.9452 - val_iou: 0.8973 - val_binary_accuracy: 0.9336 - lr: 5.8150e-05\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 5.233476330273609e-05.\n",
      "Epoch 29/100\n",
      "462/462 [==============================] - 520s 1s/step - loss: 0.0354 - precision: 0.9920 - recall: 0.9003 - dice_coef: 0.9294 - iou: 0.8689 - binary_accuracy: 0.9046 - val_loss: 0.0467 - val_precision: 0.9825 - val_recall: 0.9474 - val_dice_coef: 0.9482 - val_iou: 0.9023 - val_binary_accuracy: 0.9388 - lr: 5.2335e-05\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 4.7101286972462485e-05.\n",
      "Epoch 30/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0332 - precision: 0.9929 - recall: 0.9033 - dice_coef: 0.9322 - iou: 0.8738 - binary_accuracy: 0.9081\n",
      "Save best train weights.\n",
      "462/462 [==============================] - 529s 1s/step - loss: 0.0332 - precision: 0.9929 - recall: 0.9033 - dice_coef: 0.9322 - iou: 0.8738 - binary_accuracy: 0.9081 - val_loss: 0.0387 - val_precision: 0.9920 - val_recall: 0.9177 - val_dice_coef: 0.9371 - val_iou: 0.8828 - val_binary_accuracy: 0.9216 - lr: 4.7101e-05\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 4.239115827521624e-05.\n",
      "Epoch 31/100\n",
      "462/462 [==============================] - 520s 1s/step - loss: 0.0367 - precision: 0.9913 - recall: 0.9022 - dice_coef: 0.9300 - iou: 0.8699 - binary_accuracy: 0.9063 - val_loss: 0.0433 - val_precision: 0.9858 - val_recall: 0.9370 - val_dice_coef: 0.9444 - val_iou: 0.8958 - val_binary_accuracy: 0.9325 - lr: 4.2391e-05\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 3.8152042447694614e-05.\n",
      "Epoch 32/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0331 - precision: 0.9928 - recall: 0.9039 - dice_coef: 0.9321 - iou: 0.8735 - binary_accuracy: 0.9087\n",
      "Save best train weights.\n",
      "462/462 [==============================] - 533s 1s/step - loss: 0.0331 - precision: 0.9928 - recall: 0.9039 - dice_coef: 0.9321 - iou: 0.8735 - binary_accuracy: 0.9087 - val_loss: 0.0381 - val_precision: 0.9904 - val_recall: 0.9298 - val_dice_coef: 0.9432 - val_iou: 0.8937 - val_binary_accuracy: 0.9302 - lr: 3.8152e-05\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 3.433683820292515e-05.\n",
      "Epoch 33/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0353 - precision: 0.9919 - recall: 0.9030 - dice_coef: 0.9315 - iou: 0.8725 - binary_accuracy: 0.9074Save best val weights.\n",
      "462/462 [==============================] - 518s 1s/step - loss: 0.0353 - precision: 0.9919 - recall: 0.9030 - dice_coef: 0.9315 - iou: 0.8725 - binary_accuracy: 0.9074 - val_loss: 0.0348 - val_precision: 0.9919 - val_recall: 0.9284 - val_dice_coef: 0.9441 - val_iou: 0.8949 - val_binary_accuracy: 0.9301 - lr: 3.4337e-05\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 3.090315438263264e-05.\n",
      "Epoch 34/100\n",
      "462/462 [==============================] - 514s 1s/step - loss: 0.0356 - precision: 0.9919 - recall: 0.9031 - dice_coef: 0.9313 - iou: 0.8722 - binary_accuracy: 0.9076 - val_loss: 0.0372 - val_precision: 0.9915 - val_recall: 0.9258 - val_dice_coef: 0.9419 - val_iou: 0.8914 - val_binary_accuracy: 0.9274 - lr: 3.0903e-05\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 2.7812838944369376e-05.\n",
      "Epoch 35/100\n",
      "462/462 [==============================] - 502s 1s/step - loss: 0.0335 - precision: 0.9928 - recall: 0.9035 - dice_coef: 0.9324 - iou: 0.8741 - binary_accuracy: 0.9083 - val_loss: 0.0370 - val_precision: 0.9892 - val_recall: 0.9406 - val_dice_coef: 0.9487 - val_iou: 0.9031 - val_binary_accuracy: 0.9385 - lr: 2.7813e-05\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 2.5031555049932436e-05.\n",
      "Epoch 36/100\n",
      "462/462 [==============================] - 512s 1s/step - loss: 0.0336 - precision: 0.9928 - recall: 0.9072 - dice_coef: 0.9350 - iou: 0.8786 - binary_accuracy: 0.9117 - val_loss: 0.0362 - val_precision: 0.9914 - val_recall: 0.9347 - val_dice_coef: 0.9477 - val_iou: 0.9015 - val_binary_accuracy: 0.9353 - lr: 2.5032e-05\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 2.2528399544939195e-05.\n",
      "Epoch 37/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0328 - precision: 0.9928 - recall: 0.9048 - dice_coef: 0.9334 - iou: 0.8759 - binary_accuracy: 0.9093\n",
      "Save best train weights.\n",
      "462/462 [==============================] - 515s 1s/step - loss: 0.0328 - precision: 0.9928 - recall: 0.9048 - dice_coef: 0.9334 - iou: 0.8759 - binary_accuracy: 0.9093 - val_loss: 0.0393 - val_precision: 0.9910 - val_recall: 0.9237 - val_dice_coef: 0.9401 - val_iou: 0.8880 - val_binary_accuracy: 0.9260 - lr: 2.2528e-05\n",
      "\n",
      "Epoch 00038: LearningRateScheduler setting learning rate to 2.0275559590445276e-05.\n",
      "Epoch 38/100\n",
      "462/462 [==============================] - 560s 1s/step - loss: 0.0345 - precision: 0.9922 - recall: 0.9052 - dice_coef: 0.9330 - iou: 0.8751 - binary_accuracy: 0.9096 - val_loss: 0.0403 - val_precision: 0.9897 - val_recall: 0.9296 - val_dice_coef: 0.9426 - val_iou: 0.8925 - val_binary_accuracy: 0.9298 - lr: 2.0276e-05\n",
      "\n",
      "Epoch 00039: LearningRateScheduler setting learning rate to 1.824800363140075e-05.\n",
      "Epoch 39/100\n",
      "462/462 [==============================] - 558s 1s/step - loss: 0.0330 - precision: 0.9928 - recall: 0.9067 - dice_coef: 0.9344 - iou: 0.8776 - binary_accuracy: 0.9114 - val_loss: 0.0361 - val_precision: 0.9915 - val_recall: 0.9285 - val_dice_coef: 0.9459 - val_iou: 0.8982 - val_binary_accuracy: 0.9300 - lr: 1.8248e-05\n",
      "\n",
      "Epoch 00040: LearningRateScheduler setting learning rate to 1.6423203268260675e-05.\n",
      "Epoch 40/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0323 - precision: 0.9931 - recall: 0.9071 - dice_coef: 0.9351 - iou: 0.8788 - binary_accuracy: 0.9114\n",
      "Save best train weights.\n",
      "462/462 [==============================] - 539s 1s/step - loss: 0.0323 - precision: 0.9931 - recall: 0.9071 - dice_coef: 0.9351 - iou: 0.8788 - binary_accuracy: 0.9114 - val_loss: 0.0362 - val_precision: 0.9929 - val_recall: 0.9161 - val_dice_coef: 0.9392 - val_iou: 0.8863 - val_binary_accuracy: 0.9205 - lr: 1.6423e-05\n",
      "\n",
      "Epoch 00041: LearningRateScheduler setting learning rate to 1.4780882941434608e-05.\n",
      "Epoch 41/100\n",
      "462/462 [==============================] - 565s 1s/step - loss: 0.0335 - precision: 0.9927 - recall: 0.9069 - dice_coef: 0.9350 - iou: 0.8785 - binary_accuracy: 0.9114 - val_loss: 0.0367 - val_precision: 0.9915 - val_recall: 0.9265 - val_dice_coef: 0.9443 - val_iou: 0.8955 - val_binary_accuracy: 0.9282 - lr: 1.4781e-05\n",
      "\n",
      "Epoch 00042: LearningRateScheduler setting learning rate to 1.3302794647291146e-05.\n",
      "Epoch 42/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0326 - precision: 0.9930 - recall: 0.9050 - dice_coef: 0.9341 - iou: 0.8770 - binary_accuracy: 0.9096Save best val weights.\n",
      "462/462 [==============================] - 562s 1s/step - loss: 0.0326 - precision: 0.9930 - recall: 0.9050 - dice_coef: 0.9341 - iou: 0.8770 - binary_accuracy: 0.9096 - val_loss: 0.0330 - val_precision: 0.9927 - val_recall: 0.9303 - val_dice_coef: 0.9474 - val_iou: 0.9007 - val_binary_accuracy: 0.9325 - lr: 1.3303e-05\n",
      "\n",
      "Epoch 00043: LearningRateScheduler setting learning rate to 1.1972515182562033e-05.\n",
      "Epoch 43/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0321 - precision: 0.9933 - recall: 0.9025 - dice_coef: 0.9334 - iou: 0.8760 - binary_accuracy: 0.9076\n",
      "Save best train weights.\n",
      "462/462 [==============================] - 517s 1s/step - loss: 0.0321 - precision: 0.9933 - recall: 0.9025 - dice_coef: 0.9334 - iou: 0.8760 - binary_accuracy: 0.9076 - val_loss: 0.0354 - val_precision: 0.9913 - val_recall: 0.9302 - val_dice_coef: 0.9455 - val_iou: 0.8978 - val_binary_accuracy: 0.9308 - lr: 1.1973e-05\n",
      "\n",
      "Epoch 00044: LearningRateScheduler setting learning rate to 1.077526366430583e-05.\n",
      "Epoch 44/100\n",
      "462/462 [==============================] - 552s 1s/step - loss: 0.0331 - precision: 0.9929 - recall: 0.9068 - dice_coef: 0.9352 - iou: 0.8790 - binary_accuracy: 0.9115 - val_loss: 0.0336 - val_precision: 0.9918 - val_recall: 0.9346 - val_dice_coef: 0.9488 - val_iou: 0.9035 - val_binary_accuracy: 0.9350 - lr: 1.0775e-05\n",
      "\n",
      "Epoch 00045: LearningRateScheduler setting learning rate to 9.697737297875246e-06.\n",
      "Epoch 45/100\n",
      "462/462 [==============================] - 560s 1s/step - loss: 0.0333 - precision: 0.9929 - recall: 0.9055 - dice_coef: 0.9346 - iou: 0.8779 - binary_accuracy: 0.9103 - val_loss: 0.0368 - val_precision: 0.9913 - val_recall: 0.9271 - val_dice_coef: 0.9444 - val_iou: 0.8956 - val_binary_accuracy: 0.9288 - lr: 9.6977e-06\n",
      "\n",
      "Epoch 00046: LearningRateScheduler setting learning rate to 8.727963568087722e-06.\n",
      "Epoch 46/100\n",
      "462/462 [==============================] - 526s 1s/step - loss: 0.0335 - precision: 0.9928 - recall: 0.9045 - dice_coef: 0.9341 - iou: 0.8770 - binary_accuracy: 0.9095 - val_loss: 0.0358 - val_precision: 0.9916 - val_recall: 0.9288 - val_dice_coef: 0.9456 - val_iou: 0.8977 - val_binary_accuracy: 0.9306 - lr: 8.7280e-06\n",
      "\n",
      "Epoch 00047: LearningRateScheduler setting learning rate to 7.85516721127895e-06.\n",
      "Epoch 47/100\n",
      "462/462 [==============================] - 531s 1s/step - loss: 0.0327 - precision: 0.9930 - recall: 0.9074 - dice_coef: 0.9363 - iou: 0.8808 - binary_accuracy: 0.9124 - val_loss: 0.0341 - val_precision: 0.9924 - val_recall: 0.9253 - val_dice_coef: 0.9451 - val_iou: 0.8970 - val_binary_accuracy: 0.9276 - lr: 7.8552e-06\n",
      "\n",
      "Epoch 00048: LearningRateScheduler setting learning rate to 7.069650490151056e-06.\n",
      "Epoch 48/100\n",
      "462/462 [==============================] - 545s 1s/step - loss: 0.0330 - precision: 0.9931 - recall: 0.9044 - dice_coef: 0.9340 - iou: 0.8770 - binary_accuracy: 0.9096 - val_loss: 0.0398 - val_precision: 0.9884 - val_recall: 0.9342 - val_dice_coef: 0.9453 - val_iou: 0.8974 - val_binary_accuracy: 0.9323 - lr: 7.0697e-06\n",
      "\n",
      "Epoch 00049: LearningRateScheduler setting learning rate to 6.36268544113595e-06.\n",
      "Epoch 49/100\n",
      "462/462 [==============================] - 546s 1s/step - loss: 0.0322 - precision: 0.9934 - recall: 0.9081 - dice_coef: 0.9368 - iou: 0.8817 - binary_accuracy: 0.9130 - val_loss: 0.0384 - val_precision: 0.9897 - val_recall: 0.9354 - val_dice_coef: 0.9474 - val_iou: 0.9010 - val_binary_accuracy: 0.9349 - lr: 6.3627e-06\n",
      "\n",
      "Epoch 00050: LearningRateScheduler setting learning rate to 5.726416897022355e-06.\n",
      "Epoch 50/100\n",
      "462/462 [==============================] - 541s 1s/step - loss: 0.0329 - precision: 0.9928 - recall: 0.9081 - dice_coef: 0.9364 - iou: 0.8811 - binary_accuracy: 0.9126 - val_loss: 0.0350 - val_precision: 0.9915 - val_recall: 0.9306 - val_dice_coef: 0.9468 - val_iou: 0.8996 - val_binary_accuracy: 0.9318 - lr: 5.7264e-06\n",
      "\n",
      "Epoch 00051: LearningRateScheduler setting learning rate to 5.15377520732012e-06.\n",
      "Epoch 51/100\n",
      "462/462 [==============================] - 549s 1s/step - loss: 0.0339 - precision: 0.9927 - recall: 0.9042 - dice_coef: 0.9340 - iou: 0.8770 - binary_accuracy: 0.9091 - val_loss: 0.0376 - val_precision: 0.9908 - val_recall: 0.9334 - val_dice_coef: 0.9475 - val_iou: 0.9012 - val_binary_accuracy: 0.9342 - lr: 5.1538e-06\n",
      "\n",
      "Epoch 00052: LearningRateScheduler setting learning rate to 4.638397686588108e-06.\n",
      "Epoch 52/100\n",
      "462/462 [==============================] - ETA: 0s - loss: 0.0340 - precision: 0.9927 - recall: 0.9063 - dice_coef: 0.9349 - iou: 0.8785 - binary_accuracy: 0.9109\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 4.6383975131902845e-07.\n",
      "Val loss doesn't improve.\n",
      "462/462 [==============================] - 562s 1s/step - loss: 0.0340 - precision: 0.9927 - recall: 0.9063 - dice_coef: 0.9349 - iou: 0.8785 - binary_accuracy: 0.9109 - val_loss: 0.0370 - val_precision: 0.9909 - val_recall: 0.9290 - val_dice_coef: 0.9445 - val_iou: 0.8961 - val_binary_accuracy: 0.9298 - lr: 4.6384e-06\n",
      "Epoch 00052: early stopping\n"
     ]
    }
   ],
   "source": [
    "from models import loss\n",
    "from models.metrics import iou, dice_coef\n",
    "from models.callback.save_best import SavebestweightsandEarlyStopping\n",
    "\n",
    "model_name = 'mdanet'\n",
    "mission = 'road_thailand'\n",
    "img_size = 256\n",
    "num_class = 1 \n",
    "batch_size = 2\n",
    "\n",
    "def lr_decay(epoch):\n",
    "    initial_learningrate=1e-3\n",
    "    if epoch < 1:\n",
    "        return initial_learningrate\n",
    "    else:\n",
    "        return initial_learningrate * 0.9 ** (epoch)\n",
    "\n",
    "if batch_size >1:\n",
    "    val_batch_size = int(batch_size/2)\n",
    "else:\n",
    "    val_batch_size = batch_size\n",
    "    \n",
    "print(\"Init metric function\")\n",
    "if num_class==1:\n",
    "    recall = tf.keras.metrics.Recall()\n",
    "    precision = tf.keras.metrics.Precision()\n",
    "    model_metrics = [precision, recall, dice_coef, iou, tf.keras.metrics.BinaryAccuracy(threshold=0.5)]\n",
    "else:\n",
    "    recall = tf.keras.metrics.Recall()\n",
    "    precision = tf.keras.metrics.Precision()\n",
    "    accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "    model_metrics = [precision, recall, dice_coef, iou, accuracy]\n",
    "    \n",
    "checkpoint_filepath= '/home/quyet/DATA_ML/Projects/segmentation/logs/tmp'\n",
    "log_dir = '/home/quyet/DATA_ML/Projects/segmentation/logs/graph'\n",
    "weights_path = '/home/quyet/DATA_ML/WorkSpace/segmentation/weights/%s/'%(model_name) +model_name+'_'+mission+'_'+str(img_size)+'_'+str(num_class)+'class.h5'\n",
    "patience = 10\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only= True, \n",
    "                                                                monitor='val_loss', mode='min', save_best_only=True)\n",
    "model_lrscheduler_callback = tf.keras.callbacks.LearningRateScheduler(lr_decay, verbose=1)\n",
    "model_lrreduce_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=patience, min_lr=1e-7, verbose=1)\n",
    "model_earlystopping_callback = SavebestweightsandEarlyStopping(patience=patience, weights_path=weights_path)\n",
    "model_endtrainnan_callback = tf.keras.callbacks.TerminateOnNaN()\n",
    "model_tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=True)\n",
    "model_callbacks = [model_checkpoint_callback, model_lrscheduler_callback,\n",
    "                    model_lrreduce_callback, model_earlystopping_callback,\n",
    "                    model_tensorboard_callback,]\n",
    "\n",
    "# model = FF_UNet(attention_gates=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer = optimizer, loss = loss.balanced_cross_entropy_loss,\n",
    "             metrics = model_metrics)\n",
    "\n",
    "model.load_weights('/home/quyet/DATA_ML/WorkSpace/segmentation/weights/mdanet/mdanet_road_256_1class_train.h5')\n",
    "history_train = model.fit(train_dataset, batch_size=batch_size, epochs=100, verbose=1, \n",
    "                      callbacks=model_callbacks, validation_data=valid_dataset, \n",
    "                      validation_batch_size=val_batch_size, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75498c7a-28e0-4f6a-9c1e-ead3d86edf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6237, 6126, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/960 [00:00<?, ?it/s]2022-07-11 08:00:17.743620: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.17GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "100%|█████████████████████████████████████████| 960/960 [02:10<00:00,  7.37it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from osgeo import gdal\n",
    "from postprocess.convert_tif import dilation_obj, remove_small_items, write_image\n",
    "\n",
    "def get_im_by_coord(org_im, start_x, start_y,num_band, padding, crop_size, input_size):\n",
    "    startx = start_x-padding\n",
    "    endx = start_x+crop_size+padding\n",
    "    starty = start_y - padding\n",
    "    endy = start_y+crop_size+padding\n",
    "    result=[]\n",
    "    img = org_im[starty:endy, startx:endx]\n",
    "    img = img.swapaxes(2,1).swapaxes(1,0)\n",
    "    for chan_i in range(num_band):\n",
    "        result.append(cv2.resize(img[chan_i],(input_size, input_size), interpolation = cv2.INTER_CUBIC))\n",
    "    return np.array(result).swapaxes(0,1).swapaxes(1,2)\n",
    "\n",
    "def get_img_coords(w, h, padding, crop_size):\n",
    "    new_w = w + 2*padding\n",
    "    new_h = h + 2*padding\n",
    "    cut_w = list(range(padding, new_w - padding, crop_size))\n",
    "    cut_h = list(range(padding, new_h - padding, crop_size))\n",
    "\n",
    "    list_hight = []\n",
    "    list_weight = []\n",
    "    for i in cut_h:\n",
    "        if i < new_h - padding - crop_size:\n",
    "            list_hight.append(i)\n",
    "    list_hight.append(new_h-crop_size-padding)\n",
    "\n",
    "    for i in cut_w:\n",
    "        if i < new_w - crop_size - padding:\n",
    "            list_weight.append(i)\n",
    "    list_weight.append(new_w-crop_size-padding)\n",
    "\n",
    "    img_coords = []\n",
    "    for i in list_weight:\n",
    "        for j in list_hight:\n",
    "            img_coords.append([i, j])\n",
    "    return img_coords\n",
    "\n",
    "def padded_for_org_img(values, num_band, padding):\n",
    "    padded_org_im = []\n",
    "    for i in range(num_band):\n",
    "        band = np.pad(values[i], padding, mode='reflect')\n",
    "        padded_org_im.append(band)\n",
    "\n",
    "    values = np.array(padded_org_im).swapaxes(0,1).swapaxes(1,2)\n",
    "    print(values.shape)\n",
    "    del padded_org_im\n",
    "    return values\n",
    "\n",
    "def predict(model, values, img_coords, num_band, h, w, padding, crop_size, \n",
    "            input_size, batch_size, thresh_hold, choose_stage):\n",
    "    cut_imgs = []\n",
    "    for i in range(len(img_coords)):\n",
    "        im = get_im_by_coord(values, img_coords[i][0], img_coords[i][1],\n",
    "                            num_band,padding, crop_size, input_size)\n",
    "        cut_imgs.append(im)\n",
    "\n",
    "    a = list(range(0, len(cut_imgs), batch_size))\n",
    "\n",
    "    if a[len(a)-1] != len(cut_imgs):\n",
    "        a[len(a)-1] = len(cut_imgs)\n",
    "\n",
    "    y_pred = []\n",
    "    for i in tqdm(range(len(a)-1)):\n",
    "        x_batch = []\n",
    "        x_batch = np.array(cut_imgs[a[i]:a[i+1]])\n",
    "        # print(x_batch.shape)\n",
    "        img_edge = []\n",
    "        # for img_x in x_batch:\n",
    "        #     lab_batch = color.rgb2lab(img_x)  \n",
    "            # img_edge.append(cv2.Canny(np.asarray(np.uint8(lab_batch)),0,0)[..., np.newaxis])\n",
    "        # print(img_edge.shape)\n",
    "        # img_edge = np.array(img_edge)\n",
    "        \n",
    "        # print(x_batch.shape, img_edge.shape)\n",
    "        # y_batch = model.predict((x_batch/255, img_edge/255))\n",
    "        y_batch = model.predict(x_batch/255)\n",
    "        if len(model.outputs)>1:\n",
    "            y_batch = y_batch[choose_stage]\n",
    "        mutilabel = False\n",
    "        if y_batch.shape[-1]>=2:\n",
    "            mutilabel = True\n",
    "            y_batch = np.argmax(y_batch, axis=-1)\n",
    "        # print(np.unique(y_batch), y_batch.shape)\n",
    "            \n",
    "        y_pred.extend(y_batch)\n",
    "    big_mask = np.zeros((h, w)).astype(np.float16)\n",
    "    for i in range(len(cut_imgs)):\n",
    "        true_mask = y_pred[i].reshape((input_size,input_size))\n",
    "        if not mutilabel:\n",
    "            true_mask = (true_mask>thresh_hold).astype(np.uint8)\n",
    "            true_mask = (cv2.resize(true_mask,(input_size, input_size), interpolation = cv2.INTER_CUBIC)>thresh_hold).astype(np.uint8)\n",
    "            # true_mask = true_mask.astype(np.float16)\n",
    "        start_x = img_coords[i][1]\n",
    "        start_y = img_coords[i][0]\n",
    "        big_mask[start_x-padding:start_x-padding+crop_size, start_y-padding:start_y -\n",
    "                    padding+crop_size] = true_mask[padding:padding+crop_size, padding:padding+crop_size]\n",
    "    del cut_imgs\n",
    "    return big_mask\n",
    "\n",
    "img_size = 256\n",
    "num_band = 3\n",
    "crop_size = 200\n",
    "batch_size = 1\n",
    "thresh_hold = 0.8\n",
    "choose_stage = 0\n",
    "\n",
    "model.load_weights('/home/quyet/DATA_ML/WorkSpace/segmentation/weights/mdanet/mdanet_road_256_1class_train.h5')\n",
    "image_path = '/home/quyet/DATA_ML/Projects/road_multi/crop/img/test.tif'\n",
    "dataset = gdal.Open(image_path)\n",
    "values = dataset.ReadAsArray()[0:num_band]\n",
    "h,w = values.shape[1:3]    \n",
    "padding = int((img_size - crop_size)/2)\n",
    "img_coords = get_img_coords(w, h, padding, crop_size)\n",
    "values = padded_for_org_img(values, num_band, padding)\n",
    "big_mask = predict(model, values, img_coords, num_band, h, w, padding, crop_size, \n",
    "                    img_size, batch_size, thresh_hold, choose_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a54cbda6-517b-4ada-a616-47bafbd33a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write image...\n"
     ]
    }
   ],
   "source": [
    "image_path = '/home/quyet/DATA_ML/Projects/road_multi/crop/img/test.tif'\n",
    "result_path = write_image(image_path, big_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309a9523-274d-4ad5-83a7-41bb461c7ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
