{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12139654-5133-448b-8a73-c52012e9b1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0077a2a7-8992-42a0-ad99-7c735704b535",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.core import *\n",
    "from scripts.predict import inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0485a7b7-9d83-44e9-b542-fb13553e6c90",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 17:22:31.725717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4771 MB memory:  -> device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:05:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9113, 7636, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/7006 [00:00<?, ?it/s]2022-07-07 17:22:45.473547: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100\n",
      "2022-07-07 17:22:47.460569: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "100%|███████████████████████████████████████| 7006/7006 [10:59<00:00, 10.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write image...\n"
     ]
    }
   ],
   "source": [
    "weight_path = '/home/quyet/DATA_ML/WorkSpace/Greencover_api/weights/green_weights.h5'\n",
    "# weight_path =  '/home/quyet/DATA_ML/WorkSpace/segmentation/weights/att_unet/att_unet_road_detection_512_1class_train.h5'\n",
    "# image_path = '/home/quyet/DATA_ML/WorkSpace/Greencover_api/weights/sen2_April032022.tif'con\n",
    "image_path = '/home/nghipham/Desktop/Jupyter/public/wells_data/anh sen2/2019-AOI1_fn.tif'\n",
    "# image_path = glob.glob('/home/quyet/DATA_ML/Projects/video_hold/DJI_0020/abc/img_tif/*.tif')\n",
    "# use_model = 'att_unet'\n",
    "use_model = 'att_unet_binary'\n",
    "# 'upernet_binary'\n",
    "\n",
    "\n",
    "root_dir = os.path.dirname(sys.path[0])\n",
    "config_path = os.path.join(root_dir, 'configs', '%s.json'%(use_model))\n",
    "print(config_path)\n",
    "dict_params = json.load(open(config_path))\n",
    "# predict_params = dict_params['predict']\n",
    "# del dict_params['data'], dict_params['strategy'], dict_params['predict']\n",
    "\n",
    "# init_model = eval(dict_params['name'])\n",
    "# model = init_model(**dict_params)\n",
    "# model.load_weights(weight_path)\n",
    "# try:\n",
    "#     choose_stage = predict_params['choose_stage']\n",
    "# except:\n",
    "#     choose_stage = None\n",
    "# if type(image_path) is list :\n",
    "#     for i in image_path:\n",
    "#         result_img = inference(model, weight_path, i, predict_params['img_size'], predict_params['crop_size'], \n",
    "#                         predict_params['num_band'], predict_params['batch_size'], predict_params['thresh_hold'], \n",
    "#                         predict_params['use_dil'], predict_params['rm_small'], choose_stage)\n",
    "# else:\n",
    "#     result_img = inference(model, weight_path, image_path, predict_params['img_size'], predict_params['crop_size'], \n",
    "#                             predict_params['num_band'], predict_params['batch_size'], predict_params['thresh_hold'], \n",
    "#                             predict_params['use_dil'], predict_params['rm_small'], choose_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7679f90b-3658-47b0-817f-fc22a91bf8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.000e+00, 5.960e-08, 1.192e-07, ..., 9.990e-01, 9.995e-01,\n",
       "       1.000e+00], dtype=float16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(result_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8e1d9af-79f9-42f4-8e99-4b1c57188281",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(result_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5414a3bb-709c-48ad-9b21-aa66f98d6f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(result_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18b4482a-9a2c-4f95-a929-5dcb0bdab72e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write image...\n"
     ]
    }
   ],
   "source": [
    "from postprocess.convert_tif import write_image\n",
    "# result_path = '/home/quyet/DATA_ML/Projects/forest_monitor/image/results.tif'\n",
    "result_path = write_image(image_path, result_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a448976f-9d6e-4868-856a-ef4a9dfb9ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import rasterio\n",
    "# import tensorflow as tf\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# from rasterio.windows import Window\n",
    "\n",
    "# num_band = 8\n",
    "# input_size=256\n",
    "# stride_size = 200\n",
    "# padding = int((input_size - stride_size) / 2)\n",
    "\n",
    "# image_path = '/home/quyet/DATA_ML/Projects/forest_monitor/image/20211226_144607_59_2464_3B_AnalyticMS_SR_8b_harmonized_clip.tif'\n",
    "# current_x, current_y=0,0\n",
    "# with rasterio.open(image_path) as dataset_image:\n",
    "#         transform = dataset_image.transform\n",
    "#         topleftX = transform[2]\n",
    "#         topleftY = transform[5]\n",
    "#         XRes = transform[0]\n",
    "#         YRes = transform[4]\n",
    "#         transform = dataset_image.transform\n",
    "#         big_img = dataset_image.read()\n",
    "#         proj_str = dataset_image.crs\n",
    "#         image_name = os.path.basename(image_path)\n",
    "#         image_id = os.path.splitext(image_name)[0]\n",
    "#         imgs = dataset_image.read().swapaxes(0,1).swapaxes(1,2)\n",
    "#         print(imgs.shape)\n",
    "        \n",
    "#         # List h,w to stride window of image\n",
    "#         h,w = dataset_image.height, dataset_image.width\n",
    "#         img_1 = np.zeros((h,w))\n",
    "#         list_coordinates = []\n",
    "#         padding = int((input_size - stride_size) / 2)\n",
    "#         new_w = w + 2 * padding\n",
    "#         new_h = h + 2 * padding\n",
    "#         list_weight = list(range(padding, new_w - padding, stride_size))\n",
    "#         list_height = list(range(padding, new_h - padding, stride_size))\n",
    "#         with tqdm(total=len(list_height*len(list_weight))) as pbar:\n",
    "#             for i in range(len(list_height)):\n",
    "#                 top_left_y = list_height[i]\n",
    "#                 for j in range(len(list_weight)):\n",
    "#                     top_left_x = list_weight[j]\n",
    "#                     start_x = top_left_x - padding\n",
    "#                     end_x = min(top_left_x + stride_size + padding, new_w - padding)\n",
    "#                     start_y = top_left_y - padding\n",
    "#                     end_y = min(top_left_y + stride_size + padding, new_h - padding)\n",
    "#                     if start_x == 0:\n",
    "#                         x_off = start_x\n",
    "#                     else:\n",
    "#                         x_off = start_x - padding\n",
    "#                     if start_y == 0:\n",
    "#                         y_off = start_y\n",
    "#                     else:\n",
    "#                         y_off = start_y - padding\n",
    "#                     x_count = end_x - padding - x_off\n",
    "#                     y_count = end_y - padding - y_off\n",
    "#                     list_coordinates.append(tuple([x_off, y_off, x_count, y_count, start_x, start_y]))\n",
    "# #                     print(x_off, y_off, x_count, y_count)\n",
    "#                     image_detect = dataset_image.read(window=Window(x_off, y_off, x_count, y_count))[:num_band].swapaxes(0, 1).swapaxes(1, 2)\n",
    "#                     # print(image_detect.shape)\n",
    "# #                     list_img1.append(image_detect)\n",
    "#                     if image_detect.shape[0] < input_size or image_detect.shape[1] < input_size:\n",
    "#                         img_temp = np.zeros((input_size, input_size, image_detect.shape[2]))\n",
    "#                         if start_x == 0 and start_y == 0:\n",
    "#                             img_temp[(input_size - image_detect.shape[0]):input_size, (input_size - image_detect.shape[1]):input_size] = image_detect\n",
    "#                         elif start_x == 0:\n",
    "#                             img_temp[0:image_detect.shape[0], (input_size - image_detect.shape[1]):input_size] = image_detect\n",
    "#                         elif start_y == 0:\n",
    "#                             img_temp[(input_size - image_detect.shape[0]):input_size, 0:image_detect.shape[1]] = image_detect\n",
    "#                         else:\n",
    "#                             img_temp[0:image_detect.shape[0], 0:image_detect.shape[1]] = image_detect\n",
    "#                         image_detect = img_temp\n",
    "# #                         list_img2.append(image_detect)\n",
    "#                     if np.count_nonzero(image_detect) > 0:\n",
    "#                         if len(np.unique(image_detect)) == 2 or len(np.unique(image_detect)) == 1:\n",
    "#                             pass\n",
    "#                         else:\n",
    "# #                             y_pred = image_detect\n",
    "#                             # print(image_detect.shape)\n",
    "#                             y_pred = unet3plus.predict(tf.expand_dims(image_detect, axis=0))\n",
    "#                             y_class = np.argmax(y_pred[-1], axis=-1)  \n",
    "#                             y_pred = y_class.astype('int16')[0]\n",
    "#                     else:\n",
    "#                         y_pred = image_detect[:,:,0] \n",
    "#                         pass\n",
    "#                     if start_x == 0 and start_y == 0:\n",
    "# #                         print(\"1\")\n",
    "#                         y_pred = y_pred[padding:-padding,padding:-padding]\n",
    "#                     elif start_y == 0 and (x_count + x_off) < w:\n",
    "# #                         print(\"2\")\n",
    "#                         y_pred = y_pred[padding:-padding,padding:-padding]\n",
    "#                     elif start_y == 0 and (x_count + x_off) >= w:\n",
    "# #                         print(\"3\")\n",
    "#                         y_pred = y_pred[padding:-padding,padding:x_count]\n",
    "#                     elif (x_count + x_off) >= w and (y_count + y_off) < h:\n",
    "# #                         print(\"4\")\n",
    "#                         y_pred = y_pred[padding:-padding,padding:x_count]\n",
    "#                     elif start_x == 0 and (y_count + y_off) < h:\n",
    "# #                         print(\"5\")\n",
    "#                         y_pred = y_pred[padding:-padding:,padding:-padding]\n",
    "\n",
    "#                     elif start_x == 0 and (y_count + y_off) >= h:\n",
    "# #                         print(\"6\")\n",
    "#                         y_pred = y_pred[padding:y_count:,padding:-padding]   \n",
    "                    \n",
    "#                     elif (x_count + x_off) >= w and (y_count + y_off) >= h:\n",
    "# #                         print(\"7\")\n",
    "#                         y_pred = y_pred[padding:y_count,padding:x_count]\n",
    "                        \n",
    "#                     elif (y_count + y_off) >= h and (x_count + x_off) < w :\n",
    "# #                         print(\"8\")\n",
    "#                         y_pred = y_pred[padding:y_count,padding:-padding]\n",
    "                        \n",
    "#                     else:\n",
    "\n",
    "#                         y_pred = y_pred[padding:x_count-padding:,padding:y_count-padding]\n",
    "#                     if y_pred.shape[1] == 10:\n",
    "#                         pass\n",
    "#                     else:\n",
    "#                         if current_y >= w:\n",
    "#                             current_y = 0\n",
    "#                             current_x = current_x + past_i.shape[0]\n",
    "\n",
    "#                         img_1[current_x:current_x+y_pred.shape[0],current_y:current_y+y_pred.shape[1]]+=y_pred\n",
    "#                         current_y += y_pred.shape[1]\n",
    "#                         past_i = y_pred\n",
    "#                     pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9028ce1e-43a2-454d-82e4-411b2964b296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with rasterio.open(result_path) as src:\n",
    "#     img = src.read()\n",
    "    \n",
    "# img[img==1]=2\n",
    "# img[img==0]=1\n",
    "# img[img==2]=0\n",
    "# plt.imshow(img[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
