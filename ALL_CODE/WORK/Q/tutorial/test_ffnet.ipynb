{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4018f5f9-2467-4c7a-b7d8-f3b465dc9797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68cf91c9-fcd0-4dea-9548-cf3acd482463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def expend_as(x, n):\n",
    "    y = Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3), arguments={'repnum': n})(x)\n",
    "    return y\n",
    "\n",
    "def conv_bn_act(x, filters, drop_out=0.0):\n",
    "    x = Conv2D(filters, (3, 3), activation=None, padding='same')(x)\n",
    "\n",
    "    if drop_out > 0:\n",
    "        x = Dropout(drop_out)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def attention_layer(d, e, n):\n",
    "    d1 = Conv2D(n, (1, 1), activation=None, padding='same')(d)\n",
    "    e1 = Conv2D(n, (1, 1), activation=None, padding='same')(e)\n",
    "\n",
    "    concat_de = add([d1, e1])\n",
    "\n",
    "    relu_de = Activation('relu')(concat_de)\n",
    "    conv_de = Conv2D(1, (1, 1), padding='same')(relu_de)\n",
    "    sigmoid_de = Activation('sigmoid')(conv_de)\n",
    "\n",
    "    shape_e = K.int_shape(e)\n",
    "    upsample_psi = expend_as(sigmoid_de, shape_e[3])\n",
    "\n",
    "    return multiply([upsample_psi, e])\n",
    "\n",
    "def feature_fused_module(x, filters, compression=0.5, drop_out=0.0):\n",
    "    x1 = Conv2D(filters, (3, 3), dilation_rate=2, padding='same')(x)\n",
    "\n",
    "    if drop_out > 0:\n",
    "        x1 = Dropout(drop_out)(x1)\n",
    "\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "\n",
    "    x2 = Conv2D(filters, (3, 3), padding='same')(x)\n",
    "\n",
    "    if drop_out > 0:\n",
    "        x2 = Dropout(drop_out)(x2)\n",
    "\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "\n",
    "    x3 = add([x1, x2])\n",
    "\n",
    "    x3 = GlobalAveragePooling2D()(x3)\n",
    "\n",
    "    x3 = Dense(int(filters * compression))(x3)\n",
    "    x3 = BatchNormalization()(x3)\n",
    "    x3 = Activation('relu')(x3)\n",
    "\n",
    "    x3 = Dense(filters)(x3)\n",
    "\n",
    "    x3p = Activation('sigmoid')(x3)\n",
    "\n",
    "    x3m = Lambda(lambda x: 1 - x)(x3p)\n",
    "\n",
    "    x4 = multiply([x1, x3p])\n",
    "    x5 = multiply([x2, x3m])\n",
    "\n",
    "    return add([x4, x5])\n",
    "\n",
    "def FF_UNet(input_shape=(256, 256, 3), filters=32, compression=0.5, drop_out=0, half_net=False, attention_gates=False):\n",
    "\n",
    "    inputShape = Input(input_shape)\n",
    "\n",
    "    c1 = feature_fused_module(inputShape, filters, compression=compression, drop_out=drop_out)\n",
    "    c1 = feature_fused_module(c1, filters, compression=compression, drop_out=drop_out)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    filters = 2 * filters\n",
    "\n",
    "    c2 = feature_fused_module(p1, filters, compression=compression, drop_out=drop_out)\n",
    "    c2 = feature_fused_module(c2, filters, compression=compression, drop_out=drop_out)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    filters = 2 * filters\n",
    "\n",
    "    c3 = feature_fused_module(p2, filters, compression=compression, drop_out=drop_out)\n",
    "    c3 = feature_fused_module(c3, filters, compression=compression, drop_out=drop_out)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    filters = 2 * filters\n",
    "\n",
    "    c4 = feature_fused_module(p3, filters, compression=compression, drop_out=drop_out)\n",
    "    c4 = feature_fused_module(c4, filters, compression=compression, drop_out=drop_out)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    filters = 2 * filters\n",
    "\n",
    "    cm = feature_fused_module(p4, filters, compression=compression, drop_out=drop_out)\n",
    "    cm = feature_fused_module(cm, filters, compression=compression, drop_out=drop_out)\n",
    "\n",
    "    filters = filters // 2\n",
    "\n",
    "    u4 = Conv2DTranspose(filters, (2, 2), strides=(2, 2), padding='same')(cm)\n",
    "\n",
    "    if attention_gates:\n",
    "        u4 = concatenate([u4, attention_layer(u4, c4, 1)], axis=3)\n",
    "    else:\n",
    "        u4 = concatenate([u4, c4], axis=3)\n",
    "\n",
    "    if half_net:\n",
    "        c5 = conv_bn_act(u4, filters, drop_out=drop_out)\n",
    "        c5 = conv_bn_act(c5, filters, drop_out=drop_out)\n",
    "    else:\n",
    "        c5 = feature_fused_module(u4, filters, compression=compression, drop_out=drop_out)\n",
    "        c5 = feature_fused_module(c5, filters, compression=compression, drop_out=drop_out)\n",
    "\n",
    "    filters = filters // 2\n",
    "\n",
    "    u3 = Conv2DTranspose(filters, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "\n",
    "    if attention_gates:\n",
    "        u3 = concatenate([u3, attention_layer(u3, c3, 1)], axis=3)\n",
    "    else:\n",
    "        u3 = concatenate([u3, c3], axis=3)\n",
    "\n",
    "    if half_net:\n",
    "        c6 = conv_bn_act(u3, filters, drop_out=drop_out)\n",
    "        c6 = conv_bn_act(c6, filters, drop_out=drop_out)\n",
    "    else:\n",
    "        c6 = feature_fused_module(u3, filters, compression=compression, drop_out=drop_out)\n",
    "        c6 = feature_fused_module(c6, filters, compression=compression, drop_out=drop_out)\n",
    "\n",
    "    filters = filters // 2\n",
    "\n",
    "    u2 = Conv2DTranspose(filters, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "\n",
    "    if attention_gates:\n",
    "        u2 = concatenate([u2, attention_layer(u2, c2, 1)], axis=3)\n",
    "    else:\n",
    "        u2 = concatenate([u2, c2], axis=3)\n",
    "\n",
    "    if half_net:\n",
    "        c7 = conv_bn_act(u2, filters, drop_out=drop_out)\n",
    "        c7 = conv_bn_act(c7, filters, drop_out=drop_out)\n",
    "\n",
    "    else:\n",
    "        c7 = feature_fused_module(u2, filters, compression=compression, drop_out=drop_out)\n",
    "        c7 = feature_fused_module(c7, filters, compression=compression, drop_out=drop_out)\n",
    "\n",
    "    filters = filters // 2\n",
    "\n",
    "    u1 = Conv2DTranspose(filters, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "\n",
    "    if attention_gates:\n",
    "        u1 = concatenate([u1, attention_layer(u1, c1, 1)], axis=3)\n",
    "    else:\n",
    "        u1 = concatenate([u1, c1], axis=3)\n",
    "\n",
    "    if half_net:\n",
    "        c8 = conv_bn_act(u1, filters, drop_out=drop_out)\n",
    "        c8 = conv_bn_act(c8, filters, drop_out=drop_out)\n",
    "    else:\n",
    "        c8 = feature_fused_module(u1, filters, compression=compression, drop_out=drop_out)\n",
    "        c8 = feature_fused_module(c8, filters, compression=compression, drop_out=drop_out)\n",
    "\n",
    "    c9 = Conv2D(1, (1, 1), padding=\"same\", activation='sigmoid')(c8)\n",
    "\n",
    "    return Model(inputs=[inputShape], outputs=[c9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7314a188-b9cd-4bc6-be93-9fe2694a4d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:validation = 1804:452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-11 08:21:15.029313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4806 MB memory:  -> device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:05:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "from preprocess.prepare_dataset import data_gen\n",
    "\n",
    "out_path = '/home/quyet/DATA_ML/WorkSpace/segmentation/data/road_multi'\n",
    "overlap_mask = os.path.join(out_path, 'mask_cut_crop')\n",
    "train_dataset, valid_dataset, _, _ = data_gen(os.path.join(overlap_mask, '*.tif'), img_size=256, \n",
    "                                                            batch_size=2, N_CLASSES=1, numband=3, \n",
    "                                                            split_ratios=0.8, test_data=False, multi=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4321692c-62c5-4255-a33b-f1483c3c7f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init metric function\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-11 08:21:56.383175: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100\n",
      "2022-07-11 08:21:56.849722: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6/Unknown - 32s 326ms/step - loss: 0.1982 - precision_1: 0.8881 - recall_1: 0.5088 - dice_coef: 0.6432 - iou: 0.4754 - binary_accuracy: 0.5689WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2368s vs `on_train_batch_end` time: 0.2866s). Check your callbacks.\n",
      "    902/Unknown - 875s 937ms/step - loss: 0.1348 - precision_1: 0.9387 - recall_1: 0.7069 - dice_coef: 0.7654 - iou: 0.6222 - binary_accuracy: 0.7332\n",
      "Save best train weights.\n",
      "Save best val weights.\n",
      "902/902 [==============================] - 1106s 1s/step - loss: 0.1348 - precision_1: 0.9387 - recall_1: 0.7069 - dice_coef: 0.7654 - iou: 0.6222 - binary_accuracy: 0.7332 - val_loss: 0.1247 - val_precision_1: 0.9628 - val_recall_1: 0.7407 - val_dice_coef: 0.7999 - val_iou: 0.6732 - val_binary_accuracy: 0.7741 - lr: 0.0010\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "Epoch 2/100\n",
      "902/902 [==============================] - ETA: 0s - loss: 0.1207 - precision_1: 0.9522 - recall_1: 0.7348 - dice_coef: 0.7958 - iou: 0.6630 - binary_accuracy: 0.7631\n",
      "Save best train weights.\n",
      "902/902 [==============================] - 1059s 1s/step - loss: 0.1207 - precision_1: 0.9522 - recall_1: 0.7348 - dice_coef: 0.7958 - iou: 0.6630 - binary_accuracy: 0.7631 - val_loss: 0.1586 - val_precision_1: 0.8875 - val_recall_1: 0.9244 - val_dice_coef: 0.8589 - val_iou: 0.7587 - val_binary_accuracy: 0.8483 - lr: 9.0000e-04\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "Epoch 3/100\n",
      "902/902 [==============================] - ETA: 0s - loss: 0.1108 - precision_1: 0.9553 - recall_1: 0.7488 - dice_coef: 0.8076 - iou: 0.6800 - binary_accuracy: 0.7739\n",
      "Save best train weights.\n",
      "902/902 [==============================] - 1072s 1s/step - loss: 0.1108 - precision_1: 0.9553 - recall_1: 0.7488 - dice_coef: 0.8076 - iou: 0.6800 - binary_accuracy: 0.7739 - val_loss: 0.1790 - val_precision_1: 0.8626 - val_recall_1: 0.9410 - val_dice_coef: 0.8408 - val_iou: 0.7326 - val_binary_accuracy: 0.8358 - lr: 8.1000e-04\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "Epoch 4/100\n",
      "902/902 [==============================] - ETA: 0s - loss: 0.1075 - precision_1: 0.9580 - recall_1: 0.7680 - dice_coef: 0.8189 - iou: 0.6963 - binary_accuracy: 0.7915\n",
      "Save best train weights.\n",
      "902/902 [==============================] - 1121s 1s/step - loss: 0.1075 - precision_1: 0.9580 - recall_1: 0.7680 - dice_coef: 0.8189 - iou: 0.6963 - binary_accuracy: 0.7915 - val_loss: 0.2380 - val_precision_1: 0.8386 - val_recall_1: 0.9433 - val_dice_coef: 0.8333 - val_iou: 0.7210 - val_binary_accuracy: 0.8148 - lr: 7.2900e-04\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "Epoch 5/100\n",
      "902/902 [==============================] - ETA: 0s - loss: 0.1058 - precision_1: 0.9537 - recall_1: 0.7750 - dice_coef: 0.8203 - iou: 0.6989 - binary_accuracy: 0.7937\n",
      "Save best train weights.\n",
      "902/902 [==============================] - 1097s 1s/step - loss: 0.1058 - precision_1: 0.9537 - recall_1: 0.7750 - dice_coef: 0.8203 - iou: 0.6989 - binary_accuracy: 0.7937 - val_loss: 0.1926 - val_precision_1: 0.8822 - val_recall_1: 0.9086 - val_dice_coef: 0.8580 - val_iou: 0.7600 - val_binary_accuracy: 0.8334 - lr: 6.5610e-04\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "Epoch 6/100\n",
      "902/902 [==============================] - ETA: 0s - loss: 0.0978 - precision_1: 0.9590 - recall_1: 0.7812 - dice_coef: 0.8307 - iou: 0.7138 - binary_accuracy: 0.8021\n",
      "Save best train weights.\n",
      "902/902 [==============================] - 1101s 1s/step - loss: 0.0978 - precision_1: 0.9590 - recall_1: 0.7812 - dice_coef: 0.8307 - iou: 0.7138 - binary_accuracy: 0.8021 - val_loss: 0.2239 - val_precision_1: 0.8426 - val_recall_1: 0.9605 - val_dice_coef: 0.8565 - val_iou: 0.7572 - val_binary_accuracy: 0.8288 - lr: 5.9049e-04\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "Epoch 7/100\n",
      "902/902 [==============================] - ETA: 0s - loss: 0.0972 - precision_1: 0.9569 - recall_1: 0.7914 - dice_coef: 0.8330 - iou: 0.7170 - binary_accuracy: 0.8089\n",
      "Save best train weights.\n",
      "Save best val weights.\n",
      "902/902 [==============================] - 1105s 1s/step - loss: 0.0972 - precision_1: 0.9569 - recall_1: 0.7914 - dice_coef: 0.8330 - iou: 0.7170 - binary_accuracy: 0.8089 - val_loss: 0.0975 - val_precision_1: 0.9557 - val_recall_1: 0.8383 - val_dice_coef: 0.8512 - val_iou: 0.7479 - val_binary_accuracy: 0.8427 - lr: 5.3144e-04\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "Epoch 8/100\n",
      "902/902 [==============================] - ETA: 0s - loss: 0.0889 - precision_1: 0.9615 - recall_1: 0.8103 - dice_coef: 0.8456 - iou: 0.7358 - binary_accuracy: 0.8242\n",
      "Save best train weights.\n",
      "902/902 [==============================] - 1120s 1s/step - loss: 0.0889 - precision_1: 0.9615 - recall_1: 0.8103 - dice_coef: 0.8456 - iou: 0.7358 - binary_accuracy: 0.8242 - val_loss: 0.2268 - val_precision_1: 0.8836 - val_recall_1: 0.9254 - val_dice_coef: 0.8759 - val_iou: 0.7872 - val_binary_accuracy: 0.8459 - lr: 4.7830e-04\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "Epoch 9/100\n",
      "902/902 [==============================] - ETA: 0s - loss: 0.0875 - precision_1: 0.9617 - recall_1: 0.8091 - dice_coef: 0.8453 - iou: 0.7359 - binary_accuracy: 0.8240\n",
      "Save best train weights.\n",
      "902/902 [==============================] - 1140s 1s/step - loss: 0.0875 - precision_1: 0.9617 - recall_1: 0.8091 - dice_coef: 0.8453 - iou: 0.7359 - binary_accuracy: 0.8240 - val_loss: 0.1270 - val_precision_1: 0.9391 - val_recall_1: 0.9080 - val_dice_coef: 0.8934 - val_iou: 0.8155 - val_binary_accuracy: 0.8816 - lr: 4.3047e-04\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "Epoch 10/100\n",
      "902/902 [==============================] - ETA: 0s - loss: 0.0862 - precision_1: 0.9630 - recall_1: 0.8190 - dice_coef: 0.8536 - iou: 0.7481 - binary_accuracy: 0.8332\n",
      "Save best train weights.\n",
      "902/902 [==============================] - 1104s 1s/step - loss: 0.0862 - precision_1: 0.9630 - recall_1: 0.8190 - dice_coef: 0.8536 - iou: 0.7481 - binary_accuracy: 0.8332 - val_loss: 0.1193 - val_precision_1: 0.9852 - val_recall_1: 0.7082 - val_dice_coef: 0.7744 - val_iou: 0.6454 - val_binary_accuracy: 0.7610 - lr: 3.8742e-04\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "Epoch 11/100\n",
      "902/902 [==============================] - ETA: 0s - loss: 0.0824 - precision_1: 0.9644 - recall_1: 0.8222 - dice_coef: 0.8557 - iou: 0.7515 - binary_accuracy: 0.8356\n",
      "Save best train weights.\n",
      "902/902 [==============================] - 1070s 1s/step - loss: 0.0824 - precision_1: 0.9644 - recall_1: 0.8222 - dice_coef: 0.8557 - iou: 0.7515 - binary_accuracy: 0.8356 - val_loss: 0.1463 - val_precision_1: 0.9147 - val_recall_1: 0.9464 - val_dice_coef: 0.8939 - val_iou: 0.8137 - val_binary_accuracy: 0.8881 - lr: 3.4868e-04\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "Epoch 12/100\n",
      "902/902 [==============================] - 1054s 1s/step - loss: 0.0826 - precision_1: 0.9639 - recall_1: 0.8295 - dice_coef: 0.8590 - iou: 0.7566 - binary_accuracy: 0.8419 - val_loss: 0.1302 - val_precision_1: 0.9311 - val_recall_1: 0.9190 - val_dice_coef: 0.8907 - val_iou: 0.8099 - val_binary_accuracy: 0.8841 - lr: 3.1381e-04\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "Epoch 13/100\n",
      "902/902 [==============================] - ETA: 0s - loss: 0.0769 - precision_1: 0.9669 - recall_1: 0.8309 - dice_coef: 0.8635 - iou: 0.7636 - binary_accuracy: 0.8448\n",
      "Save best train weights.\n",
      "902/902 [==============================] - 1049s 1s/step - loss: 0.0769 - precision_1: 0.9669 - recall_1: 0.8309 - dice_coef: 0.8635 - iou: 0.7636 - binary_accuracy: 0.8448 - val_loss: 0.2643 - val_precision_1: 0.8800 - val_recall_1: 0.9557 - val_dice_coef: 0.8993 - val_iou: 0.8249 - val_binary_accuracy: 0.8640 - lr: 2.8243e-04\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 0.0002541865828329001.\n",
      "Epoch 14/100\n",
      "902/902 [==============================] - 937s 1s/step - loss: 0.0779 - precision_1: 0.9677 - recall_1: 0.8336 - dice_coef: 0.8656 - iou: 0.7671 - binary_accuracy: 0.8472 - val_loss: 0.1101 - val_precision_1: 0.9559 - val_recall_1: 0.8634 - val_dice_coef: 0.8760 - val_iou: 0.7871 - val_binary_accuracy: 0.8622 - lr: 2.5419e-04\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 0.0002287679245496101.\n",
      "Epoch 15/100\n",
      "902/902 [==============================] - ETA: 0s - loss: 0.0750 - precision_1: 0.9687 - recall_1: 0.8478 - dice_coef: 0.8734 - iou: 0.7793 - binary_accuracy: 0.8598\n",
      "Save best train weights.\n",
      "Save best val weights.\n",
      "902/902 [==============================] - 903s 1s/step - loss: 0.0750 - precision_1: 0.9687 - recall_1: 0.8478 - dice_coef: 0.8734 - iou: 0.7793 - binary_accuracy: 0.8598 - val_loss: 0.0747 - val_precision_1: 0.9753 - val_recall_1: 0.9119 - val_dice_coef: 0.9098 - val_iou: 0.8384 - val_binary_accuracy: 0.9118 - lr: 2.2877e-04\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 0.0002058911320946491.\n",
      "Epoch 16/100\n",
      "902/902 [==============================] - ETA: 0s - loss: 0.0741 - precision_1: 0.9685 - recall_1: 0.8497 - dice_coef: 0.8728 - iou: 0.7784 - binary_accuracy: 0.8604\n",
      "Save best train weights.\n",
      "902/902 [==============================] - 907s 1s/step - loss: 0.0741 - precision_1: 0.9685 - recall_1: 0.8497 - dice_coef: 0.8728 - iou: 0.7784 - binary_accuracy: 0.8604 - val_loss: 0.0852 - val_precision_1: 0.9616 - val_recall_1: 0.9206 - val_dice_coef: 0.9022 - val_iou: 0.8266 - val_binary_accuracy: 0.9085 - lr: 2.0589e-04\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 0.00018530201888518417.\n",
      "Epoch 17/100\n",
      "902/902 [==============================] - ETA: 0s - loss: 0.0699 - precision_1: 0.9700 - recall_1: 0.8512 - dice_coef: 0.8765 - iou: 0.7844 - binary_accuracy: 0.8620\n",
      "Save best train weights.\n",
      "902/902 [==============================] - 902s 1000ms/step - loss: 0.0699 - precision_1: 0.9700 - recall_1: 0.8512 - dice_coef: 0.8765 - iou: 0.7844 - binary_accuracy: 0.8620 - val_loss: 0.0880 - val_precision_1: 0.9798 - val_recall_1: 0.8613 - val_dice_coef: 0.8813 - val_iou: 0.7934 - val_binary_accuracy: 0.8767 - lr: 1.8530e-04\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 0.00016677181699666576.\n",
      "Epoch 18/100\n",
      "902/902 [==============================] - ETA: 0s - loss: 0.0694 - precision_1: 0.9719 - recall_1: 0.8574 - dice_coef: 0.8809 - iou: 0.7912 - binary_accuracy: 0.8679\n",
      "Save best train weights.\n",
      "902/902 [==============================] - 1009s 1s/step - loss: 0.0694 - precision_1: 0.9719 - recall_1: 0.8574 - dice_coef: 0.8809 - iou: 0.7912 - binary_accuracy: 0.8679 - val_loss: 0.0911 - val_precision_1: 0.9783 - val_recall_1: 0.8706 - val_dice_coef: 0.8759 - val_iou: 0.7848 - val_binary_accuracy: 0.8836 - lr: 1.6677e-04\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 0.00015009463529699917.\n",
      "Epoch 19/100\n",
      "902/902 [==============================] - 975s 1s/step - loss: 0.0700 - precision_1: 0.9720 - recall_1: 0.8615 - dice_coef: 0.8834 - iou: 0.7949 - binary_accuracy: 0.8720 - val_loss: 0.0862 - val_precision_1: 0.9606 - val_recall_1: 0.9175 - val_dice_coef: 0.9029 - val_iou: 0.8283 - val_binary_accuracy: 0.9072 - lr: 1.5009e-04\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 0.0001350851717672993.\n",
      "Epoch 20/100\n",
      "902/902 [==============================] - ETA: 0s - loss: 0.0672 - precision_1: 0.9718 - recall_1: 0.8602 - dice_coef: 0.8830 - iou: 0.7947 - binary_accuracy: 0.8703\n",
      "Save best train weights.\n",
      "902/902 [==============================] - 1017s 1s/step - loss: 0.0672 - precision_1: 0.9718 - recall_1: 0.8602 - dice_coef: 0.8830 - iou: 0.7947 - binary_accuracy: 0.8703 - val_loss: 0.1129 - val_precision_1: 0.9338 - val_recall_1: 0.9394 - val_dice_coef: 0.9101 - val_iou: 0.8404 - val_binary_accuracy: 0.9004 - lr: 1.3509e-04\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 0.00012157665459056935.\n",
      "Epoch 21/100\n",
      "902/902 [==============================] - 1050s 1s/step - loss: 0.0674 - precision_1: 0.9730 - recall_1: 0.8598 - dice_coef: 0.8843 - iou: 0.7965 - binary_accuracy: 0.8703 - val_loss: 0.0774 - val_precision_1: 0.9725 - val_recall_1: 0.8940 - val_dice_coef: 0.8930 - val_iou: 0.8111 - val_binary_accuracy: 0.8961 - lr: 1.2158e-04\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 0.00010941898913151242.\n",
      "Epoch 22/100\n",
      "902/902 [==============================] - ETA: 0s - loss: 0.0650 - precision_1: 0.9736 - recall_1: 0.8593 - dice_coef: 0.8844 - iou: 0.7971 - binary_accuracy: 0.8710\n",
      "Save best train weights.\n",
      "902/902 [==============================] - 1125s 1s/step - loss: 0.0650 - precision_1: 0.9736 - recall_1: 0.8593 - dice_coef: 0.8844 - iou: 0.7971 - binary_accuracy: 0.8710 - val_loss: 0.0752 - val_precision_1: 0.9769 - val_recall_1: 0.8938 - val_dice_coef: 0.9033 - val_iou: 0.8287 - val_binary_accuracy: 0.9006 - lr: 1.0942e-04\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 9.847709021836118e-05.\n",
      "Epoch 23/100\n",
      "902/902 [==============================] - 1091s 1s/step - loss: 0.0656 - precision_1: 0.9742 - recall_1: 0.8627 - dice_coef: 0.8880 - iou: 0.8027 - binary_accuracy: 0.8740 - val_loss: 0.0893 - val_precision_1: 0.9551 - val_recall_1: 0.9359 - val_dice_coef: 0.9167 - val_iou: 0.8511 - val_binary_accuracy: 0.9155 - lr: 9.8477e-05\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 8.862938119652506e-05.\n",
      "Epoch 24/100\n",
      "902/902 [==============================] - 1112s 1s/step - loss: 0.0669 - precision_1: 0.9728 - recall_1: 0.8664 - dice_coef: 0.8873 - iou: 0.8013 - binary_accuracy: 0.8770 - val_loss: 0.0786 - val_precision_1: 0.9762 - val_recall_1: 0.8933 - val_dice_coef: 0.8990 - val_iou: 0.8215 - val_binary_accuracy: 0.9000 - lr: 8.8629e-05\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 7.976644307687256e-05.\n",
      "Epoch 25/100\n",
      "902/902 [==============================] - ETA: 0s - loss: 0.0638 - precision_1: 0.9737 - recall_1: 0.8655 - dice_coef: 0.8880 - iou: 0.8030 - binary_accuracy: 0.8759\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 7.976643973961473e-06.\n",
      "\n",
      "Save best train weights.\n",
      "Val loss doesn't improve.\n",
      "902/902 [==============================] - 1099s 1s/step - loss: 0.0638 - precision_1: 0.9737 - recall_1: 0.8655 - dice_coef: 0.8880 - iou: 0.8030 - binary_accuracy: 0.8759 - val_loss: 0.0803 - val_precision_1: 0.9849 - val_recall_1: 0.8678 - val_dice_coef: 0.8919 - val_iou: 0.8103 - val_binary_accuracy: 0.8876 - lr: 7.9766e-05\n",
      "Epoch 00025: early stopping\n"
     ]
    }
   ],
   "source": [
    "from models import loss\n",
    "from models.metrics import iou, dice_coef\n",
    "from models.callback.save_best import SavebestweightsandEarlyStopping\n",
    "\n",
    "model_name = 'ffnet'\n",
    "mission = 'road'\n",
    "img_size = 256\n",
    "num_class = 1 \n",
    "batch_size = 2\n",
    "\n",
    "def lr_decay(epoch):\n",
    "    initial_learningrate=1e-3\n",
    "    if epoch < 1:\n",
    "        return initial_learningrate\n",
    "    else:\n",
    "        return initial_learningrate * 0.9 ** (epoch)\n",
    "\n",
    "if batch_size >1:\n",
    "    val_batch_size = int(batch_size/2)\n",
    "else:\n",
    "    val_batch_size = batch_size\n",
    "    \n",
    "print(\"Init metric function\")\n",
    "if num_class==1:\n",
    "    recall = tf.keras.metrics.Recall()\n",
    "    precision = tf.keras.metrics.Precision()\n",
    "    model_metrics = [precision, recall, dice_coef, iou, tf.keras.metrics.BinaryAccuracy(threshold=0.5)]\n",
    "else:\n",
    "    recall = tf.keras.metrics.Recall()\n",
    "    precision = tf.keras.metrics.Precision()\n",
    "    accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "    model_metrics = [precision, recall, dice_coef, iou, accuracy]\n",
    "    \n",
    "checkpoint_filepath= '/home/quyet/DATA_ML/Projects/segmentation/logs/tmp'\n",
    "log_dir = '/home/quyet/DATA_ML/Projects/segmentation/logs/graph'\n",
    "weights_path = '/home/quyet/DATA_ML/WorkSpace/segmentation/weights/%s/'%(model_name) +model_name+'_'+mission+'_'+str(img_size)+'_'+str(num_class)+'class.h5'\n",
    "patience = 10\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only= True, \n",
    "                                                                monitor='val_loss', mode='min', save_best_only=True)\n",
    "model_lrscheduler_callback = tf.keras.callbacks.LearningRateScheduler(lr_decay, verbose=1)\n",
    "model_lrreduce_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=patience, min_lr=1e-7, verbose=1)\n",
    "model_earlystopping_callback = SavebestweightsandEarlyStopping(patience=patience, weights_path=weights_path)\n",
    "model_endtrainnan_callback = tf.keras.callbacks.TerminateOnNaN()\n",
    "model_tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=True)\n",
    "model_callbacks = [model_checkpoint_callback, model_lrscheduler_callback,\n",
    "                    model_lrreduce_callback, model_earlystopping_callback,\n",
    "                    model_tensorboard_callback,]\n",
    "\n",
    "model = FF_UNet(attention_gates=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer = optimizer, loss = loss.balanced_cross_entropy_loss,\n",
    "             metrics = model_metrics)\n",
    "\n",
    "# model.load_weights('/home/quyet/DATA_ML/WorkSpace/segmentation/weights/ffnet/ffnet_road_256_1class_val.h5')\n",
    "history_train = model.fit(train_dataset, batch_size=batch_size, epochs=100, verbose=1, \n",
    "                      callbacks=model_callbacks, validation_data=valid_dataset, \n",
    "                      validation_batch_size=val_batch_size, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aa1fd64-a04a-422c-8fdb-217fb5270d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6237, 6126, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 960/960 [01:44<00:00,  9.14it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from osgeo import gdal\n",
    "from postprocess.convert_tif import dilation_obj, remove_small_items, write_image\n",
    "\n",
    "def get_im_by_coord(org_im, start_x, start_y,num_band, padding, crop_size, input_size):\n",
    "    startx = start_x-padding\n",
    "    endx = start_x+crop_size+padding\n",
    "    starty = start_y - padding\n",
    "    endy = start_y+crop_size+padding\n",
    "    result=[]\n",
    "    img = org_im[starty:endy, startx:endx]\n",
    "    img = img.swapaxes(2,1).swapaxes(1,0)\n",
    "    for chan_i in range(num_band):\n",
    "        result.append(cv2.resize(img[chan_i],(input_size, input_size), interpolation = cv2.INTER_CUBIC))\n",
    "    return np.array(result).swapaxes(0,1).swapaxes(1,2)\n",
    "\n",
    "def get_img_coords(w, h, padding, crop_size):\n",
    "    new_w = w + 2*padding\n",
    "    new_h = h + 2*padding\n",
    "    cut_w = list(range(padding, new_w - padding, crop_size))\n",
    "    cut_h = list(range(padding, new_h - padding, crop_size))\n",
    "\n",
    "    list_hight = []\n",
    "    list_weight = []\n",
    "    for i in cut_h:\n",
    "        if i < new_h - padding - crop_size:\n",
    "            list_hight.append(i)\n",
    "    list_hight.append(new_h-crop_size-padding)\n",
    "\n",
    "    for i in cut_w:\n",
    "        if i < new_w - crop_size - padding:\n",
    "            list_weight.append(i)\n",
    "    list_weight.append(new_w-crop_size-padding)\n",
    "\n",
    "    img_coords = []\n",
    "    for i in list_weight:\n",
    "        for j in list_hight:\n",
    "            img_coords.append([i, j])\n",
    "    return img_coords\n",
    "\n",
    "def padded_for_org_img(values, num_band, padding):\n",
    "    padded_org_im = []\n",
    "    for i in range(num_band):\n",
    "        band = np.pad(values[i], padding, mode='reflect')\n",
    "        padded_org_im.append(band)\n",
    "\n",
    "    values = np.array(padded_org_im).swapaxes(0,1).swapaxes(1,2)\n",
    "    print(values.shape)\n",
    "    del padded_org_im\n",
    "    return values\n",
    "\n",
    "def predict(model, values, img_coords, num_band, h, w, padding, crop_size, \n",
    "            input_size, batch_size, thresh_hold, choose_stage):\n",
    "    cut_imgs = []\n",
    "    for i in range(len(img_coords)):\n",
    "        im = get_im_by_coord(values, img_coords[i][0], img_coords[i][1],\n",
    "                            num_band,padding, crop_size, input_size)\n",
    "        cut_imgs.append(im)\n",
    "\n",
    "    a = list(range(0, len(cut_imgs), batch_size))\n",
    "\n",
    "    if a[len(a)-1] != len(cut_imgs):\n",
    "        a[len(a)-1] = len(cut_imgs)\n",
    "\n",
    "    y_pred = []\n",
    "    for i in tqdm(range(len(a)-1)):\n",
    "        x_batch = []\n",
    "        x_batch = np.array(cut_imgs[a[i]:a[i+1]])\n",
    "        # print(x_batch.shape)\n",
    "        img_edge = []\n",
    "        # for img_x in x_batch:\n",
    "        #     lab_batch = color.rgb2lab(img_x)  \n",
    "            # img_edge.append(cv2.Canny(np.asarray(np.uint8(lab_batch)),0,0)[..., np.newaxis])\n",
    "        # print(img_edge.shape)\n",
    "        # img_edge = np.array(img_edge)\n",
    "        \n",
    "        # print(x_batch.shape, img_edge.shape)\n",
    "        # y_batch = model.predict((x_batch/255, img_edge/255))\n",
    "        y_batch = model.predict(x_batch/255)\n",
    "        if len(model.outputs)>1:\n",
    "            y_batch = y_batch[choose_stage]\n",
    "        mutilabel = False\n",
    "        if y_batch.shape[-1]>=2:\n",
    "            mutilabel = True\n",
    "            y_batch = np.argmax(y_batch, axis=-1)\n",
    "        # print(np.unique(y_batch), y_batch.shape)\n",
    "            \n",
    "        y_pred.extend(y_batch)\n",
    "    big_mask = np.zeros((h, w)).astype(np.float16)\n",
    "    for i in range(len(cut_imgs)):\n",
    "        true_mask = y_pred[i].reshape((input_size,input_size))\n",
    "        if not mutilabel:\n",
    "            true_mask = (true_mask>thresh_hold).astype(np.uint8)\n",
    "            true_mask = (cv2.resize(true_mask,(input_size, input_size), interpolation = cv2.INTER_CUBIC)>thresh_hold).astype(np.uint8)\n",
    "            # true_mask = true_mask.astype(np.float16)\n",
    "        start_x = img_coords[i][1]\n",
    "        start_y = img_coords[i][0]\n",
    "        big_mask[start_x-padding:start_x-padding+crop_size, start_y-padding:start_y -\n",
    "                    padding+crop_size] = true_mask[padding:padding+crop_size, padding:padding+crop_size]\n",
    "    del cut_imgs\n",
    "    return big_mask\n",
    "\n",
    "img_size = 256\n",
    "num_band = 3\n",
    "crop_size = 200\n",
    "batch_size = 1\n",
    "thresh_hold = 0.8\n",
    "choose_stage = 0\n",
    "\n",
    "model.load_weights('/home/quyet/DATA_ML/WorkSpace/segmentation/weights/ffnet/ffnet_road_256_1class_train.h5')\n",
    "image_path = '/home/quyet/DATA_ML/Projects/road_multi/crop/img/test.tif'\n",
    "dataset = gdal.Open(image_path)\n",
    "values = dataset.ReadAsArray()[0:num_band]\n",
    "h,w = values.shape[1:3]    \n",
    "padding = int((img_size - crop_size)/2)\n",
    "img_coords = get_img_coords(w, h, padding, crop_size)\n",
    "values = padded_for_org_img(values, num_band, padding)\n",
    "big_mask = predict(model, values, img_coords, num_band, h, w, padding, crop_size, \n",
    "                    img_size, batch_size, thresh_hold, choose_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "528aa0c7-8255-4878-8926-fc817bcb126c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write image...\n"
     ]
    }
   ],
   "source": [
    "image_path = '/home/quyet/DATA_ML/Projects/road_multi/crop/img/test.tif'\n",
    "result_path = write_image(image_path, big_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4420c1c2-6508-4279-8fc0-5fae2cce78c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
