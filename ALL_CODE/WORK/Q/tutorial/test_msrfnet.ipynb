{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ef0309e-d849-4a90-8218-d7e41c30b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7352bba-a4ca-44a9-814f-31ed03b3681e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import fiona\n",
    "from skimage import color\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import rasterio.mask\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import utils\n",
    "from preprocess.argument_utils import data_augment\n",
    " \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def remove_empty(shp_path):\n",
    "    for _ in glob.glob(shp_path):\n",
    "        with fiona.open(_, \"r\") as shapefile:\n",
    "            features = [f[\"geometry\"] for f in shapefile]\n",
    "        if all(x is None for x in features):\n",
    "            try:\n",
    "                os.remove(_)\n",
    "                os.remove(_.replace('shp', 'dbf'))\n",
    "                os.remove(_.replace('shp', 'prj'))\n",
    "                os.remove(_.replace('shp', 'shx'))\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                extend = _.split('/')[-2].replace('crop_shape','crop')\n",
    "                os.remove(_.replace('shp', 'tif').replace(_.split('/')[-2], extend))\n",
    "            except:\n",
    "                pass\n",
    "        shapefile.close\n",
    "\n",
    "class generator_train(utils.Sequence):\n",
    "    def __init__(self, file_names, batch_size, N_CLASSES, numband):\n",
    "        self.file_names = file_names\n",
    "        self.batch_size = batch_size\n",
    "        self.N_CLASSES = N_CLASSES\n",
    "        self.numband = numband\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.file_names) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path_mask = self.file_names[index]\n",
    "        path_img = path_mask.replace('mask_cut_crop','img_cut_crop')\n",
    "        mask = rasterio.open(path_mask).read().swapaxes(0,1).swapaxes(1,2)\n",
    "        image = rasterio.open(path_img).read().swapaxes(0,1).swapaxes(1,2)\n",
    "        image = image[:,:,:self.numband]\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image, mask = data_augment(image, mask[:,:,0], self.N_CLASSES)\n",
    "        \n",
    "        _, image_size_height, image_size_wight = image.shape\n",
    "        lab = color.rgb2lab(image)\n",
    "        img_edge = cv2.Canny(np.asarray(np.uint8(lab)),0,0)\n",
    "        \n",
    "        mask_edge =  cv2.Canny(np.asarray(np.uint8(mask*255)),10,1000)\n",
    "        return image/255.0, img_edge/255.0, mask, mask_edge/255.0\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.file_names)\n",
    "\n",
    "class generator_valid(utils.Sequence):\n",
    "    def __init__(self, file_names, batch_size, N_CLASSES, numband):\n",
    "        self.file_names = file_names\n",
    "        self.batch_size = batch_size\n",
    "        self.N_CLASSES = N_CLASSES\n",
    "        self.numband = numband\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.file_names) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path_mask = self.file_names[index]\n",
    "        path_img = path_mask.replace('mask_cut_crop','img_cut_crop')\n",
    "        mask = rasterio.open(path_mask).read().swapaxes(0,1).swapaxes(1,2)\n",
    "        image = rasterio.open(path_img).read().swapaxes(0,1).swapaxes(1,2)\n",
    "        image = image[:,:,:self.numband]\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        mask = tf.cast(mask, tf.uint8)\n",
    "        mask = tf.one_hot(mask[:,:,0], depth=self.N_CLASSES)\n",
    "        \n",
    "        _, image_size_height, image_size_wight = image.shape\n",
    "        lab = color.rgb2lab(image)\n",
    "        img_edge = cv2.Canny(np.asarray(np.uint8(lab)),0,0)\n",
    "        \n",
    "        mask_edge =  cv2.Canny(np.asarray(np.uint8(mask*255)),10,1000)\n",
    "        return image/255.0, img_edge/255.0, mask, mask_edge/255.0\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.file_names)\n",
    "        \n",
    "def input_fn(file_names, image_size, batch_size, N_CLASSES, numband ,train=True):\n",
    "    def generator_fn():\n",
    "        if train:\n",
    "            generator = utils.OrderedEnqueuer(generator_train(file_names, batch_size, N_CLASSES, numband), False)\n",
    "        else:\n",
    "            generator = utils.OrderedEnqueuer(generator_valid(file_names, batch_size, N_CLASSES, numband), False)\n",
    "        generator.start()\n",
    "        \n",
    "        n = 0\n",
    "        while n<int(len(file_names)):\n",
    "            image, img_edge, mask, mask_edge = generator.get().__next__()\n",
    "            yield ((image, img_edge), (mask, mask_edge, mask, mask))\n",
    "            n+=1\n",
    "\n",
    "    output_types = ((tf.float32, tf.float32), (tf.float32, tf.float32, tf.float32, tf.float32))\n",
    "    output_shapes = (((image_size, image_size, numband),\n",
    "                     (image_size, image_size)),\n",
    "                     ((image_size, image_size, N_CLASSES),\n",
    "                    (image_size, image_size),\n",
    "                     (image_size, image_size, N_CLASSES),\n",
    "                     (image_size, image_size, N_CLASSES)),)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(generator=generator_fn,\n",
    "                                             output_types=output_types,\n",
    "                                             output_shapes=output_shapes)\n",
    "    dataset = dataset.repeat(1)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def data_gen(mask_path, img_size, batch_size, N_CLASSES, numband, split_ratios, test_data=False, multi=False):\n",
    "    # print(mask_path)\n",
    "    mask_img = sorted(glob.glob(mask_path))\n",
    "    np.random.shuffle(mask_img)\n",
    "    L = len(mask_img)\n",
    "    if multi:\n",
    "        if test_data:\n",
    "            L_train = int(split_ratios*L)\n",
    "            L_valid = int((1-split_ratios)/2*L)\n",
    "            L_test = L - L_train - L_valid\n",
    "            train_dataset = input_fn_multi(mask_img[:L_train], img_size, batch_size, N_CLASSES, numband)\n",
    "            valid_dataset = input_fn_multi(mask_img[L_train:L_train+L_valid], img_size, batch_size, N_CLASSES, numband, False)\n",
    "            test_dataset = input_fn_multi(mask_img[L_train+L_valid:L], img_size, batch_size, N_CLASSES, numband, False)\n",
    "            print(\"Training:validation:testing = {}:{}:{}\".format(L_train, L_valid, L_test))\n",
    "            return train_dataset, valid_dataset, test_dataset, L_train, L_valid, L_test\n",
    "        else:\n",
    "            L_train = int(split_ratios*L)\n",
    "            L_valid = int(L-L_train)\n",
    "            train_dataset = input_fn_multi(mask_img[:L_train], img_size, batch_size, N_CLASSES, numband)\n",
    "            valid_dataset = input_fn_multi(mask_img[L_train:L], img_size, batch_size, N_CLASSES, numband, False)\n",
    "            print(\"Training:validation = {}:{}\".format(L_train, L_valid))\n",
    "        return train_dataset, valid_dataset, L_train, L_valid\n",
    "    else:\n",
    "        if test_data:\n",
    "            L_train = int(split_ratios*L)\n",
    "            L_valid = int((1-split_ratios)/2*L)\n",
    "            L_test = L - L_train - L_valid\n",
    "            train_dataset = input_fn(mask_img[:L_train], img_size, batch_size, N_CLASSES, numband)\n",
    "            valid_dataset = input_fn(mask_img[L_train:L_train+L_valid], img_size, batch_size, N_CLASSES, numband, False)\n",
    "            test_dataset = input_fn(mask_img[L_train+L_valid:L], img_size, batch_size, N_CLASSES, numband, False)\n",
    "            print(\"Training:validation:testing = {}:{}:{}\".format(L_train, L_valid, L_test))\n",
    "            return train_dataset, valid_dataset, test_dataset, L_train, L_valid, L_test\n",
    "        else:\n",
    "            L_train = int(split_ratios*L)\n",
    "            L_valid = int(L-L_train)\n",
    "            train_dataset = input_fn(mask_img[:L_train], img_size, batch_size, N_CLASSES, numband)\n",
    "            if L_train == L:\n",
    "                valid_dataset = input_fn(mask_img[int(L_train*0.8):L], img_size, batch_size, N_CLASSES, numband, False)\n",
    "                print(\"Training:validation = {}:{}\".format(L_train, L-int(L_train*0.8)))\n",
    "            else:\n",
    "                valid_dataset = input_fn(mask_img[L_train:L], img_size, batch_size, N_CLASSES, numband, False)\n",
    "                print(\"Training:validation = {}:{}\".format(L_train, L_valid))\n",
    "        return train_dataset, valid_dataset, L_train, L_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ae47f78-bab8-4c6f-af29-63ac4005a98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:validation = 1804:452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 09:16:00.679616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4795 MB memory:  -> device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:05:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "out_path = '/home/quyet/DATA_ML/WorkSpace/segmentation/data/road_multi'\n",
    "overlap_mask = os.path.join(out_path, 'mask_cut_crop')\n",
    "train_dataset, valid_dataset, _, _ = data_gen(os.path.join(overlap_mask, '*.tif'), img_size=256, \n",
    "                                                            batch_size=2, N_CLASSES=1, numband=3, \n",
    "                                                            split_ratios=0.8, test_data=False, multi=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddc500e5-03a6-45b2-8a7d-0a1116a4d975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "np.random.seed(123)\n",
    "import warnings\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout,Input,Average,Conv2DTranspose,SeparableConv2D,dot,UpSampling2D,Add, Flatten,Concatenate,Multiply,Conv2D, MaxPooling2D,Activation,AveragePooling2D, ZeroPadding2D,GlobalAveragePooling2D,multiply,DepthwiseConv2D,ZeroPadding2D,GlobalAveragePooling2D,concatenate ,Lambda\n",
    "from keras.initializers import RandomNormal\n",
    "\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Model\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "import tifffile as tif\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from keras.optimizers import Adam, Nadam\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "import skimage.io\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from skimage.color import rgb2gray\n",
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=1.0)\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "# sess = tf.compat.v1.Session()\n",
    "\n",
    "def spatial_att_block(x,intermediate_channels):\n",
    "    out = Conv2D(intermediate_channels,kernel_size=(1,1),strides=(1,1),padding='same', kernel_initializer = 'he_normal')(x)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('relu')(out)\n",
    "    out = Conv2D(1,kernel_size=(1,1),strides=(1,1),padding='same', kernel_initializer = 'he_normal')(out)\n",
    "    out = Activation('sigmoid')(out)\n",
    "    return out\n",
    "    \n",
    "def resblock(x,ip_channels,op_channels,stride=(1,1)):\n",
    "    residual = x\n",
    "    out = Conv2D(op_channels,kernel_size=(3,3),strides=stride,padding='same', kernel_initializer = 'he_normal')(x)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Activation('relu')(out)\n",
    "    out = Conv2D(op_channels,kernel_size=(3,3),strides=stride,padding='same', kernel_initializer = 'he_normal')(x)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Add()([out,residual])\n",
    "    out = Activation('relu')(out)\n",
    "    return out\n",
    "\n",
    "def dual_att_blocks(skip,prev,out_channels):\n",
    "    up = Conv2DTranspose(out_channels,4, strides=(2, 2), padding='same')(prev)\n",
    "    up = BatchNormalization()(up)\n",
    "    up = Activation('relu')(up)\n",
    "    inp_layer = Concatenate()([skip,up])\n",
    "    inp_layer = Conv2D(out_channels,3,strides=(1,1),padding='same', kernel_initializer = 'he_normal')(inp_layer)\n",
    "    inp_layer = BatchNormalization()(inp_layer)\n",
    "    inp_layer = Activation('relu')(inp_layer)\n",
    "    se_out = se_block(inp_layer,out_channels)\n",
    "    sab = spatial_att_block(inp_layer,out_channels//4)\n",
    "    #sab = Add()([sab,1])\n",
    "    sab = Lambda(lambda y : y+1)(sab)\n",
    "    final = Multiply()([sab,se_out])\n",
    "    return final\n",
    "    \n",
    "\n",
    "def gsc(input_features,gating_features,in_channels,out_channels,kernel_size=1,stride=1,dilation=1,groups=1):\n",
    "    x = Concatenate()([input_features,gating_features])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(in_channels+1, (1,1), strides =(1,1), padding='same', kernel_initializer = 'he_normal')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(1,kernel_size=(1,1),strides=1,padding='same', kernel_initializer = 'he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    return x\n",
    "\n",
    "def se_block(in_block, ch, ratio=16):\n",
    "    x = GlobalAveragePooling2D()(in_block)\n",
    "    x = Dense(ch//ratio, activation='relu')(x)\n",
    "    x = Dense(ch, activation='sigmoid')(x)\n",
    "    return Multiply()([in_block, x])\n",
    "\n",
    "def Attention_B(X, G, k):\n",
    "    FL = int(X.shape[-1])\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    theta = Conv2D(k,(2,2), strides = (2,2), padding='same')(X)\n",
    "    Phi = Conv2D(k, (1,1), strides =(1,1), padding='same', use_bias=True)(G)\n",
    "   \n",
    "    ADD = Add()([theta, Phi])\n",
    "    ADD = Activation('relu')(ADD)\n",
    "    Psi = Conv2D(1,(1,1), strides = (1,1), padding=\"same\",kernel_initializer=init)(ADD)\n",
    "    Psi = Activation('sigmoid')(Psi)\n",
    "    Up = Conv2DTranspose(1, (2,2), strides=(2, 2), padding='valid')(Psi)\n",
    "    Final = Multiply()([X, Up])\n",
    "    Final = BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-5)(Final)\n",
    "    print(Final.shape)\n",
    "    return Final\n",
    "def Unet3(input_shape,n_filters,kernel=(3,3),strides=(1,1),pad='same'):\n",
    "    x = input_shape\n",
    "    conv1 = Conv2D(n_filters,kernel_size=kernel,strides=strides,padding=pad, kernel_initializer = 'he_normal')(input_shape)\n",
    "    conv1 = BatchNormalization(axis=-1)(conv1)\n",
    "    conv1 = LeakyReLU(alpha=0.1)(conv1)\n",
    "   \n",
    "    conv2 = Conv2D(n_filters,kernel_size=kernel,strides=strides,padding=pad, kernel_initializer = 'he_normal')(conv1)\n",
    "    conv2 = BatchNormalization(axis=-1)(conv2)\n",
    "    conv2 =  LeakyReLU(alpha=0.1)(conv2)\n",
    "   \n",
    "    x = Conv2D(n_filters,kernel_size = (1,1),strides = (1,1),padding = 'same', kernel_initializer = 'he_normal')(x)\n",
    "   \n",
    "    return Add()([x,conv2])\n",
    "def Up3(input1,input2,kernel=(3,3),stride=(1,1), pad='same'):\n",
    "    #up = UpSampling2D(2)(input2)\n",
    "    up = Conv2DTranspose(int(input1.shape[-1]),(1, 1), strides=(2, 2), padding='same', kernel_initializer = 'he_normal')(input2)\n",
    "    up = Concatenate()([up,input1])\n",
    "    \n",
    "    #up1 = BatchNormalization()(up)\n",
    "    #up1 =  LeakyReLU(alpha=0.25)(up1)\n",
    "    #up1 = Conv2D(int(input1.shape[-1]),kernel_size=(3,3),strides=(1,1),padding='same')(up1)\n",
    "    #up1 = BatchNormalization()(up1)\n",
    "    #up1 =  LeakyReLU(alpha=0.25)(up1)\n",
    "    #up1 = Conv2D(int(input1.shape[-1]),kernel_size=(3,3),strides=(1,1),padding='same')(up1)\n",
    "    #up2 = Add()([up1,up])\n",
    "    return up\n",
    "    \n",
    "    return Unet3(up,int(input1.shape[-1]),kernel,stride,pad)\n",
    "def gatingSig(input_shape,n_filters,kernel=(1,1),strides=(1,1),pad='same'):\n",
    "    conv = Conv2D(n_filters,kernel_size=kernel,strides=strides,padding=pad, kernel_initializer = 'he_normal')(input_shape)\n",
    "    conv = BatchNormalization(axis=-1)(conv)\n",
    "    return LeakyReLU(alpha=0.1)(conv)\n",
    "\n",
    "def DSup(x, var):\n",
    "    d = Conv2D(1,(1,1), strides=(1,1), padding = \"same\", kernel_initializer = 'he_normal')(x)\n",
    "    d = UpSampling2D(var)(d)\n",
    "    return d\n",
    "\n",
    "def DSup1(x, var):\n",
    "    d = Conv2D(1,(2,2), strides=(2,2), padding = \"same\", kernel_initializer = 'he_normal')(x)\n",
    "    d = UpSampling2D(var)(d)\n",
    "    return d\n",
    "\n",
    "#Keras\n",
    "\n",
    "\n",
    "def msrf(input_size=(512,512,3),input_size_2=(512,512,1)):\n",
    "    n_labels=1\n",
    "    feature_scale=8\n",
    "    #input_shape= Image.shape\n",
    "    filters = [64, 128, 256, 512,1024]\n",
    "    atrous_rates = (6, 12, 18)\n",
    "    n_labels=1\n",
    "    feature_scale=8\n",
    "    #input_shape= Image.shape\n",
    "    filters = [64, 128, 256, 512,1024]\n",
    "\n",
    "    inputs_img = Input(input_size)\n",
    "    inputs_img = tf.image.resize(inputs_img, size=(256,256))\n",
    "    canny = Input(input_size_2, name='checkdim')\n",
    "    canny = tf.image.resize(canny, size=(256,256))\n",
    "    n11 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs_img)\n",
    "    n11 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(n11)\n",
    "    n11 = BatchNormalization()(n11)\n",
    "    n11 = se_block(n11,32)\n",
    "\n",
    "    \n",
    "    n12 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(n11)\n",
    "    n12 = BatchNormalization()(n12)\n",
    "    #here\n",
    "    n12 = Add()([n12,n11])\n",
    "    pred1 = Conv2D(1,(1,1), strides=(1,1), padding=\"same\",activation='sigmoid', kernel_initializer = 'he_normal')(n12)\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(n11)\n",
    "    pool1 = Dropout(0.2)(pool1)\n",
    "    n21 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    n21 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(n21)\n",
    "    n21 = BatchNormalization()(n21)\n",
    "    n21 = se_block(n21,64)\n",
    "    #here\n",
    "    \n",
    "    \n",
    "    n22 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(n21)\n",
    "    n22 = BatchNormalization()(n22)\n",
    "    n22 = Add()([n22,n21])\n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(n21)\n",
    "    pool2 = Dropout(0.2)(pool2)\n",
    "    \n",
    "    n31 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    n31 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(n31)\n",
    "    n31 = BatchNormalization()(n31)\n",
    "    n31 = se_block(n31,128)\n",
    "   \n",
    "    \n",
    "    n32 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(n31)\n",
    "    n32 = BatchNormalization()(n32)\n",
    "    n32 = Add()([n32,n31])\n",
    "    \n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(n31)\n",
    "    pool3 = Dropout(0.2)(pool3)\n",
    "    n41 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    n41 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(n41)\n",
    "    n41 = BatchNormalization()(n41)\n",
    "    #############################################ASPP\n",
    "    shape_before = n41.shape\n",
    "    \n",
    "    \n",
    "    \n",
    "    #############################################\n",
    "    \n",
    "    n12,n22 = RDDB(n11,n21,32,64,16)\n",
    "    # pred2 = Conv2D(1,(1,1), strides=(1,1), padding=\"same\",activation='sigmoid')(n12)\n",
    "    \n",
    "    n32,n42 = RDDB(n31,n41,128,256,64)\n",
    "    \n",
    "    n12,n22 = RDDB(n12,n22,32,64,16)\n",
    "    # pred3 = Conv2D(1,(1,1), strides=(1,1), padding=\"same\",activation='sigmoid')(n12)\n",
    "    \n",
    "    n32,n42 = RDDB(n32,n42,128,256,64)\n",
    "    \n",
    "    n22,n32 = RDDB(n22,n32,64,128,32)\n",
    "    \n",
    "    \n",
    "    n13,n23 = RDDB(n12,n22,32,64,16)\n",
    "    \n",
    "    n33,n43 = RDDB(n32,n42,128,256,64)\n",
    "    \n",
    "    n23,n33 = RDDB(n23,n33,64,128,32)\n",
    "    \n",
    "    n13,n23 = RDDB(n12,n22,32,64,16)\n",
    "    \n",
    "    n33,n43 = RDDB(n32,n42,128,256,64)\n",
    "    \n",
    "    n13 = Lambda(lambda x: x * 0.4)(n13)\n",
    "    n23 = Lambda(lambda x: x * 0.4)(n23)\n",
    "    n33 = Lambda(lambda x: x * 0.4)(n33)\n",
    "    n43 = Lambda(lambda x: x * 0.4)(n43)\n",
    "    \n",
    "    \n",
    "    n13,n23 = Add()([n11,n13]),Add()([n21,n23])\n",
    "    n33,n43 = Add()([n31,n33]),Add()([n41,n43])\n",
    "\n",
    "    ###############Shape Stream\n",
    "\n",
    "    \n",
    "    d0 = Conv2D(32,kernel_size=(1,1),strides=(1,1),padding='same', kernel_initializer = 'he_normal')(n23)\n",
    "    ss = keras.layers.UpSampling2D(size=(2, 2), data_format=None, interpolation='bilinear')(d0)\n",
    "    ss = resblock(ss,32,32)\n",
    "    c3 = Conv2D(1, kernel_size=(1,1),strides=(1,1),padding='same', kernel_initializer = 'he_normal')(n33)\n",
    "    c3 = keras.layers.UpSampling2D(size=(4, 4), data_format=None, interpolation='bilinear')(c3)\n",
    "    ss = Conv2D(16,kernel_size=(1,1),strides=(1,1),padding='same', kernel_initializer = 'he_normal')(ss)\n",
    "    ss = gsc(ss,c3,32,32)\n",
    "    ss = resblock(ss,16,16)\n",
    "    ss = Conv2D(8,kernel_size=(1,1),strides=(1,1),padding='same', kernel_initializer = 'he_normal')(ss)\n",
    "    c4 = Conv2D(1, kernel_size=(1,1),strides=(1,1),padding='same', kernel_initializer = 'he_normal')(n43)\n",
    "    c4 = keras.layers.UpSampling2D(size=(8, 8), data_format=None, interpolation='bilinear')(c4)\n",
    "    ss = gsc(ss,c4,16,16)\n",
    "    ss = resblock(ss,8,8)\n",
    "    ss = Conv2D(4,kernel_size=(1,1),strides=(1,1),padding='same', kernel_initializer = 'he_normal')(ss)\n",
    "    ss = Conv2D(1,kernel_size=(1,1),padding='same', kernel_initializer = 'he_normal')(ss)\n",
    "    edge_out = Activation('sigmoid',name='edge_out')(ss)\n",
    "\n",
    "    #######canny edge\n",
    "    # canny = cv2.Canny(np.asarray(canny),10,100)\n",
    "    cat = Concatenate()([edge_out,canny])\n",
    "    cw = Conv2D(1,kernel_size=(1,1),padding='same', kernel_initializer = 'he_normal')(cat)\n",
    "    acts = Activation('sigmoid')(cw)\n",
    "    edge = Conv2D(1, kernel_size=(1,1),strides=(1,1),padding='same', kernel_initializer = 'he_normal')(acts)\n",
    "    edge = BatchNormalization()(edge)\n",
    "    edge = Activation('relu')(edge)\n",
    "    \n",
    "    \n",
    "    #########################\n",
    "    \n",
    "   \n",
    "    n34_preinput=Attention_B(n33,n43,128)\n",
    "    n34 = Up3(n34_preinput,n43)\n",
    "    n34_d = dual_att_blocks(n33,n43,128)\n",
    "    n34_t = Concatenate()([n34,n34_d])\n",
    "    n34_t = Conv2D(128,kernel_size=(1,1),strides=(1,1),padding='same', kernel_initializer = 'he_normal')(n34_t)\n",
    "    n34_2 = BatchNormalization()(n34_t)\n",
    "    n34_2 = Activation('relu')(n34_2)\n",
    "    n34_2 = Conv2D(128,kernel_size=(3,3),strides=(1,1),padding='same', kernel_initializer = 'he_normal')(n34_2)\n",
    "    n34_2 = BatchNormalization()(n34_2)\n",
    "    n34_2 = Activation('relu')(n34_2)\n",
    "    n34_2 = Conv2D(128,kernel_size=(3,3),strides=(1,1),padding='same', kernel_initializer = 'he_normal')(n34_2)\n",
    "    n34 = Add()([n34_2,n34_t])\n",
    "    pred4 = Conv2D(1,kernel_size=(1,1),strides=(1,1),padding='same',activation=\"sigmoid\", kernel_initializer = 'he_normal')(n34)\n",
    "    pred4 = UpSampling2D(size=(4,4),interpolation='bilinear',name='pred4')(pred4)\n",
    "\n",
    "    \n",
    "   \n",
    "    n24_preinput =Attention_B(n23,n34,64)\n",
    "    n24 = Up3(n24_preinput,n34)\n",
    "    n24_d = dual_att_blocks(n23,n34,64)\n",
    "    n24_t = Concatenate()([n24,n24_d])\n",
    "    n24_t = Conv2D(64,kernel_size=(1,1),strides=(1,1),padding='same', kernel_initializer = 'he_normal')(n24_t)\n",
    "    n24_2 = BatchNormalization()(n24_t)\n",
    "    n24_2 = Activation('relu')(n24_2)\n",
    "    n24_2 = Conv2D(64,kernel_size=(3,3),strides=(1,1),padding='same', kernel_initializer = 'he_normal')(n24_2)\n",
    "    n24_2 = BatchNormalization()(n24_2)\n",
    "    n24_2 = Activation('relu')(n24_2)\n",
    "    n24_2 = Conv2D(64,kernel_size=(3,3),strides=(1,1),padding='same', kernel_initializer = 'he_normal')(n24_2)\n",
    "    n24 = Add()([n24_2,n24_t])\n",
    "    pred2 = Conv2D(1,kernel_size=(1,1),strides=(1,1),padding=\"same\" , activation=\"sigmoid\", kernel_initializer = 'he_normal')(n24)\n",
    "    pred2 = UpSampling2D(size=(2,2),interpolation='bilinear',name='pred2')(pred2)\n",
    "   \n",
    "    n14_preinput = Conv2DTranspose(32,4, strides=(2, 2), padding='same')(n24)\n",
    "    n14_input = Concatenate()([n14_preinput,n13])\n",
    "    n14_input = Conv2D(32, 1, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(n14_input)\n",
    "    n14 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(n14_input)\n",
    "    n14 = BatchNormalization()(n14)\n",
    "    n14 = Add()([n14,n14_input])\n",
    "    n14 = Concatenate()([n14,edge])\n",
    "    n14 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(n14)\n",
    "    n14 = BatchNormalization()(n14)\n",
    "    x = Conv2D(1,(1,1), strides=(1,1), padding=\"same\",activation='sigmoid',name='x', kernel_initializer = 'he_normal')(n14)\n",
    "    \n",
    "    model = Model(inputs= [inputs_img,canny],outputs = [x, edge_out, pred2, pred4])\n",
    "    return model\n",
    "\n",
    "def RDDB(x,y,nf1=128,nf2=1212,gc=64,bias=True):\n",
    "    x1 = Conv2D(filters=gc, kernel_size=3, strides=1,padding='same', use_bias=bias, kernel_initializer = 'he_normal')(x)\n",
    "    x1 = LeakyReLU(alpha=0.25)(x1)\n",
    "    \n",
    "    y1 = Conv2D(filters=gc, kernel_size=3, strides=1,padding='same', use_bias=bias, kernel_initializer = 'he_normal')(y)\n",
    "    y1 = LeakyReLU(alpha=0.25)(y)\n",
    "    \n",
    "    x1c = Conv2D(filters=gc, kernel_size=3, strides=2,padding='same', use_bias=bias, kernel_initializer = 'he_normal')(x)\n",
    "    x1c = LeakyReLU(alpha=0.25)(x1c)\n",
    "    y1t = Conv2DTranspose(filters=gc, kernel_size=3, strides=2,padding='same', use_bias=bias)(y)\n",
    "    y1t = LeakyReLU(alpha=0.25)(y1t)\n",
    "    \n",
    "    \n",
    "    x2_input = concatenate([x,x1,y1t],axis=-1)\n",
    "    x2 = Conv2D(filters= gc, kernel_size=3,strides=1, padding='same',use_bias=bias, kernel_initializer = 'he_normal')(x2_input)\n",
    "    x2 = LeakyReLU(alpha=0.25)(x2)\n",
    "    \n",
    "    y2_input = concatenate([y,y1,x1c],axis=-1)\n",
    "    y2 = Conv2D(filters= gc, kernel_size=3,strides=1, padding='same',use_bias=bias, kernel_initializer = 'he_normal')(y2_input)\n",
    "    y2 = LeakyReLU(alpha=0.25)(y2)\n",
    "    \n",
    "    x2c = Conv2D(filters=gc, kernel_size=3, strides=2,padding='same', use_bias=bias, kernel_initializer = 'he_normal')(x1)\n",
    "    x2c = LeakyReLU(alpha=0.25)(x2c)\n",
    "    y2t = Conv2DTranspose(filters=gc, kernel_size=3, strides=2,padding='same', use_bias=bias)(y1)\n",
    "    y2t = LeakyReLU(alpha=0.25)(y2t)\n",
    "    \n",
    "    \n",
    "    \n",
    "    x3_input = concatenate([x,x1,x2,y2t] , axis=-1)\n",
    "    x3 = Conv2D(filters= gc, kernel_size=3,strides=1, padding='same', use_bias=bias, kernel_initializer = 'he_normal')(x3_input)\n",
    "    x3 = LeakyReLU(alpha=0.25)(x3)\n",
    "    \n",
    "    y3_input = concatenate([y,y1,y2,x2c] , axis=-1)\n",
    "    y3 = Conv2D(filters= gc, kernel_size=3,strides=1, padding='same', use_bias=bias, kernel_initializer = 'he_normal')(y3_input)\n",
    "    y3 = LeakyReLU(alpha=0.25)(y3)\n",
    "    \n",
    "    x3c = Conv2D(filters=gc, kernel_size=3, strides=2,padding='same', use_bias=bias, kernel_initializer = 'he_normal')(x3)\n",
    "    x3c = LeakyReLU(alpha=0.25)(x3c)\n",
    "    y3t = Conv2DTranspose(filters=gc, kernel_size=3, strides=2,padding='same', use_bias=bias, kernel_initializer = 'he_normal')(y3)\n",
    "    y3t = LeakyReLU(alpha=0.25)(y3t)\n",
    "    \n",
    "    \n",
    "        \n",
    "    x4_input = concatenate([x,x1,x2,x3,y3t] , axis=-1)\n",
    "    x4 = Conv2D(filters= gc, kernel_size=3,strides=1, padding='same', use_bias=bias, kernel_initializer = 'he_normal')(x4_input)\n",
    "    x4 = LeakyReLU(alpha=0.25)(x4)\n",
    "    \n",
    "    \n",
    "    y4_input = concatenate([y,y1,y2,y3,x3c] , axis=-1)\n",
    "    y4 = Conv2D(filters= gc, kernel_size=3,strides=1, padding='same', use_bias=bias, kernel_initializer = 'he_normal')(y4_input)\n",
    "    y4 = LeakyReLU(alpha=0.25)(y4)\n",
    "    \n",
    "    x4c = Conv2D(filters=gc, kernel_size=3, strides=2,padding='same', use_bias=bias, kernel_initializer = 'he_normal')(x4)\n",
    "    x4c = LeakyReLU(alpha=0.25)(x4c)\n",
    "    y4t = Conv2DTranspose(filters=gc, kernel_size=3, strides=2,padding='same', use_bias=bias)(y4)\n",
    "    y4t = LeakyReLU(alpha=0.25)(y4t)\n",
    "    \n",
    "        \n",
    "    x5_input = concatenate([x,x1,x2,x3,x4,y4t] , axis=-1)\n",
    "    x5 = Conv2D(filters= nf1, kernel_size=3,strides=1, padding='same', use_bias=bias, kernel_initializer = 'he_normal')(x5_input)\n",
    "    x5 = LeakyReLU(alpha=0.25)(x5)\n",
    "    \n",
    "    y5_input = concatenate([y,y1,y2,y3,y4,x4c] , axis=-1)\n",
    "    y5 = Conv2D(filters= nf2, kernel_size=3,strides=1, padding='same', use_bias=bias, kernel_initializer = 'he_normal')(y5_input)\n",
    "    y5 = LeakyReLU(alpha=0.25)(y5)\n",
    "        \n",
    "    x5 = Lambda(lambda x: x * 0.4)(x5)\n",
    "    y5 = Lambda(lambda x: x * 0.4)(y5)\n",
    "        \n",
    "    return Add()([x5,x]),Add()([y5,y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c311b3ef-9436-4667-8513-a5e55fdd0be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 64, 64, 128)\n",
      "(None, 128, 128, 64)\n"
     ]
    }
   ],
   "source": [
    "def dice_coefficient(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true[:,:,:,0])\n",
    "    y_pred_f = K.flatten(y_pred[:,:,:,0])\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    d1 =  (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return d1\n",
    "\n",
    "def dice_coefficient_loss(y_true, y_pred):\n",
    "    return 1.-dice_coefficient(y_true, y_pred)\n",
    "\n",
    "def seg_loss(y_true, y_pred):\n",
    "    # print(y_true.shape, y_pred.shape)\n",
    "    dice_s = dice_coefficient_loss(y_true,y_pred)\n",
    "    \n",
    "    #ce_loss = BinaryCrossentropy(y_true,y_pred)\n",
    "    ce_loss =tf.keras.backend.binary_crossentropy(y_true,y_pred)\n",
    "    \n",
    "    return ce_loss + dice_s\n",
    "\n",
    "def _to_tensor(x, dtype):\n",
    "    x = tf.convert_to_tensor(x)\n",
    "    if x.dtype != dtype:\n",
    "        x = tf.cast(x, dtype)\n",
    "    return x\n",
    "\n",
    "def balanced_cross_entropy_loss(y_true, y_pred):\n",
    "    _epsilon = _to_tensor(tf.keras.backend.epsilon(), y_pred.dtype )\n",
    "    y_pred = tf.clip_by_value(y_pred, _epsilon, 1 - _epsilon)\n",
    "    y_pred = tf.math.log(y_pred/ (1 - y_pred))\n",
    "\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    count_neg = tf.reduce_sum(input_tensor=1. - y_true)\n",
    "    count_pos = tf.reduce_sum(input_tensor=y_true)\n",
    "    beta = count_neg / (count_neg + count_pos)\n",
    "    pos_weight = beta / (1 - beta)\n",
    "    cost = tf.nn.weighted_cross_entropy_with_logits(logits=y_pred, labels=y_true, pos_weight=pos_weight)\n",
    "    cost = tf.reduce_mean(input_tensor=cost * (1 - beta))\n",
    "    return tf.compat.v1.where(tf.equal(count_pos, 0.0), 0.0, cost)\n",
    "\n",
    "G = msrf()\n",
    "optimizer = Adam(learning_rate=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "G.compile(optimizer = optimizer, loss = {'x':seg_loss,'edge_out':'binary_crossentropy','pred4':seg_loss,'pred2':seg_loss},\n",
    "            loss_weights={'x':2.,'edge_out':1.,'pred4':1. , 'pred2':1.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52972046-0849-4200-b96b-bd675a610d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 09:16:34.390202: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100\n",
      "2022-07-12 09:16:34.797408: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 11.0.221, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-07-12 09:16:37.563435: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.23GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-12 09:16:38.861241: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-12 09:16:40.674873: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-12 09:16:40.684430: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-12 09:16:40.713608: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.56GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-12 09:16:40.722401: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.57GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-12 09:16:41.245810: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-12 09:16:41.258557: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.07GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-12 09:16:41.293841: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.54GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-07-12 09:16:41.306434: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.57GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    902/Unknown - 1041s 1s/step - loss: 2.8677 - x_loss: 0.6840 - edge_out_loss: 0.0950 - pred2_loss: 0.6315 - pred4_loss: 0.7733\n",
      "Save best train weights.\n",
      "Save best val weights.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 09:37:36.525927: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 424673280 exceeds 10% of free system memory.\n",
      "2022-07-12 09:37:38.241688: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 424673280 exceeds 10% of free system memory.\n",
      "2022-07-12 09:37:39.186315: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 424673280 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902/902 [==============================] - 1294s 1s/step - loss: 2.8677 - x_loss: 0.6840 - edge_out_loss: 0.0950 - pred2_loss: 0.6315 - pred4_loss: 0.7733 - val_loss: 3.5335 - val_x_loss: 0.7701 - val_edge_out_loss: 0.0622 - val_pred2_loss: 1.0376 - val_pred4_loss: 0.8935 - lr: 0.0010\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0009000000000000001.\n",
      "Epoch 2/100\n",
      "902/902 [==============================] - ETA: 0s - loss: 2.6569 - x_loss: 0.6192 - edge_out_loss: 0.0542 - pred2_loss: 0.5839 - pred4_loss: 0.7804\n",
      "Save best train weights.\n",
      "Save best val weights.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 09:58:25.521320: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 424673280 exceeds 10% of free system memory.\n",
      "2022-07-12 09:58:27.398365: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 424673280 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902/902 [==============================] - 1249s 1s/step - loss: 2.6569 - x_loss: 0.6192 - edge_out_loss: 0.0542 - pred2_loss: 0.5839 - pred4_loss: 0.7804 - val_loss: 3.0709 - val_x_loss: 0.7037 - val_edge_out_loss: 0.0561 - val_pred2_loss: 0.7364 - val_pred4_loss: 0.8710 - lr: 9.0000e-04\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.0008100000000000001.\n",
      "Epoch 3/100\n",
      "902/902 [==============================] - ETA: 0s - loss: 2.5240 - x_loss: 0.5878 - edge_out_loss: 0.0510 - pred2_loss: 0.5389 - pred4_loss: 0.7585\n",
      "Save best train weights.\n",
      "Save best val weights.\n",
      "902/902 [==============================] - 1264s 1s/step - loss: 2.5240 - x_loss: 0.5878 - edge_out_loss: 0.0510 - pred2_loss: 0.5389 - pred4_loss: 0.7585 - val_loss: 2.6146 - val_x_loss: 0.6256 - val_edge_out_loss: 0.0559 - val_pred2_loss: 0.5548 - val_pred4_loss: 0.7527 - lr: 8.1000e-04\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.0007290000000000002.\n",
      "Epoch 4/100\n",
      "902/902 [==============================] - 1261s 1s/step - loss: 2.7191 - x_loss: 0.6475 - edge_out_loss: 0.0535 - pred2_loss: 0.5846 - pred4_loss: 0.7861 - val_loss: 2.9043 - val_x_loss: 0.7289 - val_edge_out_loss: 0.0607 - val_pred2_loss: 0.5933 - val_pred4_loss: 0.7926 - lr: 7.2900e-04\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.0006561000000000001.\n",
      "Epoch 5/100\n",
      "902/902 [==============================] - 1242s 1s/step - loss: 2.6582 - x_loss: 0.6616 - edge_out_loss: 0.0534 - pred2_loss: 0.5338 - pred4_loss: 0.7479 - val_loss: 2.7867 - val_x_loss: 0.7148 - val_edge_out_loss: 0.0513 - val_pred2_loss: 0.5416 - val_pred4_loss: 0.7643 - lr: 6.5610e-04\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.00059049.\n",
      "Epoch 6/100\n",
      "902/902 [==============================] - 1255s 1s/step - loss: 2.7557 - x_loss: 0.7391 - edge_out_loss: 0.0525 - pred2_loss: 0.4953 - pred4_loss: 0.7298 - val_loss: 2.9911 - val_x_loss: 0.7455 - val_edge_out_loss: 0.0550 - val_pred2_loss: 0.6514 - val_pred4_loss: 0.7937 - lr: 5.9049e-04\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 0.000531441.\n",
      "Epoch 7/100\n",
      "902/902 [==============================] - 1227s 1s/step - loss: 2.6847 - x_loss: 0.7307 - edge_out_loss: 0.0501 - pred2_loss: 0.4655 - pred4_loss: 0.7078 - val_loss: 2.9907 - val_x_loss: 0.7350 - val_edge_out_loss: 0.0574 - val_pred2_loss: 0.6504 - val_pred4_loss: 0.8128 - lr: 5.3144e-04\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 0.0004782969000000001.\n",
      "Epoch 8/100\n",
      "902/902 [==============================] - 1224s 1s/step - loss: 2.6073 - x_loss: 0.7204 - edge_out_loss: 0.0483 - pred2_loss: 0.4298 - pred4_loss: 0.6885 - val_loss: 3.0504 - val_x_loss: 0.7143 - val_edge_out_loss: 0.0486 - val_pred2_loss: 0.8847 - val_pred4_loss: 0.6885 - lr: 4.7830e-04\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 0.0004304672100000001.\n",
      "Epoch 9/100\n",
      "902/902 [==============================] - 1212s 1s/step - loss: 2.5678 - x_loss: 0.7202 - edge_out_loss: 0.0476 - pred2_loss: 0.4051 - pred4_loss: 0.6747 - val_loss: 3.0678 - val_x_loss: 0.7155 - val_edge_out_loss: 0.0475 - val_pred2_loss: 0.8895 - val_pred4_loss: 0.6997 - lr: 4.3047e-04\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 0.0003874204890000001.\n",
      "Epoch 10/100\n",
      "902/902 [==============================] - 1232s 1s/step - loss: 2.5699 - x_loss: 0.7342 - edge_out_loss: 0.0473 - pred2_loss: 0.3869 - pred4_loss: 0.6673 - val_loss: 2.8345 - val_x_loss: 0.7281 - val_edge_out_loss: 0.0467 - val_pred2_loss: 0.6723 - val_pred4_loss: 0.6593 - lr: 3.8742e-04\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 0.0003486784401000001.\n",
      "Epoch 11/100\n",
      "902/902 [==============================] - 1241s 1s/step - loss: 2.5396 - x_loss: 0.7236 - edge_out_loss: 0.0461 - pred2_loss: 0.3834 - pred4_loss: 0.6629 - val_loss: 2.8138 - val_x_loss: 0.7218 - val_edge_out_loss: 0.0484 - val_pred2_loss: 0.6105 - val_pred4_loss: 0.7112 - lr: 3.4868e-04\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 0.0003138105960900001.\n",
      "Epoch 12/100\n",
      "902/902 [==============================] - 1246s 1s/step - loss: 2.5539 - x_loss: 0.7376 - edge_out_loss: 0.0460 - pred2_loss: 0.3736 - pred4_loss: 0.6591 - val_loss: 2.8442 - val_x_loss: 0.7291 - val_edge_out_loss: 0.0461 - val_pred2_loss: 0.6540 - val_pred4_loss: 0.6859 - lr: 3.1381e-04\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 0.0002824295364810001.\n",
      "Epoch 13/100\n",
      "902/902 [==============================] - ETA: 0s - loss: 2.5124 - x_loss: 0.7270 - edge_out_loss: 0.0455 - pred2_loss: 0.3613 - pred4_loss: 0.6514\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 2.824295370373875e-05.\n",
      "\n",
      "Save best train weights.\n",
      "Val loss doesn't improve.\n",
      "902/902 [==============================] - 1239s 1s/step - loss: 2.5124 - x_loss: 0.7270 - edge_out_loss: 0.0455 - pred2_loss: 0.3613 - pred4_loss: 0.6514 - val_loss: 2.8305 - val_x_loss: 0.7572 - val_edge_out_loss: 0.0460 - val_pred2_loss: 0.5935 - val_pred4_loss: 0.6767 - lr: 2.8243e-04\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "from models.callback.save_best import SavebestweightsandEarlyStopping\n",
    "\n",
    "model_name = 'msrfnet'\n",
    "mission = 'road'\n",
    "img_size = 256\n",
    "num_class = 1 \n",
    "batch_size = 2\n",
    "\n",
    "def lr_decay(epoch):\n",
    "    initial_learningrate=1e-3\n",
    "    if epoch < 1:\n",
    "        return initial_learningrate\n",
    "    else:\n",
    "        return initial_learningrate * 0.9 ** (epoch)\n",
    "\n",
    "if batch_size >1:\n",
    "    val_batch_size = int(batch_size/2)\n",
    "else:\n",
    "    val_batch_size = batch_size\n",
    "\n",
    "checkpoint_filepath= '/home/quyet/DATA_ML/Projects/segmentation/logs/tmp'\n",
    "log_dir = '/home/quyet/DATA_ML/Projects/segmentation/logs/graph'\n",
    "weights_path = '/home/quyet/DATA_ML/WorkSpace/segmentation/weights/%s/'%(model_name) +model_name+'_'+mission+'_'+str(img_size)+'_'+str(num_class)+'class.h5'\n",
    "patience = 10\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only= True, \n",
    "                                                                monitor='val_loss', mode='min', save_best_only=True)\n",
    "model_lrscheduler_callback = tf.keras.callbacks.LearningRateScheduler(lr_decay, verbose=1)\n",
    "model_lrreduce_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=patience, min_lr=1e-7, verbose=1)\n",
    "model_earlystopping_callback = SavebestweightsandEarlyStopping(patience=patience, weights_path=weights_path)\n",
    "model_endtrainnan_callback = tf.keras.callbacks.TerminateOnNaN()\n",
    "model_tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=True)\n",
    "model_callbacks = [model_checkpoint_callback, model_lrscheduler_callback,\n",
    "                    model_lrreduce_callback, model_earlystopping_callback,\n",
    "                    model_tensorboard_callback,]\n",
    "\n",
    "# G.load_weights('/home/quyet/DATA_ML/WorkSpace/segmentation/weights/msrfnet/msrfnet_road_256_1class_train.h5')\n",
    "history_train = G.fit(train_dataset, batch_size=batch_size, epochs=100, verbose=1, \n",
    "                      callbacks=model_callbacks, validation_data=valid_dataset, \n",
    "                      validation_batch_size=val_batch_size, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ea72ba43-f7c4-476c-86b3-d744ed193248",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6237, 6126, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 960/960 [03:06<00:00,  5.14it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from osgeo import gdal\n",
    "from postprocess.convert_tif import dilation_obj, remove_small_items, write_image\n",
    "\n",
    "def get_im_by_coord(org_im, start_x, start_y,num_band, padding, crop_size, input_size):\n",
    "    startx = start_x-padding\n",
    "    endx = start_x+crop_size+padding\n",
    "    starty = start_y - padding\n",
    "    endy = start_y+crop_size+padding\n",
    "    result=[]\n",
    "    img = org_im[starty:endy, startx:endx]\n",
    "    img = img.swapaxes(2,1).swapaxes(1,0)\n",
    "    for chan_i in range(num_band):\n",
    "        result.append(cv2.resize(img[chan_i],(input_size, input_size), interpolation = cv2.INTER_CUBIC))\n",
    "    return np.array(result).swapaxes(0,1).swapaxes(1,2)\n",
    "\n",
    "def get_img_coords(w, h, padding, crop_size):\n",
    "    new_w = w + 2*padding\n",
    "    new_h = h + 2*padding\n",
    "    cut_w = list(range(padding, new_w - padding, crop_size))\n",
    "    cut_h = list(range(padding, new_h - padding, crop_size))\n",
    "\n",
    "    list_hight = []\n",
    "    list_weight = []\n",
    "    for i in cut_h:\n",
    "        if i < new_h - padding - crop_size:\n",
    "            list_hight.append(i)\n",
    "    list_hight.append(new_h-crop_size-padding)\n",
    "\n",
    "    for i in cut_w:\n",
    "        if i < new_w - crop_size - padding:\n",
    "            list_weight.append(i)\n",
    "    list_weight.append(new_w-crop_size-padding)\n",
    "\n",
    "    img_coords = []\n",
    "    for i in list_weight:\n",
    "        for j in list_hight:\n",
    "            img_coords.append([i, j])\n",
    "    return img_coords\n",
    "\n",
    "def padded_for_org_img(values, num_band, padding):\n",
    "    padded_org_im = []\n",
    "    for i in range(num_band):\n",
    "        band = np.pad(values[i], padding, mode='reflect')\n",
    "        padded_org_im.append(band)\n",
    "\n",
    "    values = np.array(padded_org_im).swapaxes(0,1).swapaxes(1,2)\n",
    "    print(values.shape)\n",
    "    del padded_org_im\n",
    "    return values\n",
    "\n",
    "def predict(model, values, img_coords, num_band, h, w, padding, crop_size, \n",
    "            input_size, batch_size, thresh_hold, choose_stage):\n",
    "    cut_imgs = []\n",
    "    for i in range(len(img_coords)):\n",
    "        im = get_im_by_coord(values, img_coords[i][0], img_coords[i][1],\n",
    "                            num_band,padding, crop_size, input_size)\n",
    "        cut_imgs.append(im)\n",
    "\n",
    "    a = list(range(0, len(cut_imgs), batch_size))\n",
    "\n",
    "    if a[len(a)-1] != len(cut_imgs):\n",
    "        a[len(a)-1] = len(cut_imgs)\n",
    "\n",
    "    y_pred = []\n",
    "    for i in tqdm(range(len(a)-1)):\n",
    "        x_batch = []\n",
    "        x_batch = np.array(cut_imgs[a[i]:a[i+1]])\n",
    "        # print(x_batch.shape)\n",
    "        img_edge = []\n",
    "        for img_x in x_batch:\n",
    "            lab_batch = color.rgb2lab(img_x)  \n",
    "            img_edge.append(cv2.Canny(np.asarray(np.uint8(lab_batch)),0,0)[..., np.newaxis])\n",
    "        # print(img_edge.shape)\n",
    "        img_edge = np.array(img_edge)\n",
    "        \n",
    "        # print(x_batch.shape, img_edge.shape)\n",
    "        y_batch = model.predict((x_batch/255, img_edge/255))\n",
    "        if len(model.outputs)>1:\n",
    "            y_batch = y_batch[choose_stage]\n",
    "        mutilabel = False\n",
    "        if y_batch.shape[-1]>=2:\n",
    "            mutilabel = True\n",
    "            y_batch = np.argmax(y_batch, axis=-1)\n",
    "        # print(np.unique(y_batch), y_batch.shape)\n",
    "            \n",
    "        y_pred.extend(y_batch)\n",
    "    big_mask = np.zeros((h, w)).astype(np.float16)\n",
    "    for i in range(len(cut_imgs)):\n",
    "        true_mask = y_pred[i].reshape((input_size,input_size))\n",
    "        if not mutilabel:\n",
    "            true_mask = (true_mask>thresh_hold).astype(np.uint8)\n",
    "            true_mask = (cv2.resize(true_mask,(input_size, input_size), interpolation = cv2.INTER_CUBIC)>thresh_hold).astype(np.uint8)\n",
    "            # true_mask = true_mask.astype(np.float16)\n",
    "        start_x = img_coords[i][1]\n",
    "        start_y = img_coords[i][0]\n",
    "        big_mask[start_x-padding:start_x-padding+crop_size, start_y-padding:start_y -\n",
    "                    padding+crop_size] = true_mask[padding:padding+crop_size, padding:padding+crop_size]\n",
    "    del cut_imgs\n",
    "    return big_mask\n",
    "\n",
    "img_size = 256\n",
    "num_band = 3\n",
    "crop_size = 200\n",
    "batch_size = 1\n",
    "thresh_hold = 0.8\n",
    "choose_stage = 0\n",
    "\n",
    "G.load_weights('/home/quyet/DATA_ML/WorkSpace/segmentation/weights/msrfnet/msrfnet_road_256_1class_val.h5')\n",
    "image_path = '/home/quyet/DATA_ML/Projects/road_multi/crop/img/test.tif'\n",
    "dataset = gdal.Open(image_path)\n",
    "values = dataset.ReadAsArray()[0:num_band]\n",
    "h,w = values.shape[1:3]    \n",
    "padding = int((img_size - crop_size)/2)\n",
    "img_coords = get_img_coords(w, h, padding, crop_size)\n",
    "values = padded_for_org_img(values, num_band, padding)\n",
    "big_mask = predict(G, values, img_coords, num_band, h, w, padding, crop_size, \n",
    "                    img_size, batch_size, thresh_hold, choose_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "479285b6-48f2-4944-a5a9-8d858c306737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write image...\n"
     ]
    }
   ],
   "source": [
    "image_path = '/home/quyet/DATA_ML/Projects/road_multi/crop/img/test.tif'\n",
    "result_path = write_image(image_path, big_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffc5695-5ad8-4ef2-8eef-ec8951b91f57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
