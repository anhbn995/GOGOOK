{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b449911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import glob \n",
    "import numpy as np\n",
    "import sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0b973cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "# from tensorboard_logger import configure, log_value\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "927810e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import modules, net, resnet, densenet, senet\n",
    "import loaddata\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c99fec6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(is_resnet, is_densenet, is_senet):\n",
    "    if is_resnet:\n",
    "        original_model = resnet.resnet50(pretrained = True)\n",
    "        Encoder = modules.E_resnet(original_model) \n",
    "        model = net.model(Encoder, num_features=2048, block_channel = [256, 512, 1024, 2048])\n",
    "    if is_densenet:\n",
    "        original_model = densenet.densenet161(pretrained=True)\n",
    "        Encoder = modules.E_densenet(original_model)\n",
    "        model = net.model(Encoder, num_features=2208, block_channel = [192, 384, 1056, 2208])\n",
    "    if is_senet:\n",
    "        original_model = senet.senet154(pretrained=None)\n",
    "        Encoder = modules.E_senet(original_model)\n",
    "        model = net.model(Encoder, num_features=2048, block_channel = [256, 512, 1024, 2048])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "daafa30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f5aaa4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=\"pretrain/Block0_skip_model_110.pth.tar\"\n",
    "model = define_model(is_resnet=False, is_densenet=False, is_senet=True)\n",
    "# model = torch.nn.DataParallel(model,device_ids=[0]).cuda()\n",
    "model.to(device)\n",
    "state_dict = torch.load(x)['state_dict']\n",
    "\n",
    "del state_dict[\"E.Harm.dct\"]\n",
    "del state_dict[\"E.Harm.weight\"]\n",
    "del state_dict[\"E.Harm.bias\"]\n",
    "\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9041e31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = loaddata.getTestingData(3, \"dataset/test_osi1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae2e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_loss(depth , output, losses, batchSize):\n",
    "    \n",
    "    ones = torch.ones(depth.size(0), 1, depth.size(2),depth.size(3)).float().cuda()\n",
    "    get_gradient = sobel.Sobel().cuda()\n",
    "    cos = nn.CosineSimilarity(dim=1, eps=0)\n",
    "    depth_grad = get_gradient(depth)\n",
    "    output_grad = get_gradient(output)\n",
    "    depth_grad_dx = depth_grad[:, 0, :, :].contiguous().view_as(depth)\n",
    "    depth_grad_dy = depth_grad[:, 1, :, :].contiguous().view_as(depth)\n",
    "    output_grad_dx = output_grad[:, 0, :, :].contiguous().view_as(depth)\n",
    "    output_grad_dy = output_grad[:, 1, :, :].contiguous().view_as(depth)\n",
    "    depth_normal = torch.cat((-depth_grad_dx, -depth_grad_dy, ones), 1)\n",
    "    output_normal = torch.cat((-output_grad_dx, -output_grad_dy, ones), 1)\n",
    "\n",
    "    loss_depth = torch.log(torch.abs(output - depth) + 0.5).mean()\n",
    "\n",
    "    loss_dx = torch.log(torch.abs(output_grad_dx - depth_grad_dx) + 0.5).mean()\n",
    "    loss_dy = torch.log(torch.abs(output_grad_dy - depth_grad_dy) + 0.5).mean()\n",
    "    loss_normal = torch.abs(1 - cos(output_normal, depth_normal)).mean()\n",
    "    loss = loss_depth + loss_normal + (loss_dx + loss_dy)\n",
    "    losses.update(loss.data, batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050f4cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    '''\n",
    "    alist.sort(key=natural_keys) sorts in human order\n",
    "    http://nedbatchelder.com/blog/200712/human_sorting.html\n",
    "    (See Toothy's implementation in the comments)\n",
    "    '''\n",
    "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f351b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "    totalNumber = 0\n",
    "    errorSum = {'MSE': 0, 'RMSE': 0, 'MAE': 0,'SSIM':0}\n",
    "\n",
    "    for i, sample_batched in enumerate(test_loader):\n",
    "        image, depth = sample_batched['image'], sample_batched['depth']\n",
    "        depth = depth.cuda()\n",
    "        image = image.cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(image)\n",
    "\n",
    "        output = torch.nn.functional.interpolate(output,size=(440,440),mode='bilinear')\n",
    "\n",
    "\n",
    "        batchSize = depth.size(0)\n",
    "        testing_loss(depth,output,losses,batchSize)\n",
    "\n",
    "\n",
    "        totalNumber = totalNumber + batchSize\n",
    "\n",
    "       \n",
    "\n",
    "        errors = util.evaluateError(output, depth,i,batchSize)\n",
    "\n",
    "        errorSum = util.addErrors(errorSum, errors, batchSize)\n",
    "        averageError = util.averageErrors(errorSum, totalNumber)\n",
    "                     \n",
    "\n",
    "    averageError['RMSE'] = np.sqrt(averageError['MSE'])\n",
    "    loss = float((losses.avg).data.cpu().numpy())\n",
    "\n",
    "\n",
    "\n",
    "    print('Model Loss {loss:.4f}\\t'\n",
    "        'MSE {mse:.4f}\\t'\n",
    "        'RMSE {rmse:.4f}\\t'\n",
    "        'MAE {mae:.4f}\\t'\n",
    "        'SSIM {ssim:.4f}\\t'.format(loss=loss,mse=averageError['MSE']\\\n",
    "            ,rmse=averageError['RMSE'],mae=averageError['MAE'],\\\n",
    "            ssim=averageError['SSIM']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f146b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a2846cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagefile=\"./data/test_rgbs_base/315000_233500_RGB_0_4.tif\"\n",
    "from PIL import Image\n",
    "image = Image.open(imagefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4508d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def centerCrop(image, size):\n",
    "\n",
    "    w1, h1 = image.size\n",
    "\n",
    "    tw, th = size\n",
    "\n",
    "    if w1 == tw and h1 == th:\n",
    "        return image\n",
    "\n",
    "    x1 = int(round((w1 - tw) / 2.))\n",
    "    y1 = int(round((h1 - th) / 2.))\n",
    "\n",
    "    image = image.crop((x1, y1, tw + x1, th + y1))\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c870a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=centerCrop(image,[440,440])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "60fb45b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic=image\n",
    "image=torch.ByteTensor(\n",
    "                torch.ByteStorage.from_buffer(pic.tobytes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d5a74c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nchannel = len(pic.mode)\n",
    "image = image.view(pic.size[1], pic.size[0], nchannel)\n",
    "image = image.transpose(0, 1).transpose(0, 2).contiguous()\n",
    "image = image.float()/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a0a70df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7059, 0.6941, 0.7137,  ..., 0.4980, 0.4314, 0.5216],\n",
       "         [0.7529, 0.6667, 0.4314,  ..., 0.5569, 0.5490, 0.4745],\n",
       "         [0.7294, 0.6706, 0.5608,  ..., 0.3647, 0.4824, 0.5804],\n",
       "         ...,\n",
       "         [0.6353, 0.6510, 0.5608,  ..., 0.4000, 0.2275, 0.0980],\n",
       "         [0.6157, 0.6314, 0.6078,  ..., 0.1804, 0.1412, 0.0588],\n",
       "         [0.5961, 0.5804, 0.5765,  ..., 0.1294, 0.1059, 0.0941]],\n",
       "\n",
       "        [[0.6980, 0.6941, 0.7255,  ..., 0.4431, 0.4078, 0.4510],\n",
       "         [0.7451, 0.6549, 0.4353,  ..., 0.5176, 0.4902, 0.4314],\n",
       "         [0.7294, 0.6824, 0.5569,  ..., 0.4078, 0.5020, 0.5412],\n",
       "         ...,\n",
       "         [0.6000, 0.6314, 0.5451,  ..., 0.3569, 0.2118, 0.1059],\n",
       "         [0.6039, 0.6235, 0.5843,  ..., 0.1843, 0.1412, 0.0745],\n",
       "         [0.5412, 0.5255, 0.5373,  ..., 0.1255, 0.1098, 0.1216]],\n",
       "\n",
       "        [[0.7098, 0.6980, 0.7216,  ..., 0.4392, 0.4157, 0.4431],\n",
       "         [0.7333, 0.6588, 0.4667,  ..., 0.4941, 0.4706, 0.4431],\n",
       "         [0.7216, 0.6863, 0.5882,  ..., 0.3804, 0.4667, 0.4980],\n",
       "         ...,\n",
       "         [0.5882, 0.6275, 0.5529,  ..., 0.3412, 0.2510, 0.1804],\n",
       "         [0.6078, 0.6353, 0.6039,  ..., 0.2196, 0.1843, 0.1373],\n",
       "         [0.5647, 0.5647, 0.5608,  ..., 0.1725, 0.1490, 0.1569]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e3b9c037",
   "metadata": {},
   "outputs": [],
   "source": [
    "__imagenet_stats = {'mean': [0.485, 0.456, 0.406],\n",
    "                    'std': [0.229, 0.224, 0.225]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "46b20b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9646,  0.9132,  0.9988,  ...,  0.0569, -0.2342,  0.1597],\n",
       "         [ 1.1700,  0.7933, -0.2342,  ...,  0.3138,  0.2796, -0.0458],\n",
       "         [ 1.0673,  0.8104,  0.3309,  ..., -0.5253, -0.0116,  0.4166],\n",
       "         ...,\n",
       "         [ 0.6563,  0.7248,  0.3309,  ..., -0.3712, -1.1247, -1.6898],\n",
       "         [ 0.5707,  0.6392,  0.5364,  ..., -1.3302, -1.5014, -1.8610],\n",
       "         [ 0.4851,  0.4166,  0.3994,  ..., -1.5528, -1.6555, -1.7069]],\n",
       "\n",
       "        [[ 1.0805,  1.0630,  1.2031,  ..., -0.0574, -0.2150, -0.0224],\n",
       "         [ 1.2906,  0.8880, -0.0924,  ...,  0.2752,  0.1527, -0.1099],\n",
       "         [ 1.2206,  1.0105,  0.4503,  ..., -0.2150,  0.2052,  0.3803],\n",
       "         ...,\n",
       "         [ 0.6429,  0.7829,  0.3978,  ..., -0.4426, -1.0903, -1.5630],\n",
       "         [ 0.6604,  0.7479,  0.5728,  ..., -1.2129, -1.4055, -1.7031],\n",
       "         [ 0.3803,  0.3102,  0.3627,  ..., -1.4755, -1.5455, -1.4930]],\n",
       "\n",
       "        [[ 1.3502,  1.2980,  1.4025,  ...,  0.1476,  0.0431,  0.1651],\n",
       "         [ 1.4548,  1.1237,  0.2696,  ...,  0.3916,  0.2871,  0.1651],\n",
       "         [ 1.4025,  1.2457,  0.8099,  ..., -0.1138,  0.2696,  0.4091],\n",
       "         ...,\n",
       "         [ 0.8099,  0.9842,  0.6531,  ..., -0.2881, -0.6890, -1.0027],\n",
       "         [ 0.8971,  1.0191,  0.8797,  ..., -0.8284, -0.9853, -1.1944],\n",
       "         [ 0.7054,  0.7054,  0.6879,  ..., -1.0376, -1.1421, -1.1073]]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for t, m, s in zip(image, __imagenet_stats['mean'], __imagenet_stats['std']):\n",
    "    t.sub_(m).div_(s)\n",
    "image    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3738a627",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image[None,:].cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(image)\n",
    "    \n",
    "output = torch.nn.functional.interpolate(output,size=(440,440),mode='bilinear')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e91655c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.9710e-01,  1.9915e-01,  2.0325e-01,  ..., -2.4351e-04,\n",
       "           -4.5214e-04, -5.5645e-04],\n",
       "          [ 1.9978e-01,  2.0144e-01,  2.0476e-01,  ..., -1.4563e-04,\n",
       "           -3.3420e-04, -4.2849e-04],\n",
       "          [ 2.0513e-01,  2.0601e-01,  2.0777e-01,  ...,  5.0143e-05,\n",
       "           -9.8321e-05, -1.7255e-04],\n",
       "          ...,\n",
       "          [ 1.1790e-01,  1.1857e-01,  1.1989e-01,  ...,  6.4433e-04,\n",
       "            7.3726e-04,  7.8373e-04],\n",
       "          [ 1.1517e-01,  1.1611e-01,  1.1799e-01,  ...,  8.5819e-04,\n",
       "            1.2413e-03,  1.4329e-03],\n",
       "          [ 1.1380e-01,  1.1488e-01,  1.1703e-01,  ...,  9.6512e-04,\n",
       "            1.4934e-03,  1.7575e-03]]]], device='cuda:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "945cb3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_0_1 = output.cpu().detach().numpy()\n",
    "output_0_1= output_0_1*100\n",
    "output_0_1[np.where(output_0_1>=30)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "943903f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 440, 440)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_0_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "99017682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.windows import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3b0a97b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(imagefile) as src:\n",
    "    xsize, ysize = 440, 440\n",
    "    \n",
    "    xoff, yoff = (src.width - xsize)//2, (src.height - ysize)//2\n",
    "    \n",
    "    window=Window(xoff, yoff, xsize, ysize)\n",
    "    transform = src.window_transform(window)\n",
    "    \n",
    "    profile = src.profile\n",
    "    profile.update({\n",
    "        'height': ysize,\n",
    "        'width': xsize,\n",
    "        'transform': transform\n",
    "    })\n",
    "    \n",
    "    with rasterio.open('./test/image1.tif', 'w', **profile) as dst:\n",
    "        dst.write(src.read(window=window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8d028d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "testimage='./test/image2.tif'\n",
    "with rasterio.open(testimage) as src:\n",
    "    img=src.read()[0:3]\n",
    "    img=img.astype(float)/255\n",
    "    \n",
    "img=torch.from_numpy(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c55041a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t, m, s in zip(img, __imagenet_stats['mean'], __imagenet_stats['std']):\n",
    "    t.sub_(m).div_(s)\n",
    "img=img.float()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "49ae5dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img[None,:].cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(img)\n",
    "    \n",
    "pred = torch.nn.functional.interpolate(pred,size=(440,440),mode='bilinear')\n",
    "pred = pred.cpu().detach().numpy()\n",
    "pred= pred*100\n",
    "pred[np.where(pred>=30)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4ca3c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(testimage) as src:\n",
    "    profile = src.profile\n",
    "    profile.update({\n",
    "        'count': 1,\n",
    "        'dtype': rasterio.float32\n",
    "    })\n",
    "    \n",
    "    with rasterio.open('./test/height2.tif','w', **profile) as dst:\n",
    "        dst.write(pred[0][0], 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
