{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 19:29:50.537703: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/skm/anaconda3/envs/myai/lib/python3.9/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/home/skm/anaconda3/envs/myai/lib/python3.9/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/home/skm/anaconda3/envs/myai/lib/python3.9/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6Status12empty_stringB5cxx11Ev']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/home/skm/anaconda3/envs/myai/lib/python3.9/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/home/skm/anaconda3/envs/myai/lib/python3.9/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/home/skm/anaconda3/envs/myai/lib/python3.9/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFN3tsl8StatusOrISt10unique_ptrIS1_NS5_4core15RefCountDeleterEEEEvEE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import threading\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "import glob, os\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from rasterio.windows import Window\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "def write_window_many_chanel(output_ds, arr_c, window_draw_pre):\n",
    "    s_h, e_h ,s_w, e_w, sw_w, sw_h, size_w_crop, size_h_crop = window_draw_pre \n",
    "    output_ds.write(arr_c[s_h:e_h,s_w:e_w],window = Window(sw_w, sw_h, size_w_crop, size_h_crop), indexes = 1)\n",
    "\n",
    "\n",
    "def read_window_and_index_result(crop_size, h_crop_start, w_crop_start, start_w_org, start_h_org, padding, h, w, tmp_img_size_model, src_img, num_band_train):\n",
    "    \"\"\"\n",
    "        Trả về img de predict vs kich thước model\n",
    "        Và vị trí để có thể ghi mask vào trong đúng vị trí ảnh\n",
    "    \"\"\"\n",
    "    if h_crop_start < 0 and w_crop_start < 0:\n",
    "        h_crop_start = 0\n",
    "        w_crop_start = 0\n",
    "        size_h_crop = crop_size + padding\n",
    "        size_w_crop = crop_size + padding\n",
    "        img_window_crop  = src_img.read([*range(1, num_band_train+1)],window=Window(w_crop_start, h_crop_start, size_w_crop, size_h_crop))\n",
    "        tmp_img_size_model[:, padding:, padding:] = img_window_crop\n",
    "        window_draw_pre = [padding, crop_size + padding, padding, crop_size + padding, start_w_org, start_h_org, crop_size, crop_size]\n",
    "\n",
    "    elif h_crop_start < 0:\n",
    "        h_crop_start = 0\n",
    "        size_h_crop = crop_size + padding\n",
    "        size_w_crop = min(crop_size + 2*padding, w - start_w_org + padding)\n",
    "        img_window_crop  = src_img.read([*range(1, num_band_train+1)],window=Window(w_crop_start, h_crop_start, size_w_crop, size_h_crop))\n",
    "        if size_w_crop == w - start_w_org + padding:\n",
    "            end_c_index_w =  size_w_crop\n",
    "            tmp_img_size_model[:,padding:,:end_c_index_w] = img_window_crop\n",
    "        else:\n",
    "            end_c_index_w = crop_size + padding\n",
    "            tmp_img_size_model[:, padding:,:] = img_window_crop\n",
    "        window_draw_pre = [padding, crop_size + padding ,padding, end_c_index_w, start_w_org, start_h_org,  min(crop_size, w - start_w_org), crop_size]\n",
    "\n",
    "    elif w_crop_start < 0:\n",
    "        w_crop_start = 0\n",
    "        size_w_crop = crop_size + padding\n",
    "        size_h_crop = min(crop_size + 2*padding, h - start_h_org + padding)\n",
    "        img_window_crop  = src_img.read([*range(1, num_band_train+1)],window=Window(w_crop_start, h_crop_start, size_w_crop, size_h_crop))\n",
    "        if size_h_crop == h - start_h_org + padding:\n",
    "            end_c_index_h =  size_h_crop\n",
    "            tmp_img_size_model[:,:end_c_index_h,padding:] = img_window_crop\n",
    "        else:\n",
    "            end_c_index_h = crop_size + padding\n",
    "            tmp_img_size_model[:,:, padding:] = img_window_crop\n",
    "        window_draw_pre = [padding, end_c_index_h, padding, crop_size + padding, start_w_org, start_h_org, crop_size, min(crop_size, h - start_h_org)]\n",
    "    \n",
    "    else:\n",
    "        size_w_crop = min(crop_size +2*padding, w - start_w_org + padding)\n",
    "        size_h_crop = min(crop_size +2*padding, h - start_h_org + padding)\n",
    "        img_window_crop  = src_img.read([*range(1, num_band_train+1)],window=Window(w_crop_start, h_crop_start, size_w_crop, size_h_crop))\n",
    "        if size_w_crop < (crop_size + 2*padding) and size_h_crop < (crop_size + 2*padding):\n",
    "            end_c_index_h = size_h_crop\n",
    "            end_c_index_w = size_w_crop\n",
    "            tmp_img_size_model[:,:end_c_index_h,:   end_c_index_w] = img_window_crop\n",
    "        elif size_w_crop < (crop_size + 2*padding):\n",
    "            end_c_index_h = crop_size + padding\n",
    "            end_c_index_w = size_w_crop\n",
    "            tmp_img_size_model[:,:,:end_c_index_w] = img_window_crop\n",
    "        elif size_h_crop < (crop_size + 2*padding):\n",
    "            end_c_index_w = crop_size + padding\n",
    "            end_c_index_h = size_h_crop\n",
    "            tmp_img_size_model[:,:end_c_index_h,:] = img_window_crop\n",
    "        else:\n",
    "            end_c_index_w = crop_size + padding\n",
    "            end_c_index_h = crop_size + padding\n",
    "            tmp_img_size_model[:,:,:] = img_window_crop\n",
    "        window_draw_pre = [padding, end_c_index_h, padding, end_c_index_w, start_w_org, start_h_org, min(crop_size, w - start_w_org), min(crop_size, h - start_h_org)]\n",
    "    return tmp_img_size_model, window_draw_pre, Window(w_crop_start, h_crop_start, size_w_crop, size_h_crop)\n",
    "\n",
    "\n",
    "\n",
    "def predict_win(numpy_chanel_first, detect_fn):\n",
    "    image_np_chanel_last = np.transpose(numpy_chanel_first, (1,2,0))\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np_chanel_last, 0), dtype=tf.float32)\n",
    "    detections, _, _ = detect_fn(input_tensor)\n",
    "    return detections\n",
    "\n",
    "\n",
    "def convert_detections_to_polygon(detections, source_data, windo, min_score_thresh):\n",
    "    transfrom_win = source_data.window_transform(windo)\n",
    "    im_width, im_height = windo.width, windo.height\n",
    "    all_boxes = detections['detection_boxes'][0].numpy()\n",
    "    all_scores = detections['detection_scores'][0].numpy()\n",
    "    \n",
    "    list_polygons = list()\n",
    "    list_scores = list()\n",
    "    for i in range(all_boxes.shape[0]):\n",
    "        if all_scores[i] > min_score_thresh:\n",
    "            ymin, xmin, ymax, xmax = tuple(all_boxes[i].tolist())\n",
    "            (left_pixel, right_pixel, top_pixel, bottom_pixel) = (xmin * im_width, xmax * im_width,\n",
    "                                    ymin * im_height, ymax * im_height)\n",
    "            \n",
    "            left_geo, top_geo = transfrom_win * (left_pixel, top_pixel)\n",
    "            right_geo, bottom_geo = transfrom_win * (right_pixel, bottom_pixel)\n",
    "            polygon = Polygon([(left_geo, top_geo), (right_geo, top_geo), (right_geo, bottom_geo), (left_geo, bottom_geo)])\n",
    "            list_polygons.append(polygon)\n",
    "            list_scores.append(all_scores[i])\n",
    "    return list_polygons, list_scores\n",
    " \n",
    "def predict_lager(fp_img, model_ship, model_size, crop_size, score_thresh):\n",
    "    num_band_train = 3\n",
    "    with rasterio.open(fp_img) as src:\n",
    "        h,w = src.height,src.width\n",
    "        source_crs = src.crs\n",
    "        source_transform = src.transform\n",
    "    \n",
    "    padding = int((model_size - crop_size)/2)\n",
    "    list_weight = list(range(0, w, crop_size))\n",
    "    list_hight = list(range(0, h, crop_size))\n",
    "    \n",
    "    list_polygons_all = list()\n",
    "    list_scores_all = list()\n",
    "    \n",
    "    with tqdm(total=len(list_hight)*len(list_weight)) as pbar:\n",
    "        with rasterio.open(fp_img) as src:\n",
    "            for start_h_org in list_hight:\n",
    "                for start_w_org in list_weight:\n",
    "                    # vi tri bat dau\n",
    "                    h_crop_start = start_h_org - padding\n",
    "                    w_crop_start = start_w_org - padding\n",
    "                    \n",
    "                    # kich thuoc\n",
    "                    tmp_img_model = np.zeros((num_band_train, model_size,model_size))\n",
    "                    tmp_img_model, _, wind = read_window_and_index_result(crop_size, h_crop_start, w_crop_start, start_w_org, start_h_org, padding, h, w, tmp_img_model, src, num_band_train)\n",
    "                    detections = predict_win(tmp_img_model, detect_fn)\n",
    "                    list_polygons, list_scores = convert_detections_to_polygon(detections, src, wind, score_thresh)\n",
    "                    list_polygons_all += list_polygons\n",
    "                    list_scores_all +=list_scores\n",
    "                    pbar.update()\n",
    "    return list_polygons_all, list_scores_all, source_crs\n",
    "                    \n",
    "\n",
    "def NMS_polygons(list_polygons, list_scores, list_labels=None, iou_threshold=0.2):\n",
    "    list_shapely_polygons = [Polygon(polygon) for polygon in list_polygons]\n",
    "    list_bound = [np.array(polygon.bounds) for polygon in list_shapely_polygons]\n",
    "    indexes = tf.image.non_max_suppression(np.array(list_bound), np.array(list_scores), len(list_scores),iou_threshold=iou_threshold)\n",
    "    result_polygons = [list_polygons[idx] for idx in indexes]\n",
    "    result_scores = [list_scores[idx] for idx in indexes]\n",
    "    if list_labels:\n",
    "        result_labels = [list_labels[idx] for idx in indexes]\n",
    "        return result_polygons, result_scores, result_labels\n",
    "    else:\n",
    "        return result_polygons, result_scores\n",
    "\n",
    "\n",
    "def get_model_detection_function(model):\n",
    "    \"\"\"Get a tf.function for detection.\"\"\"\n",
    "\n",
    "    @tf.function\n",
    "    def detect_fn(image):\n",
    "        \"\"\"Detect objects in image.\"\"\"\n",
    "\n",
    "        image, shapes = model.preprocess(image)\n",
    "        prediction_dict = model.predict(image, shapes)\n",
    "        detections = model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "        return detections, prediction_dict, tf.reshape(shapes, [-1])\n",
    "\n",
    "    return detect_fn\n",
    "\n",
    "\n",
    "def main(fp_img, detect_fn, model_size, crop_sizes, fp_out_shape):\n",
    "    \n",
    "    # load model is the best\n",
    "    # filenames = glob.glob(os.path.join(dir_weight,'*.index'))\n",
    "    # filenames = list(pathlib.Path(dir_weight).glob('*.index'))\n",
    "    # filenames.sort()\n",
    "    # print(filenames)\n",
    "    # # #recover our saved model\n",
    "    # model_dir = dir_weight\n",
    "    # #generally you want to put the last ckpt from training in here\n",
    "    # configs = config_util.get_configs_from_pipeline_file(pipeline_file)\n",
    "    # model_config = configs['model']\n",
    "    # detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "    # # print(detection_model)\n",
    "    # # Restore checkpoint\n",
    "    # ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "    # print(os.path.join(str(filenames[-1]).replace('.index','')))\n",
    "    # ckpt.restore(os.path.join(str(filenames[-1]).replace('.index','')))\n",
    "    # detect_fn = get_model_detection_function(detection_model)\n",
    "    \n",
    "    \n",
    "    # predict each win\n",
    "    list_polygons_all, list_scores_all, source_crs = predict_lager(fp_img, detect_fn, model_size, crop_sizes, score_thresh=0.5)\n",
    "    return list_polygons_all, list_scores_all, source_crs\n",
    "    # gdf = gpd.GeoDataFrame({'geometry': [list_polygons_all]}, crs=source_crs)\n",
    "    # gdf.to_file(fp_out_shape)\n",
    "    # result_polygons, result_scores = NMS_polygons(list_polygons_all, list_scores_all, list_labels=None, iou_threshold=0.2)\n",
    "    # print(result_polygons)\n",
    "    # gdf = gpd.GeoDataFrame({'geometry': [result_polygons]}, crs=source_crs)\n",
    "    # gdf.to_file(fp_out_shape.replace('.shp', '_a.shp'))\n",
    "    # pass\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# if __name__==\"__main__\":\n",
    "#     fp_img = r'/home/skm/SKM16/IMAGE/ZZ_ZZ/TauBien/DaNang_23_07_2009_LowAccuracy.tif'\n",
    "#     dir_weight = r'/home/skm/SKM16/IMAGE/ZZ_ZZ/TauBien/code/Try/SSD/train_custom/faster_rcnn_resnet50_v1_640x640_coco17_tpu_256'\n",
    "#     pipeline_file = r'/home/skm/SKM16/IMAGE/ZZ_ZZ/TauBien/code/Try/SSD/pretrain_model/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8/pipeline_256.config'\n",
    "#     model_size = 256\n",
    "#     crop_sizes = 200\n",
    "#     fp_out_shape = r'/home/skm/SKM16/IMAGE/ZZ_ZZ/TauBien/fast_256.shp'\n",
    "    \n",
    "#     filenames = list(pathlib.Path(dir_weight).glob('*.index'))\n",
    "#     filenames.sort()\n",
    "#     print(filenames)\n",
    "#     # #recover our saved model\n",
    "#     model_dir = dir_weight\n",
    "#     #generally you want to put the last ckpt from training in here\n",
    "#     configs = config_util.get_configs_from_pipeline_file(pipeline_file)\n",
    "#     model_config = configs['model']\n",
    "#     detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "#     # print(detection_model)\n",
    "#     # Restore checkpoint\n",
    "#     ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "#     print(os.path.join(str(filenames[-1]).replace('.index','')))\n",
    "#     ckpt.restore(os.path.join(str(filenames[-1]).replace('.index','')))\n",
    "#     detect_fn = get_model_detection_function(detection_model)\n",
    "    \n",
    "#     main(fp_img, detect_fn, model_size, crop_sizes, fp_out_shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/home/skm/SKM16/IMAGE/ZZ_ZZ/TauBien/code/Try/SSD/train_custom/faster_rcnn_resnet50_v1_640x640_coco17_tpu_256/ckpt-195.index'), PosixPath('/home/skm/SKM16/IMAGE/ZZ_ZZ/TauBien/code/Try/SSD/train_custom/faster_rcnn_resnet50_v1_640x640_coco17_tpu_256/ckpt-196.index'), PosixPath('/home/skm/SKM16/IMAGE/ZZ_ZZ/TauBien/code/Try/SSD/train_custom/faster_rcnn_resnet50_v1_640x640_coco17_tpu_256/ckpt-197.index'), PosixPath('/home/skm/SKM16/IMAGE/ZZ_ZZ/TauBien/code/Try/SSD/train_custom/faster_rcnn_resnet50_v1_640x640_coco17_tpu_256/ckpt-198.index'), PosixPath('/home/skm/SKM16/IMAGE/ZZ_ZZ/TauBien/code/Try/SSD/train_custom/faster_rcnn_resnet50_v1_640x640_coco17_tpu_256/ckpt-199.index'), PosixPath('/home/skm/SKM16/IMAGE/ZZ_ZZ/TauBien/code/Try/SSD/train_custom/faster_rcnn_resnet50_v1_640x640_coco17_tpu_256/ckpt-200.index'), PosixPath('/home/skm/SKM16/IMAGE/ZZ_ZZ/TauBien/code/Try/SSD/train_custom/faster_rcnn_resnet50_v1_640x640_coco17_tpu_256/ckpt-201.index')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 19:30:00.552055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10401 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/skm/SKM16/IMAGE/ZZ_ZZ/TauBien/code/Try/SSD/train_custom/faster_rcnn_resnet50_v1_640x640_coco17_tpu_256/ckpt-201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4212 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /home/skm/anaconda3/envs/myai/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:460: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 19:30:26.147951: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "100%|██████████| 4212/4212 [06:05<00:00, 11.52it/s]\n"
     ]
    }
   ],
   "source": [
    "fp_img = r'/home/skm/SKM16/IMAGE/ZZ_ZZ/TauBien/DaNang_23_07_2009_LowAccuracy.tif'\n",
    "dir_weight = r'/home/skm/SKM16/IMAGE/ZZ_ZZ/TauBien/code/Try/SSD/train_custom/faster_rcnn_resnet50_v1_640x640_coco17_tpu_256'\n",
    "pipeline_file = r'/home/skm/SKM16/IMAGE/ZZ_ZZ/TauBien/code/Try/SSD/pretrain_model/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8/pipeline_256.config'\n",
    "model_size = 256\n",
    "crop_sizes = 200\n",
    "fp_out_shape = r'/home/skm/SKM16/IMAGE/ZZ_ZZ/TauBien/fast_256.shp'\n",
    "\n",
    "filenames = list(pathlib.Path(dir_weight).glob('*.index'))\n",
    "filenames.sort()\n",
    "print(filenames)\n",
    "# #recover our saved model\n",
    "model_dir = dir_weight\n",
    "#generally you want to put the last ckpt from training in here\n",
    "configs = config_util.get_configs_from_pipeline_file(pipeline_file)\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "# print(detection_model)\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "print(os.path.join(str(filenames[-1]).replace('.index','')))\n",
    "ckpt.restore(os.path.join(str(filenames[-1]).replace('.index','')))\n",
    "detect_fn = get_model_detection_function(detection_model)\n",
    "\n",
    "list_polygons_all, list_scores_all, source_crs = main(fp_img, detect_fn, model_size, crop_sizes, fp_out_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRS.from_epsg(4326)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_out_shape = r'/home/skm/SKM16/IMAGE/ZZ_ZZ/TauBien/fast_256.shp'\n",
    "import rasterio\n",
    "with rasterio.open(fp_img) as src:\n",
    "    crs = src.crs\n",
    "\n",
    "gdf = gpd.GeoDataFrame(geometry=list_polygons_all)\n",
    "gdf.crs = crs\n",
    "gdf.to_file(fp_out_shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
